{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOlkP5uYKz1UzoINcUEXPz0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%%capture\n","!pip install causal-conv1d>=1.1.0 mamba-ssm pytorch-minimize psutil gputil"],"metadata":{"id":"ZwiuxPglymDa","executionInfo":{"status":"ok","timestamp":1707264701711,"user_tz":300,"elapsed":9036,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Ao2CxvRxtzRo","executionInfo":{"status":"ok","timestamp":1707264710322,"user_tz":300,"elapsed":8614,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch.optim import Adam\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","from numpy import genfromtxt\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","import psutil\n","import GPUtil\n","from google.colab import drive\n","from mamba_ssm import Mamba\n","import time\n","from pathlib import Path"]},{"cell_type":"code","source":["# This will prompt you to click on a link and generate an authorization code.\n","drive.mount('/content/drive')\n","project_path = '/content/drive/MyDrive/AI/CGD_research/light-har'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZF4Bm_Hy1cB","executionInfo":{"status":"ok","timestamp":1707264711195,"user_tz":300,"elapsed":896,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}},"outputId":"4fa6da0a-8544-483b-9ba2-6d251393382c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["def compute_metrics_base(model, x_test, y_test, model_path):\n","    \"\"\"\n","    Compute the accuracy of the PyTorch model.\n","\n","    :param model: PyTorch model.\n","    :param x_test: Test dataset features (as a PyTorch Tensor).\n","    :param y_test: Test dataset labels (as a NumPy array).\n","    :param model_dir: Directory where the PyTorch model files are stored.\n","    :return: None\n","    \"\"\"\n","\n","    model.eval()\n","    with torch.no_grad():\n","        # Get the model's predictions\n","        outputs = model(x_test)\n","        _, predicted_labels = torch.max(outputs, 1)\n","\n","        # Convert y_test to tensor if it's not already\n","        true_labels = torch.tensor(y_test) if not isinstance(y_test, torch.Tensor) else y_test\n","        true_labels = true_labels.squeeze()  # Remove unnecessary dimensions\n","\n","    model_file = Path(model_path)\n","\n","    # Size in bytes\n","    model_size_bytes = model_file.stat().st_size\n","\n","    # Convert size to kilobytes (optional)\n","    model_size_kb = model_size_bytes / 1024\n","    print(f\"Size of the model: {model_size_kb:.2f} KB\")\n","\n","    # Compute accuracy\n","    accuracy = accuracy_score(true_labels.cpu().numpy(), predicted_labels.cpu().numpy())\n","    print(f'Accuracy on the test set: {accuracy:.2%}')\n","\n","def measure_cpu_utilization_and_run(func, *args, **kwargs):\n","    \"\"\"\n","    Measure CPU utilization while running a function.\n","\n","    Parameters:\n","        func (function): The function to be executed.\n","        *args: Arguments to be passed to func.\n","        **kwargs: Keyword arguments to be passed to func.\n","\n","    Returns:\n","        float: CPU utilization percentage during the execution of func.\n","        float: The elapsed time during the execution of func.\n","        any: The result of func execution.\n","    \"\"\"\n","\n","    # Measure CPU utilization before execution\n","    cpu_percent_before = psutil.cpu_percent(interval=None)\n","\n","    # Record the start time\n","    start_time = time.time()\n","\n","    # Execute the function and store its result\n","    result = func(*args, **kwargs)\n","\n","    # Record the end time\n","    end_time = time.time()\n","\n","    # Measure CPU utilization after execution\n","    cpu_percent_after = psutil.cpu_percent(interval=None)\n","\n","    # Calculate elapsed time and average CPU utilization\n","    elapsed_time = end_time - start_time\n","    average_cpu_utilization = (cpu_percent_before + cpu_percent_after) / 2\n","\n","    return average_cpu_utilization, elapsed_time, result"],"metadata":{"id":"7klURsjYveXq","executionInfo":{"status":"ok","timestamp":1707264711195,"user_tz":300,"elapsed":3,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Load Data\n","x = genfromtxt(project_path+'/data/WISDM_x.csv', delimiter=',')\n","y_df = pd.read_csv(project_path+'/data/WISDM_y.csv')\n","y = y_df.values.flatten()  # Flatten if y is 2D\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Function to create time series dataset\n","def create_series(x, y, timestep, overlap):\n","    slide_step = int(timestep * (1 - overlap))\n","    data_num = int((len(x) / slide_step) - 1)\n","    dataset = np.ndarray(shape=(data_num, timestep, x.shape[1]))\n","    labels = []\n","\n","    for i in range(data_num):\n","        labels.append(y[slide_step * (i + 1) - 1])\n","        for j in range(timestep):\n","            dataset[i, j, :] = x[slide_step * i + j, :]\n","\n","    return dataset, np.array(labels)\n","\n","# Create time series\n","timestep = 16  # Replace with your value\n","overlap = 0.5  # Replace with your value\n","X_series, y_series = create_series(x, y_encoded, timestep, overlap)"],"metadata":{"id":"nVqheAjvw6T-","executionInfo":{"status":"ok","timestamp":1707264722343,"user_tz":300,"elapsed":11150,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_series, y_series, test_size=0.2, random_state=42)\n","\n","# Convert to PyTorch tensors\n","x_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","x_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","print(x_train_tensor.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSIjy4aS1UpF","executionInfo":{"status":"ok","timestamp":1707265206046,"user_tz":300,"elapsed":175,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}},"outputId":"43abb291-a170-4088-acb0-d7c91af7c9f9"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([104856, 16, 3])\n"]}]},{"cell_type":"code","source":["# Create a DataLoader\n","batch_size = 32\n","train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n","\n","# Create a test Dataloader\n","test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"],"metadata":{"id":"e_m1eTF71XqT","executionInfo":{"status":"ok","timestamp":1707264722343,"user_tz":300,"elapsed":3,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class TimeSeriesMamba(nn.Module):\n","    def __init__(self, sequence_length, num_features, head_size, n_heads, ff_dim, n_trans_blocks, mlp_units, drop=0.0, mlp_drop=0.0):\n","        super(TimeSeriesMamba, self).__init__()\n","\n","        # Encoder module\n","        self.encoders = nn.ModuleList([\n","            Mamba(\n","                d_model=num_features,\n","                d_state=16,\n","                d_conv=4,\n","                expand=2,\n","        ) for _ in range(n_trans_blocks)])\n","\n","        # Global average pooling\n","        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n","\n","        # MLP layers\n","        mlp_layers = []\n","        current_dim = num_features\n","        for dim in mlp_units:\n","            mlp_layers.extend([\n","                nn.Linear(current_dim, dim),\n","                nn.ReLU(),\n","                nn.Dropout(mlp_drop) if mlp_drop > 0.0 else nn.Identity(),  # Apply dropout conditionally\n","            ])\n","            current_dim = dim\n","\n","        self.mlp = nn.Sequential(*mlp_layers)\n","        self.final_layer = nn.Linear(mlp_units[-1], 6)\n","\n","    def forward(self, input_data):\n","        # Encoder\n","        for encoder in self.encoders:\n","            encoded_data = encoder(input_data)\n","\n","        # Global average pooling\n","        encoded_data = encoded_data.permute(0, 2, 1)\n","        global_avg_pooled = self.global_avg_pooling(encoded_data)\n","        flattened = torch.flatten(global_avg_pooled, 1)\n","\n","        # MLP\n","        mlp_output = self.mlp(flattened)\n","\n","        # Final layer\n","        output = self.final_layer(mlp_output)\n","        return output\n","\n","# Model instantiation\n","model = TimeSeriesMamba(\n","    sequence_length=16,\n","    num_features=3,\n","    head_size=3,\n","    n_heads=1,\n","    ff_dim=64,\n","    n_trans_blocks=4,\n","    mlp_units=[128, 64],\n","    drop=0.1,\n","    mlp_drop=0.1\n",")"],"metadata":{"id":"VBQ9qZA5z8Yr","executionInfo":{"status":"ok","timestamp":1707264722958,"user_tz":300,"elapsed":618,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Trained by Adam Optimizer"],"metadata":{"id":"-KX4gWolzEoM"}},{"source":["model_path = project_path+'/models/mamba_base.pt'\n","model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GiOniAof0yav","executionInfo":{"status":"ok","timestamp":1707264827422,"user_tz":300,"elapsed":307,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}},"outputId":"7106c4b9-ecc3-4219-d7a3-9faeef448120"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["model = model.to('cuda')\n","x_test_tensor = x_test_tensor.to('cuda')\n","y_test_tensor = y_test_tensor.to('cuda')\n","\n","cpu_usage, inference_time, _ = measure_cpu_utilization_and_run(compute_metrics_base, model, x_test_tensor, y_test_tensor, model_path)\n","\n","print(f'CPU usage during inference: {cpu_usage:.2f}%')\n","print(f'Inference time: {inference_time:.4f} seconds')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3jAJN4A0abt","executionInfo":{"status":"ok","timestamp":1707265210242,"user_tz":300,"elapsed":517,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}},"outputId":"481ba598-d3ff-4586-bcec-14f7774b23e9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of the model: 55.66 KB\n","Accuracy on the test set: 86.92%\n","CPU usage during inference: 58.65%\n","Inference time: 0.2846 seconds\n"]}]},{"cell_type":"markdown","source":["## Trained by Conjugate Gradient Method"],"metadata":{"id":"QiFwWCbTImRF"}},{"cell_type":"code","source":["model_path = project_path+'/models/mamba_cg_base.pt'\n","model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1u4eKCF_4eO5","executionInfo":{"status":"ok","timestamp":1707268576809,"user_tz":300,"elapsed":550,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}},"outputId":"69228b60-4e12-4b25-ccdc-319a0563ec5b"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["model = model.to('cuda')\n","x_test_tensor = x_test_tensor.to('cuda')\n","y_test_tensor = y_test_tensor.to('cuda')\n","\n","cpu_usage, inference_time, _ = measure_cpu_utilization_and_run(compute_metrics_base, model, x_test_tensor, y_test_tensor, model_path)\n","\n","print(f'CPU usage during inference: {cpu_usage:.2f}%')\n","print(f'Inference time: {inference_time:.4f} seconds')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3vofXRdIvDU","executionInfo":{"status":"ok","timestamp":1707268579335,"user_tz":300,"elapsed":152,"user":{"displayName":"Poom Chan","userId":"17431502970867301186"}},"outputId":"bb57a3a9-0669-4ba5-d26d-24e01bf73628"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of the model: 55.79 KB\n","Accuracy on the test set: 78.53%\n","CPU usage during inference: 40.10%\n","Inference time: 0.0664 seconds\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"LJH2m4v0Ix5T"},"execution_count":null,"outputs":[]}]}