{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fee4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35ef5f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Current GPU device: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "# Torch device configuration\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "    if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name(device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2738544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_metrics_base(model, x_test, y_test, model_path):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of the PyTorch model.\n",
    "\n",
    "    :param model: PyTorch model.\n",
    "    :param x_test: Test dataset features (as a PyTorch Tensor).\n",
    "    :param y_test: Test dataset labels (as a NumPy array).\n",
    "    :param model_dir: Directory where the PyTorch model files are stored.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get the model's predictions\n",
    "        outputs = model(x_test)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "\n",
    "        # Convert y_test to tensor if it's not already\n",
    "        true_labels = torch.tensor(y_test) if not isinstance(y_test, torch.Tensor) else y_test\n",
    "        true_labels = true_labels.squeeze()  # Remove unnecessary dimensions\n",
    "\n",
    "    model_file = Path(model_path)\n",
    "\n",
    "    # Size in bytes\n",
    "    model_size_bytes = model_file.stat().st_size\n",
    "\n",
    "    # Convert size to kilobytes (optional)\n",
    "    model_size_kb = model_size_bytes / 1024\n",
    "    print(f\"Size of the model: {model_size_kb:.2f} KB\")\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels.numpy(), predicted_labels.numpy())\n",
    "    print(f'Accuracy on the test set: {accuracy:.2%}')\n",
    "    \n",
    "def measure_cpu_utilization_and_run(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Measure CPU utilization while running a function.\n",
    "\n",
    "    Parameters:\n",
    "        func (function): The function to be executed.\n",
    "        *args: Arguments to be passed to func.\n",
    "        **kwargs: Keyword arguments to be passed to func.\n",
    "\n",
    "    Returns:\n",
    "        float: CPU utilization percentage during the execution of func.\n",
    "        float: The elapsed time during the execution of func.\n",
    "        any: The result of func execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Measure CPU utilization before execution\n",
    "    cpu_percent_before = psutil.cpu_percent(interval=None)\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Execute the function and store its result\n",
    "    result = func(*args, **kwargs)\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Measure CPU utilization after execution\n",
    "    cpu_percent_after = psutil.cpu_percent(interval=None)\n",
    "\n",
    "    # Calculate elapsed time and average CPU utilization\n",
    "    elapsed_time = end_time - start_time\n",
    "    average_cpu_utilization = (cpu_percent_before + cpu_percent_after) / 2\n",
    "\n",
    "    return average_cpu_utilization, elapsed_time, result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c2ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x = genfromtxt('../../Data/WISDM_x.csv', delimiter=',')\n",
    "y_df = pd.read_csv('../../Data/WISDM_y.csv')\n",
    "y = y_df.values.flatten()  # Flatten if y is 2D\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Function to create time series dataset\n",
    "def create_series(x, y, timestep, overlap):\n",
    "    slide_step = int(timestep * (1 - overlap))\n",
    "    data_num = int((len(x) / slide_step) - 1)\n",
    "    dataset = np.ndarray(shape=(data_num, timestep, x.shape[1]))\n",
    "    labels = []\n",
    "\n",
    "    for i in range(data_num):\n",
    "        labels.append(y[slide_step * (i + 1) - 1])\n",
    "        for j in range(timestep):\n",
    "            dataset[i, j, :] = x[slide_step * i + j, :]\n",
    "\n",
    "    return dataset, np.array(labels)\n",
    "\n",
    "# Create time series\n",
    "timestep = 16  # Replace with your value\n",
    "overlap = 0.5  # Replace with your value\n",
    "X_series, y_series = create_series(x, y_encoded, timestep, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7842f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(104856, 16, 3), X_test shape:(26214, 16, 3), y_train shape:(104856,), y_test shape:(26214,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_series, y_series, test_size=0.2, random_state=42)\n",
    "print(f'X_train shape:{X_train.shape}, X_test shape:{X_test.shape}, y_train shape:{y_train.shape}, y_test shape:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c86d475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64)  # Assuming y_train is already encoded as class indexes\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97b360ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "training_percentage = 0.9  # Set the desired percentage of training samples\n",
    "\n",
    "# Calculate the number of training samples\n",
    "n_total_samples = X_train_tensor.shape[0]\n",
    "n_training_data = int(training_percentage * n_total_samples)\n",
    "\n",
    "# Create a subset of the training data\n",
    "subset_indices = torch.randperm(n_total_samples)[:n_training_data]\n",
    "x_train_subset = X_train_tensor[subset_indices]\n",
    "y_train_subset = y_train_tensor[subset_indices]\n",
    "\n",
    "# Create a DataLoader for the subset\n",
    "batch_size = n_training_data\n",
    "train_dataset = TensorDataset(x_train_subset, y_train_subset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create a test Dataloader\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56b1440b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformer(\n",
       "  (encoders): ModuleList(\n",
       "    (0-3): 4 x TransformerEncoderBlock(\n",
       "      (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 3, kernel_size=(1,), stride=(1,))\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (global_avg_pooling): AdaptiveAvgPool1d(output_size=1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=64, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Transformer model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, head_size, n_heads, ff_dim, dropout=0.0):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=input_dim, num_heads=n_heads, dropout=dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=ff_dim, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=ff_dim, out_channels=input_dim, kernel_size=1)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # LayerNorm and Multi-head Attention\n",
    "        x = self.norm1(src)\n",
    "        x, _ = self.attention(x, x, x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x + src  # skip connection\n",
    "\n",
    "        # Feed Forward\n",
    "        x = self.norm2(x)\n",
    "        x = x.permute(1, 2, 0)  # Conv1D expects (batch_size, channels, length)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.permute(2, 0, 1)  # back to (length, batch_size, channels)\n",
    "        x = x + src  # skip connection\n",
    "        return x\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, sequence_length, num_features, head_size, n_heads, ff_dim, n_trans_blocks, mlp_units, drop=0.0, mlp_drop=0.0):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.encoders = nn.ModuleList([TransformerEncoderBlock(num_features, head_size, n_heads, ff_dim, drop) for _ in range(n_trans_blocks)])\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        mlp_layers = []\n",
    "        current_dim = num_features\n",
    "        for dim in mlp_units:\n",
    "            mlp_layers.append(nn.Linear(current_dim, dim))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(mlp_drop))\n",
    "            current_dim = dim  # Set input dim for the next layer\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        self.final_layer = nn.Linear(mlp_units[-1], 6)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = src.permute(1, 0, 2)  # Transformer expects (seq_len, batch_size, features)\n",
    "        for encoder in self.encoders:\n",
    "            src = encoder(src)\n",
    "\n",
    "        # Global average pooling\n",
    "        src = src.permute(1, 2, 0)  # pooling expects (batch_size, channels, length)\n",
    "        src = self.global_avg_pooling(src)\n",
    "        src = torch.flatten(src, 1)  # Flatten the output for the MLP\n",
    "\n",
    "        # MLP\n",
    "        src = self.mlp(src)\n",
    "        output = self.final_layer(src)\n",
    "        return output\n",
    "\n",
    "# Input parameters for your data\n",
    "sequence_length = 16  # The length of the time series sequences in your data\n",
    "num_features = 3     # The number of features in each time step of your data sequence\n",
    "\n",
    "# Instantiate the model\n",
    "# Instantiate the model with an adjusted number of heads and head size\n",
    "# The head size must be a multiple of num_features.\n",
    "model = TimeSeriesTransformer(\n",
    "    sequence_length=16, \n",
    "    num_features=3, \n",
    "    head_size=3,  # Each head will now have an embed size of 1 (3 / 3)\n",
    "    n_heads=1,  # Only one head since our embed_dim is 3\n",
    "    ff_dim=64, \n",
    "    n_trans_blocks=4, \n",
    "    mlp_units=[128, 64], \n",
    "    drop=0.1, \n",
    "    mlp_drop=0.1\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ab86147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 1.4931, Val Accuracy: 42.89%\n",
      "Epoch [2/100], Train Loss: 1.3841, Val Accuracy: 47.83%\n",
      "Epoch [3/100], Train Loss: 1.3353, Val Accuracy: 50.66%\n",
      "Epoch [4/100], Train Loss: 1.3010, Val Accuracy: 50.86%\n",
      "Epoch [5/100], Train Loss: 1.2863, Val Accuracy: 51.16%\n",
      "Epoch [6/100], Train Loss: 1.2778, Val Accuracy: 51.95%\n",
      "Epoch [7/100], Train Loss: 1.2692, Val Accuracy: 51.79%\n",
      "Epoch [8/100], Train Loss: 1.2625, Val Accuracy: 52.25%\n",
      "Epoch [9/100], Train Loss: 1.2583, Val Accuracy: 52.38%\n",
      "Epoch [10/100], Train Loss: 1.2525, Val Accuracy: 52.38%\n",
      "Epoch [11/100], Train Loss: 1.2005, Val Accuracy: 55.73%\n",
      "Epoch [12/100], Train Loss: 1.1871, Val Accuracy: 56.29%\n",
      "Epoch [13/100], Train Loss: 1.1796, Val Accuracy: 56.61%\n",
      "Epoch [14/100], Train Loss: 1.1720, Val Accuracy: 56.51%\n",
      "Epoch [15/100], Train Loss: 1.1661, Val Accuracy: 57.08%\n",
      "Epoch [16/100], Train Loss: 1.1608, Val Accuracy: 56.82%\n",
      "Epoch [17/100], Train Loss: 1.1565, Val Accuracy: 57.34%\n",
      "Epoch [18/100], Train Loss: 1.1522, Val Accuracy: 57.58%\n",
      "Epoch [19/100], Train Loss: 1.1479, Val Accuracy: 57.82%\n",
      "Epoch [20/100], Train Loss: 1.1252, Val Accuracy: 58.74%\n",
      "Epoch [21/100], Train Loss: 1.1006, Val Accuracy: 60.10%\n",
      "Epoch [22/100], Train Loss: 1.0959, Val Accuracy: 59.86%\n",
      "Epoch [23/100], Train Loss: 1.0924, Val Accuracy: 60.25%\n",
      "Epoch [24/100], Train Loss: 1.0848, Val Accuracy: 60.86%\n",
      "Epoch [25/100], Train Loss: 1.0790, Val Accuracy: 60.70%\n",
      "Epoch [26/100], Train Loss: 1.0759, Val Accuracy: 60.92%\n",
      "Epoch [27/100], Train Loss: 1.0716, Val Accuracy: 61.28%\n",
      "Epoch [28/100], Train Loss: 1.0655, Val Accuracy: 61.28%\n",
      "Epoch [29/100], Train Loss: 1.0602, Val Accuracy: 61.72%\n",
      "Epoch [30/100], Train Loss: 1.0573, Val Accuracy: 61.57%\n",
      "Epoch [31/100], Train Loss: 1.0570, Val Accuracy: 61.83%\n",
      "Epoch [32/100], Train Loss: 1.0540, Val Accuracy: 62.13%\n",
      "Epoch [33/100], Train Loss: 1.0481, Val Accuracy: 62.04%\n",
      "Epoch [34/100], Train Loss: 1.0430, Val Accuracy: 62.62%\n",
      "Epoch [35/100], Train Loss: 1.0381, Val Accuracy: 62.67%\n",
      "Epoch [36/100], Train Loss: 1.0338, Val Accuracy: 62.95%\n",
      "Epoch [37/100], Train Loss: 1.0281, Val Accuracy: 63.23%\n",
      "Epoch [38/100], Train Loss: 1.0193, Val Accuracy: 63.59%\n",
      "Epoch [39/100], Train Loss: 1.0134, Val Accuracy: 63.83%\n",
      "Epoch [40/100], Train Loss: 1.0114, Val Accuracy: 63.87%\n",
      "Epoch [41/100], Train Loss: 0.9810, Val Accuracy: 65.04%\n",
      "Epoch [42/100], Train Loss: 0.9636, Val Accuracy: 66.09%\n",
      "Epoch [43/100], Train Loss: 0.9592, Val Accuracy: 66.03%\n",
      "Epoch [44/100], Train Loss: 0.9577, Val Accuracy: 65.98%\n",
      "Epoch [45/100], Train Loss: 0.9554, Val Accuracy: 66.26%\n",
      "Epoch [46/100], Train Loss: 0.9531, Val Accuracy: 66.37%\n",
      "Epoch [47/100], Train Loss: 0.9519, Val Accuracy: 66.29%\n",
      "Epoch [48/100], Train Loss: 0.9492, Val Accuracy: 66.54%\n",
      "Epoch [49/100], Train Loss: 0.9491, Val Accuracy: 66.52%\n",
      "Epoch [50/100], Train Loss: 0.9471, Val Accuracy: 66.86%\n",
      "Epoch [51/100], Train Loss: 0.9438, Val Accuracy: 66.85%\n",
      "Epoch [52/100], Train Loss: 0.9394, Val Accuracy: 67.09%\n",
      "Epoch [53/100], Train Loss: 0.9388, Val Accuracy: 67.08%\n",
      "Epoch [54/100], Train Loss: 0.9380, Val Accuracy: 67.10%\n",
      "Epoch [55/100], Train Loss: 0.9294, Val Accuracy: 67.83%\n",
      "Epoch [56/100], Train Loss: 0.9193, Val Accuracy: 68.00%\n",
      "Epoch [57/100], Train Loss: 0.9159, Val Accuracy: 68.26%\n",
      "Epoch [58/100], Train Loss: 0.9142, Val Accuracy: 68.21%\n",
      "Epoch [59/100], Train Loss: 0.9126, Val Accuracy: 68.43%\n",
      "Epoch [60/100], Train Loss: 0.9064, Val Accuracy: 68.51%\n",
      "Epoch [61/100], Train Loss: 0.9029, Val Accuracy: 68.68%\n",
      "Epoch [62/100], Train Loss: 0.9016, Val Accuracy: 68.80%\n",
      "Epoch [63/100], Train Loss: 0.9002, Val Accuracy: 69.04%\n",
      "Epoch [64/100], Train Loss: 0.8987, Val Accuracy: 68.89%\n",
      "Epoch [65/100], Train Loss: 0.8962, Val Accuracy: 69.03%\n",
      "Epoch [66/100], Train Loss: 0.8883, Val Accuracy: 69.39%\n",
      "Epoch [67/100], Train Loss: 0.8836, Val Accuracy: 69.48%\n",
      "Epoch [68/100], Train Loss: 0.8827, Val Accuracy: 69.39%\n",
      "Epoch [69/100], Train Loss: 0.8823, Val Accuracy: 69.63%\n",
      "Epoch [70/100], Train Loss: 0.8811, Val Accuracy: 69.51%\n",
      "Epoch [71/100], Train Loss: 0.8780, Val Accuracy: 69.82%\n",
      "Epoch [72/100], Train Loss: 0.8783, Val Accuracy: 69.93%\n",
      "Epoch [73/100], Train Loss: 0.8760, Val Accuracy: 69.88%\n",
      "Epoch [74/100], Train Loss: 0.8754, Val Accuracy: 69.94%\n",
      "Epoch [75/100], Train Loss: 0.8684, Val Accuracy: 69.99%\n",
      "Epoch [76/100], Train Loss: 0.8655, Val Accuracy: 70.54%\n",
      "Epoch [77/100], Train Loss: 0.8641, Val Accuracy: 70.51%\n",
      "Epoch [78/100], Train Loss: 0.8638, Val Accuracy: 70.55%\n",
      "Epoch [79/100], Train Loss: 0.8627, Val Accuracy: 70.43%\n",
      "Epoch [80/100], Train Loss: 0.8599, Val Accuracy: 70.74%\n",
      "Epoch [81/100], Train Loss: 0.8562, Val Accuracy: 70.64%\n",
      "Epoch [82/100], Train Loss: 0.8553, Val Accuracy: 70.52%\n",
      "Epoch [83/100], Train Loss: 0.8529, Val Accuracy: 70.70%\n",
      "Epoch [84/100], Train Loss: 0.8506, Val Accuracy: 70.66%\n",
      "Epoch [85/100], Train Loss: 0.8449, Val Accuracy: 71.15%\n",
      "Epoch [86/100], Train Loss: 0.8447, Val Accuracy: 71.02%\n",
      "Epoch [87/100], Train Loss: 0.8429, Val Accuracy: 70.83%\n",
      "Epoch [88/100], Train Loss: 0.8394, Val Accuracy: 71.24%\n",
      "Epoch [89/100], Train Loss: 0.8327, Val Accuracy: 71.29%\n",
      "Epoch [90/100], Train Loss: 0.8304, Val Accuracy: 71.28%\n",
      "Epoch [91/100], Train Loss: 0.8288, Val Accuracy: 71.35%\n",
      "Epoch [92/100], Train Loss: 0.8276, Val Accuracy: 71.54%\n",
      "Epoch [93/100], Train Loss: 0.8266, Val Accuracy: 71.45%\n",
      "Epoch [94/100], Train Loss: 0.8262, Val Accuracy: 71.69%\n",
      "Epoch [95/100], Train Loss: 0.8254, Val Accuracy: 71.70%\n",
      "Epoch [96/100], Train Loss: 0.8227, Val Accuracy: 71.58%\n",
      "Epoch [97/100], Train Loss: 0.8204, Val Accuracy: 71.67%\n",
      "Epoch [98/100], Train Loss: 0.8216, Val Accuracy: 71.69%\n",
      "Epoch [99/100], Train Loss: 0.8209, Val Accuracy: 71.74%\n",
      "Epoch [100/100], Train Loss: 0.8207, Val Accuracy: 71.65%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmin import Minimizer\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = Minimizer(model.parameters(),\n",
    "                      method='cg',\n",
    "                      tol=1e-3,\n",
    "                      max_iter=2,\n",
    "                      disp=0)\n",
    "\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "num_fine_tune_epochs = 100\n",
    "best_val_accuracy = 0.0  # Variable to track the best validation accuracy\n",
    "best_model_state = None  # Variable to store the state of the best model\n",
    "\n",
    "for epoch in range(num_fine_tune_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Move inputs and labels to the selected device\n",
    "        inputs, labels = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, labels)\n",
    "            # loss.backward()  <-- do not call backward!\n",
    "            return loss\n",
    "\n",
    "        loss = optimizer.step(closure)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        # Move inputs and labels to the selected device\n",
    "        inputs, labels = X_batch.to(device), y_batch.to(device)\n",
    "        output = model(inputs)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_fine_tune_epochs}], Train Loss: {avg_loss:.4f}, Val Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Save the model if the current validation accuracy is better than the best\n",
    "    if accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = accuracy\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd3fcf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "model_path = 'models/transformer_base.pt'\n",
    "torch.save(best_model_state, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "365f1ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7281\n",
      "Precision: 0.6814\n",
      "Recall: 0.7281\n",
      "F1 Score: 0.6699\n",
      "The model size is 61.94 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model_path = 'models/transformer_base.pt'\n",
    "\n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Collect all predictions and labels to compute overall metrics\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert collected predictions and labels to arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')\n",
    "\n",
    "# Get the size of the saved model file\n",
    "model_size = os.path.getsize(model_path)\n",
    "print(f\"The model size is {model_size/1024:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b340fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model: 61.94 KB\n",
      "Accuracy on the test set: 72.81%\n",
      "CPU usage during inference: 6.40%\n",
      "Inference time: 0.4594 seconds\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "\n",
    "cpu_usage, inference_time, _ = measure_cpu_utilization_and_run(compute_metrics_base, model, X_test_tensor, y_test_tensor, model_path)\n",
    "\n",
    "print(f'CPU usage during inference: {cpu_usage:.2f}%')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38360f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization complete and model saved.\n"
     ]
    }
   ],
   "source": [
    "import torch.quantization\n",
    "# torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "# Load the saved model's state dict\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Make sure the model is in evaluation mode before quantization\n",
    "model.eval()\n",
    "\n",
    "# Perform dynamic quantization\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model,  # the original model\n",
    "    {torch.nn.Linear},  # specify which layer types to quantize\n",
    "    dtype=torch.qint8  # the target data type for quantized weights\n",
    ")\n",
    "\n",
    "# Save the quantized model\n",
    "quantized_model_path = \"models/transformer_CG_quantized.pt\"\n",
    "torch.save(quantized_model.state_dict(), quantized_model_path)\n",
    "\n",
    "# Now you can use quantized_model for inference\n",
    "print(\"Quantization complete and model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0bc8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7285\n",
      "Precision: 0.6812\n",
      "Recall: 0.7285\n",
      "F1 Score: 0.6710\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "quantized_model.to('cpu')\n",
    "quantized_model.eval()  # Set the model to evaluation mode\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
    "        outputs = quantized_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Collect all predictions and labels to compute overall metrics\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert collected predictions and labels to arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ee39d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model: 37.72 KB\n",
      "Accuracy on the test set: 72.84%\n",
      "CPU usage during inference: 1.95%\n",
      "Inference time: 0.2147 seconds\n"
     ]
    }
   ],
   "source": [
    "cpu_usage, inference_time, _ = measure_cpu_utilization_and_run(compute_metrics_base, quantized_model, X_test_tensor, y_test_tensor, quantized_model_path)\n",
    "\n",
    "print(f'CPU usage during inference: {cpu_usage:.2f}%')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
