{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XX_AR4FbasKc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Preprocessing**"
      ],
      "metadata": {
        "id": "XX_AR4FbasKc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poosUw_45l4O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf  # Version 1.0.0 (some previous versions are used in past commits)\n",
        "from sklearn import metrics\n",
        "\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Useful Constants\n",
        "\n",
        "# Those are separate normalised input features for the neural network\n",
        "INPUT_SIGNAL_TYPES = [\n",
        "    \"x_accel\",\n",
        "    \"y_accel\",\n",
        "    \"z_accel\",\n",
        "]\n",
        "\n",
        "# Output classes to learn how to classify\n",
        "LABELS = [\n",
        "    \"Walking\", \n",
        "    \"Jogging\", \n",
        "    \"Uptairs\", \n",
        "    \"Downstairs\", \n",
        "    \"Sitting\", \n",
        "    \"Standing\"\n",
        "] "
      ],
      "metadata": {
        "id": "y3X3Y3n7Ic8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "x = genfromtxt('/content/drive/MyDrive/Colab Notebooks/WISDM_x.csv', delimiter=',')\n",
        "y = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/WISDM_y.csv').to_numpy()"
      ],
      "metadata": {
        "id": "Gl8CawmV9fyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_series(x,y,timestep,overlap):\n",
        "\n",
        "  slide_step = int(timestep*(1-overlap))\n",
        "  data_num = int((len(x)/slide_step)-1)\n",
        "  \n",
        "  dataset = np.ndarray(shape=(data_num,timestep,len(x[0])))\n",
        "  labels = list()\n",
        "\n",
        "  for i in range(data_num):\n",
        "    labels.append(y[slide_step*(i+1)-1])\n",
        "    for j in range(timestep):\n",
        "      dataset[i,j,:] = x[slide_step*i+j,:]\n",
        "\n",
        "  return dataset,np.array(labels)\n"
      ],
      "metadata": {
        "id": "e3VBgAnMR0H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y).reshape(-1,1)\n",
        "\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "y = ohe.fit_transform(y).toarray()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwGN7lDhHgbR",
        "outputId": "638cc634-38d6-4e70-98ff-38223d8206fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[1]\n",
        "# y2 = y.extend"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl6THkokIZ4R",
        "outputId": "2564590e-a8a7-4eba-fde0-9a7539cd080a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred.append(\"5\")\n",
        "dataset,labels = create_series(x,y,256,0.5)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset,labels,test_size=0.3, random_state=412)\n",
        "# X_test, X_val, y_test, y_val = train_test_split(X_toSplit,y_toSplit,test_size=0.25, random_state=412)"
      ],
      "metadata": {
        "id": "-jUILW0nXcZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train.shape,\n",
        "# X_test.shape,\n",
        "# X_val.shape,\n",
        "# dataset.shape\n",
        "# )"
      ],
      "metadata": {
        "id": "ecD7uzjLVISo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mhwJ__U5POC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y69e8D-iOzRD",
        "outputId": "82b7232d-15a8-465a-c3d2-d74377e9d1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8190, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Data \n",
        "\n",
        "training_data_count = len(X_train)  # 96092 training series (with 50% overlap between each serie)\n",
        "test_data_count = len(X_test)  # 41183 testing series\n",
        "n_steps = len(X_train[0])  # 16 timesteps per series\n",
        "n_input = len(X_train[0][0])  # 3 input parameters per timestep\n",
        "\n",
        "\n",
        "# LSTM Neural Network's internal structure\n",
        "# n_hidden = 32 # Hidden layer num of features\n",
        "n_classes = 6 # Total classes (should go up, or should go down)\n",
        "\n",
        "\n",
        "# Training \n",
        "\n",
        "learning_rate = 0.0025\n",
        "lambda_loss_amount = 0.0015\n",
        "training_iters = training_data_count * 300  # Loop 300 times on the dataset\n",
        "batch_size = 64\n",
        "display_iter = 30000  # To show test set accuracy during training\n",
        "\n",
        "\n",
        "# Some debugging info\n",
        "\n",
        "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
        "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
        "print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
        "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")"
      ],
      "metadata": {
        "id": "-RGKAYMXYtsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70fcfb2-6b81-45e1-e95e-13f761f73d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some useful info to get an insight on dataset's shape and normalisation:\n",
            "(X shape, y shape, every X's mean, every X's standard deviation)\n",
            "(2457, 256, 3) (2457, 6) 2.882226147169298 6.897425254528976\n",
            "The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model**"
      ],
      "metadata": {
        "id": "BQoqmnSea1Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(256, return_sequences=True,input_shape=(n_steps, n_input)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.LSTM(128, return_sequences=True))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.LSTM(64, return_sequences=True))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.LSTM(32))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(6, activation='softmax'))\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(X_train,y_train,batch_size=64,epochs=10000,validation_split=0.1,callbacks=[callback])\n",
        "\n",
        "model.save('/Users/wangshiyu/Desktop/lstm_model')"
      ],
      "metadata": {
        "id": "jvsEG8SRfxxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e62133-8ce3-4bbb-cf80-673af8522747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "81/81 [==============================] - 11s 72ms/step - loss: 0.9979 - accuracy: 0.6649 - val_loss: 0.9254 - val_accuracy: 0.7213\n",
            "Epoch 2/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.8154 - accuracy: 0.7089 - val_loss: 0.8477 - val_accuracy: 0.7352\n",
            "Epoch 3/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.9702 - accuracy: 0.6792 - val_loss: 0.7298 - val_accuracy: 0.7509\n",
            "Epoch 4/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.7562 - accuracy: 0.7327 - val_loss: 0.6722 - val_accuracy: 0.7456\n",
            "Epoch 5/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.6259 - accuracy: 0.7775 - val_loss: 0.5434 - val_accuracy: 0.8014\n",
            "Epoch 6/10000\n",
            "81/81 [==============================] - 5s 59ms/step - loss: 0.6231 - accuracy: 0.7790 - val_loss: 0.5295 - val_accuracy: 0.8136\n",
            "Epoch 7/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.5887 - accuracy: 0.7953 - val_loss: 0.5154 - val_accuracy: 0.8171\n",
            "Epoch 8/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.5099 - accuracy: 0.8108 - val_loss: 0.5173 - val_accuracy: 0.8101\n",
            "Epoch 9/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.4479 - accuracy: 0.8306 - val_loss: 0.3920 - val_accuracy: 0.8397\n",
            "Epoch 10/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.4246 - accuracy: 0.8380 - val_loss: 0.4547 - val_accuracy: 0.8240\n",
            "Epoch 11/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.4170 - accuracy: 0.8345 - val_loss: 0.4727 - val_accuracy: 0.8345\n",
            "Epoch 12/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.4112 - accuracy: 0.8463 - val_loss: 0.4606 - val_accuracy: 0.8519\n",
            "Epoch 13/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.3874 - accuracy: 0.8465 - val_loss: 0.4112 - val_accuracy: 0.8467\n",
            "Epoch 14/10000\n",
            "81/81 [==============================] - 5s 56ms/step - loss: 0.4371 - accuracy: 0.8304 - val_loss: 0.4726 - val_accuracy: 0.8380\n",
            "Epoch 15/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.4656 - accuracy: 0.8197 - val_loss: 0.4205 - val_accuracy: 0.8380\n",
            "Epoch 16/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.3542 - accuracy: 0.8587 - val_loss: 0.2868 - val_accuracy: 0.8763\n",
            "Epoch 17/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.3122 - accuracy: 0.8701 - val_loss: 0.3000 - val_accuracy: 0.8850\n",
            "Epoch 18/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.2697 - accuracy: 0.8833 - val_loss: 0.2967 - val_accuracy: 0.8798\n",
            "Epoch 19/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.2841 - accuracy: 0.8715 - val_loss: 0.2936 - val_accuracy: 0.8833\n",
            "Epoch 20/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.2986 - accuracy: 0.8787 - val_loss: 0.3595 - val_accuracy: 0.8484\n",
            "Epoch 21/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.3276 - accuracy: 0.8721 - val_loss: 0.4801 - val_accuracy: 0.8118\n",
            "Epoch 22/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.2745 - accuracy: 0.8967 - val_loss: 0.2814 - val_accuracy: 0.8868\n",
            "Epoch 23/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.3172 - accuracy: 0.9017 - val_loss: 0.2434 - val_accuracy: 0.9077\n",
            "Epoch 24/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.2178 - accuracy: 0.9279 - val_loss: 0.2217 - val_accuracy: 0.9164\n",
            "Epoch 25/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.2230 - accuracy: 0.9207 - val_loss: 0.2652 - val_accuracy: 0.9111\n",
            "Epoch 26/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.2284 - accuracy: 0.9223 - val_loss: 0.3248 - val_accuracy: 0.8780\n",
            "Epoch 27/10000\n",
            "81/81 [==============================] - 4s 56ms/step - loss: 0.2018 - accuracy: 0.9316 - val_loss: 0.2532 - val_accuracy: 0.9059\n",
            "Epoch 28/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.1910 - accuracy: 0.9426 - val_loss: 0.1976 - val_accuracy: 0.9303\n",
            "Epoch 29/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.2008 - accuracy: 0.9368 - val_loss: 0.2711 - val_accuracy: 0.9024\n",
            "Epoch 30/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.2437 - accuracy: 0.9143 - val_loss: 0.2122 - val_accuracy: 0.9129\n",
            "Epoch 31/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.1713 - accuracy: 0.9448 - val_loss: 0.2001 - val_accuracy: 0.9303\n",
            "Epoch 32/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.2615 - accuracy: 0.9230 - val_loss: 0.3683 - val_accuracy: 0.8850\n",
            "Epoch 33/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.2742 - accuracy: 0.9106 - val_loss: 0.2421 - val_accuracy: 0.9146\n",
            "Epoch 34/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.1752 - accuracy: 0.9465 - val_loss: 0.1469 - val_accuracy: 0.9495\n",
            "Epoch 35/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.1355 - accuracy: 0.9575 - val_loss: 0.1552 - val_accuracy: 0.9460\n",
            "Epoch 36/10000\n",
            "81/81 [==============================] - 5s 56ms/step - loss: 0.2306 - accuracy: 0.9362 - val_loss: 0.1816 - val_accuracy: 0.9408\n",
            "Epoch 37/10000\n",
            "81/81 [==============================] - 5s 56ms/step - loss: 0.1701 - accuracy: 0.9548 - val_loss: 0.1521 - val_accuracy: 0.9564\n",
            "Epoch 38/10000\n",
            "81/81 [==============================] - 4s 56ms/step - loss: 0.1165 - accuracy: 0.9674 - val_loss: 0.1309 - val_accuracy: 0.9547\n",
            "Epoch 39/10000\n",
            "81/81 [==============================] - 5s 56ms/step - loss: 0.0980 - accuracy: 0.9742 - val_loss: 0.1402 - val_accuracy: 0.9547\n",
            "Epoch 40/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.0944 - accuracy: 0.9756 - val_loss: 0.1640 - val_accuracy: 0.9495\n",
            "Epoch 41/10000\n",
            "81/81 [==============================] - 5s 56ms/step - loss: 0.1004 - accuracy: 0.9711 - val_loss: 0.1196 - val_accuracy: 0.9599\n",
            "Epoch 42/10000\n",
            "81/81 [==============================] - 5s 56ms/step - loss: 0.1190 - accuracy: 0.9672 - val_loss: 0.1884 - val_accuracy: 0.9425\n",
            "Epoch 43/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.2432 - accuracy: 0.9277 - val_loss: 0.1830 - val_accuracy: 0.9390\n",
            "Epoch 44/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.1196 - accuracy: 0.9651 - val_loss: 0.1871 - val_accuracy: 0.9547\n",
            "Epoch 45/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.1041 - accuracy: 0.9696 - val_loss: 0.1387 - val_accuracy: 0.9564\n",
            "Epoch 46/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.1085 - accuracy: 0.9663 - val_loss: 0.1458 - val_accuracy: 0.9617\n",
            "Epoch 47/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.0944 - accuracy: 0.9719 - val_loss: 0.1194 - val_accuracy: 0.9721\n",
            "Epoch 48/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.1236 - accuracy: 0.9643 - val_loss: 0.1169 - val_accuracy: 0.9669\n",
            "Epoch 49/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.1005 - accuracy: 0.9700 - val_loss: 0.1017 - val_accuracy: 0.9599\n",
            "Epoch 50/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.0787 - accuracy: 0.9800 - val_loss: 0.1056 - val_accuracy: 0.9634\n",
            "Epoch 51/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.0711 - accuracy: 0.9812 - val_loss: 0.1604 - val_accuracy: 0.9599\n",
            "Epoch 52/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.0742 - accuracy: 0.9793 - val_loss: 0.1145 - val_accuracy: 0.9652\n",
            "Epoch 53/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.0889 - accuracy: 0.9744 - val_loss: 0.2069 - val_accuracy: 0.9373\n",
            "Epoch 54/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.0932 - accuracy: 0.9750 - val_loss: 0.1042 - val_accuracy: 0.9739\n",
            "Epoch 55/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.0627 - accuracy: 0.9833 - val_loss: 0.0999 - val_accuracy: 0.9721\n",
            "Epoch 56/10000\n",
            "81/81 [==============================] - 4s 53ms/step - loss: 0.0752 - accuracy: 0.9787 - val_loss: 0.1051 - val_accuracy: 0.9634\n",
            "Epoch 57/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.0621 - accuracy: 0.9822 - val_loss: 0.0979 - val_accuracy: 0.9652\n",
            "Epoch 58/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.0425 - accuracy: 0.9886 - val_loss: 0.0811 - val_accuracy: 0.9721\n",
            "Epoch 59/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.0450 - accuracy: 0.9874 - val_loss: 0.0766 - val_accuracy: 0.9791\n",
            "Epoch 60/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.1173 - accuracy: 0.9701 - val_loss: 0.1997 - val_accuracy: 0.9460\n",
            "Epoch 61/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.3095 - accuracy: 0.8980 - val_loss: 0.1588 - val_accuracy: 0.9443\n",
            "Epoch 62/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.1404 - accuracy: 0.9558 - val_loss: 0.1210 - val_accuracy: 0.9547\n",
            "Epoch 63/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.1064 - accuracy: 0.9674 - val_loss: 0.0895 - val_accuracy: 0.9686\n",
            "Epoch 64/10000\n",
            "81/81 [==============================] - 4s 54ms/step - loss: 0.0973 - accuracy: 0.9725 - val_loss: 0.1207 - val_accuracy: 0.9669\n",
            "Epoch 65/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.1109 - accuracy: 0.9692 - val_loss: 0.1391 - val_accuracy: 0.9564\n",
            "Epoch 66/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.0851 - accuracy: 0.9736 - val_loss: 0.1279 - val_accuracy: 0.9512\n",
            "Epoch 67/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.0679 - accuracy: 0.9791 - val_loss: 0.1136 - val_accuracy: 0.9652\n",
            "Epoch 68/10000\n",
            "81/81 [==============================] - 4s 55ms/step - loss: 0.0581 - accuracy: 0.9818 - val_loss: 0.0940 - val_accuracy: 0.9721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses, lstm_cell_18_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilASkF_HL7wd",
        "outputId": "d2750958-019e-4316-f6b8-25eda10dd79c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77/77 [==============================] - 2s 22ms/step - loss: 0.1227 - accuracy: 0.9666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1227295771241188, 0.966625988483429]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ]
}