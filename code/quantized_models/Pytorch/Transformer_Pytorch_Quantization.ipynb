{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fee4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2738544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_metrics_base(model, x_test, y_test, model_path):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of the PyTorch model.\n",
    "\n",
    "    :param model: PyTorch model.\n",
    "    :param x_test: Test dataset features (as a PyTorch Tensor).\n",
    "    :param y_test: Test dataset labels (as a NumPy array).\n",
    "    :param model_dir: Directory where the PyTorch model files are stored.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get the model's predictions\n",
    "        outputs = model(x_test)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "\n",
    "        # Convert y_test to tensor if it's not already\n",
    "        true_labels = torch.tensor(y_test) if not isinstance(y_test, torch.Tensor) else y_test\n",
    "        true_labels = true_labels.squeeze()  # Remove unnecessary dimensions\n",
    "\n",
    "    model_file = Path(model_path)\n",
    "\n",
    "    # Size in bytes\n",
    "    model_size_bytes = model_file.stat().st_size\n",
    "\n",
    "    # Convert size to kilobytes (optional)\n",
    "    model_size_kb = model_size_bytes / 1024\n",
    "    print(f\"Size of the model: {model_size_kb:.2f} KB\")\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels.numpy(), predicted_labels.numpy())\n",
    "    print(f'Accuracy on the test set: {accuracy:.2%}')\n",
    "def measure_cpu_utilization_and_run(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Measure CPU utilization while running a function.\n",
    "\n",
    "    Parameters:\n",
    "        func (function): The function to be executed.\n",
    "        *args: Arguments to be passed to func.\n",
    "        **kwargs: Keyword arguments to be passed to func.\n",
    "\n",
    "    Returns:\n",
    "        float: CPU utilization percentage during the execution of func.\n",
    "        float: The elapsed time during the execution of func.\n",
    "        any: The result of func execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Measure CPU utilization before execution\n",
    "    cpu_percent_before = psutil.cpu_percent(interval=None)\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Execute the function and store its result\n",
    "    result = func(*args, **kwargs)\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Measure CPU utilization after execution\n",
    "    cpu_percent_after = psutil.cpu_percent(interval=None)\n",
    "\n",
    "    # Calculate elapsed time and average CPU utilization\n",
    "    elapsed_time = end_time - start_time\n",
    "    average_cpu_utilization = (cpu_percent_before + cpu_percent_after) / 2\n",
    "\n",
    "    return average_cpu_utilization, elapsed_time, result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15c2ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x = genfromtxt('../Data/WISDM_x.csv', delimiter=',')\n",
    "y_df = pd.read_csv('../Data/WISDM_y.csv')\n",
    "y = y_df.values.flatten()  # Flatten if y is 2D\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Function to create time series dataset\n",
    "def create_series(x, y, timestep, overlap):\n",
    "    slide_step = int(timestep * (1 - overlap))\n",
    "    data_num = int((len(x) / slide_step) - 1)\n",
    "    dataset = np.ndarray(shape=(data_num, timestep, x.shape[1]))\n",
    "    labels = []\n",
    "\n",
    "    for i in range(data_num):\n",
    "        labels.append(y[slide_step * (i + 1) - 1])\n",
    "        for j in range(timestep):\n",
    "            dataset[i, j, :] = x[slide_step * i + j, :]\n",
    "\n",
    "    return dataset, np.array(labels)\n",
    "\n",
    "# Create time series\n",
    "timestep = 16  # Replace with your value\n",
    "overlap = 0.5  # Replace with your value\n",
    "X_series, y_series = create_series(x, y_encoded, timestep, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7842f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(109820, 16, 3), X_test shape:(27455, 16, 3), y_train shape:(109820,), y_test shape:(27455,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_series, y_series, test_size=0.2, random_state=42)\n",
    "print(f'X_train shape:{X_train.shape}, X_test shape:{X_test.shape}, y_train shape:{y_train.shape}, y_test shape:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c86d475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64)  # Assuming y_train is already encoded as class indexes\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3d9c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56b1440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Transformer model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, head_size, n_heads, ff_dim, dropout=0.0):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=input_dim, num_heads=n_heads, dropout=dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=ff_dim, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=ff_dim, out_channels=input_dim, kernel_size=1)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # LayerNorm and Multi-head Attention\n",
    "        x = self.norm1(src)\n",
    "        x, _ = self.attention(x, x, x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x + src  # skip connection\n",
    "\n",
    "        # Feed Forward\n",
    "        x = self.norm2(x)\n",
    "        x = x.permute(1, 2, 0)  # Conv1D expects (batch_size, channels, length)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.permute(2, 0, 1)  # back to (length, batch_size, channels)\n",
    "        x = x + src  # skip connection\n",
    "        return x\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, sequence_length, num_features, head_size, n_heads, ff_dim, n_trans_blocks, mlp_units, drop=0.0, mlp_drop=0.0):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.encoders = nn.ModuleList([TransformerEncoderBlock(num_features, head_size, n_heads, ff_dim, drop) for _ in range(n_trans_blocks)])\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        mlp_layers = []\n",
    "        current_dim = num_features\n",
    "        for dim in mlp_units:\n",
    "            mlp_layers.append(nn.Linear(current_dim, dim))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(mlp_drop))\n",
    "            current_dim = dim  # Set input dim for the next layer\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        self.final_layer = nn.Linear(mlp_units[-1], 6)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = src.permute(1, 0, 2)  # Transformer expects (seq_len, batch_size, features)\n",
    "        for encoder in self.encoders:\n",
    "            src = encoder(src)\n",
    "\n",
    "        # Global average pooling\n",
    "        src = src.permute(1, 2, 0)  # pooling expects (batch_size, channels, length)\n",
    "        src = self.global_avg_pooling(src)\n",
    "        src = torch.flatten(src, 1)  # Flatten the output for the MLP\n",
    "\n",
    "        # MLP\n",
    "        src = self.mlp(src)\n",
    "        output = self.final_layer(src)\n",
    "        return output\n",
    "\n",
    "# Input parameters for your data\n",
    "sequence_length = 16  # The length of the time series sequences in your data\n",
    "num_features = 3     # The number of features in each time step of your data sequence\n",
    "\n",
    "# Instantiate the model\n",
    "# Instantiate the model with an adjusted number of heads and head size\n",
    "# The head size must be a multiple of num_features.\n",
    "model = TimeSeriesTransformer(\n",
    "    sequence_length=16, \n",
    "    num_features=3, \n",
    "    head_size=3,  # Each head will now have an embed size of 1 (3 / 3)\n",
    "    n_heads=1,  # Only one head since our embed_dim is 3\n",
    "    ff_dim=64, \n",
    "    n_trans_blocks=4, \n",
    "    mlp_units=[128, 64], \n",
    "    drop=0.1, \n",
    "    mlp_drop=0.1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bde95e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformer(\n",
       "  (encoders): ModuleList(\n",
       "    (0-3): 4 x TransformerEncoderBlock(\n",
       "      (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 3, kernel_size=(1,), stride=(1,))\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (global_avg_pooling): AdaptiveAvgPool1d(output_size=1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=64, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ab86147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/3432], Loss: 1.3302, Accuracy: 51.56%\n",
      "Epoch [1/10], Step [200/3432], Loss: 1.1653, Accuracy: 60.38%\n",
      "Epoch [1/10], Step [300/3432], Loss: 1.0615, Accuracy: 64.03%\n",
      "Epoch [1/10], Step [400/3432], Loss: 0.9988, Accuracy: 66.81%\n",
      "Epoch [1/10], Step [500/3432], Loss: 0.9809, Accuracy: 67.59%\n",
      "Epoch [1/10], Step [600/3432], Loss: 0.9121, Accuracy: 70.28%\n",
      "Epoch [1/10], Step [700/3432], Loss: 0.9297, Accuracy: 69.72%\n",
      "Epoch [1/10], Step [800/3432], Loss: 0.9169, Accuracy: 69.94%\n",
      "Epoch [1/10], Step [900/3432], Loss: 0.9201, Accuracy: 70.03%\n",
      "Epoch [1/10], Step [1000/3432], Loss: 0.9044, Accuracy: 70.38%\n",
      "Epoch [1/10], Step [1100/3432], Loss: 0.8885, Accuracy: 69.81%\n",
      "Epoch [1/10], Step [1200/3432], Loss: 0.8673, Accuracy: 70.41%\n",
      "Epoch [1/10], Step [1300/3432], Loss: 0.8268, Accuracy: 72.53%\n",
      "Epoch [1/10], Step [1400/3432], Loss: 0.8236, Accuracy: 72.16%\n",
      "Epoch [1/10], Step [1500/3432], Loss: 0.7972, Accuracy: 73.91%\n",
      "Epoch [1/10], Step [1600/3432], Loss: 0.8121, Accuracy: 72.50%\n",
      "Epoch [1/10], Step [1700/3432], Loss: 0.7769, Accuracy: 74.12%\n",
      "Epoch [1/10], Step [1800/3432], Loss: 0.7629, Accuracy: 73.97%\n",
      "Epoch [1/10], Step [1900/3432], Loss: 0.7559, Accuracy: 74.59%\n",
      "Epoch [1/10], Step [2000/3432], Loss: 0.7927, Accuracy: 73.62%\n",
      "Epoch [1/10], Step [2100/3432], Loss: 0.7463, Accuracy: 74.50%\n",
      "Epoch [1/10], Step [2200/3432], Loss: 0.7114, Accuracy: 75.72%\n",
      "Epoch [1/10], Step [2300/3432], Loss: 0.7364, Accuracy: 74.91%\n",
      "Epoch [1/10], Step [2400/3432], Loss: 0.7362, Accuracy: 75.53%\n",
      "Epoch [1/10], Step [2500/3432], Loss: 0.6942, Accuracy: 76.72%\n",
      "Epoch [1/10], Step [2600/3432], Loss: 0.7222, Accuracy: 75.47%\n",
      "Epoch [1/10], Step [2700/3432], Loss: 0.7043, Accuracy: 76.69%\n",
      "Epoch [1/10], Step [2800/3432], Loss: 0.7304, Accuracy: 75.78%\n",
      "Epoch [1/10], Step [2900/3432], Loss: 0.7309, Accuracy: 74.78%\n",
      "Epoch [1/10], Step [3000/3432], Loss: 0.6849, Accuracy: 77.16%\n",
      "Epoch [1/10], Step [3100/3432], Loss: 0.7353, Accuracy: 74.72%\n",
      "Epoch [1/10], Step [3200/3432], Loss: 0.7263, Accuracy: 74.62%\n",
      "Epoch [1/10], Step [3300/3432], Loss: 0.6988, Accuracy: 76.28%\n",
      "Epoch [1/10], Step [3400/3432], Loss: 0.6987, Accuracy: 76.25%\n",
      "Epoch [2/10], Step [100/3432], Loss: 0.7043, Accuracy: 75.94%\n",
      "Epoch [2/10], Step [200/3432], Loss: 0.6955, Accuracy: 76.41%\n",
      "Epoch [2/10], Step [300/3432], Loss: 0.7019, Accuracy: 75.66%\n",
      "Epoch [2/10], Step [400/3432], Loss: 0.7232, Accuracy: 75.25%\n",
      "Epoch [2/10], Step [500/3432], Loss: 0.6955, Accuracy: 75.78%\n",
      "Epoch [2/10], Step [600/3432], Loss: 0.7002, Accuracy: 75.91%\n",
      "Epoch [2/10], Step [700/3432], Loss: 0.6766, Accuracy: 76.50%\n",
      "Epoch [2/10], Step [800/3432], Loss: 0.6716, Accuracy: 77.22%\n",
      "Epoch [2/10], Step [900/3432], Loss: 0.6652, Accuracy: 76.56%\n",
      "Epoch [2/10], Step [1000/3432], Loss: 0.6644, Accuracy: 77.38%\n",
      "Epoch [2/10], Step [1100/3432], Loss: 0.6614, Accuracy: 77.28%\n",
      "Epoch [2/10], Step [1200/3432], Loss: 0.6679, Accuracy: 77.41%\n",
      "Epoch [2/10], Step [1300/3432], Loss: 0.6680, Accuracy: 76.72%\n",
      "Epoch [2/10], Step [1400/3432], Loss: 0.6466, Accuracy: 77.56%\n",
      "Epoch [2/10], Step [1500/3432], Loss: 0.6729, Accuracy: 76.44%\n",
      "Epoch [2/10], Step [1600/3432], Loss: 0.6984, Accuracy: 75.88%\n",
      "Epoch [2/10], Step [1700/3432], Loss: 0.6478, Accuracy: 77.69%\n",
      "Epoch [2/10], Step [1800/3432], Loss: 0.6678, Accuracy: 77.09%\n",
      "Epoch [2/10], Step [1900/3432], Loss: 0.6381, Accuracy: 78.09%\n",
      "Epoch [2/10], Step [2000/3432], Loss: 0.6339, Accuracy: 77.47%\n",
      "Epoch [2/10], Step [2100/3432], Loss: 0.6346, Accuracy: 77.84%\n",
      "Epoch [2/10], Step [2200/3432], Loss: 0.6569, Accuracy: 77.38%\n",
      "Epoch [2/10], Step [2300/3432], Loss: 0.6521, Accuracy: 77.06%\n",
      "Epoch [2/10], Step [2400/3432], Loss: 0.6333, Accuracy: 78.19%\n",
      "Epoch [2/10], Step [2500/3432], Loss: 0.6696, Accuracy: 76.50%\n",
      "Epoch [2/10], Step [2600/3432], Loss: 0.6811, Accuracy: 76.19%\n",
      "Epoch [2/10], Step [2700/3432], Loss: 0.6665, Accuracy: 76.97%\n",
      "Epoch [2/10], Step [2800/3432], Loss: 0.6341, Accuracy: 77.94%\n",
      "Epoch [2/10], Step [2900/3432], Loss: 0.6289, Accuracy: 78.38%\n",
      "Epoch [2/10], Step [3000/3432], Loss: 0.6452, Accuracy: 77.91%\n",
      "Epoch [2/10], Step [3100/3432], Loss: 0.6438, Accuracy: 78.00%\n",
      "Epoch [2/10], Step [3200/3432], Loss: 0.6558, Accuracy: 77.97%\n",
      "Epoch [2/10], Step [3300/3432], Loss: 0.6285, Accuracy: 78.25%\n",
      "Epoch [2/10], Step [3400/3432], Loss: 0.6565, Accuracy: 77.28%\n",
      "Epoch [3/10], Step [100/3432], Loss: 0.6642, Accuracy: 77.06%\n",
      "Epoch [3/10], Step [200/3432], Loss: 0.6789, Accuracy: 76.38%\n",
      "Epoch [3/10], Step [300/3432], Loss: 0.6503, Accuracy: 77.38%\n",
      "Epoch [3/10], Step [400/3432], Loss: 0.6550, Accuracy: 77.78%\n",
      "Epoch [3/10], Step [500/3432], Loss: 0.6455, Accuracy: 77.62%\n",
      "Epoch [3/10], Step [600/3432], Loss: 0.6514, Accuracy: 78.03%\n",
      "Epoch [3/10], Step [700/3432], Loss: 0.6449, Accuracy: 77.69%\n",
      "Epoch [3/10], Step [800/3432], Loss: 0.6664, Accuracy: 76.44%\n",
      "Epoch [3/10], Step [900/3432], Loss: 0.6446, Accuracy: 77.81%\n",
      "Epoch [3/10], Step [1000/3432], Loss: 0.6303, Accuracy: 78.47%\n",
      "Epoch [3/10], Step [1100/3432], Loss: 0.6325, Accuracy: 77.84%\n",
      "Epoch [3/10], Step [1200/3432], Loss: 0.6227, Accuracy: 78.75%\n",
      "Epoch [3/10], Step [1300/3432], Loss: 0.6352, Accuracy: 78.91%\n",
      "Epoch [3/10], Step [1400/3432], Loss: 0.6483, Accuracy: 78.25%\n",
      "Epoch [3/10], Step [1500/3432], Loss: 0.6576, Accuracy: 77.81%\n",
      "Epoch [3/10], Step [1600/3432], Loss: 0.6423, Accuracy: 77.84%\n",
      "Epoch [3/10], Step [1700/3432], Loss: 0.6433, Accuracy: 78.16%\n",
      "Epoch [3/10], Step [1800/3432], Loss: 0.6599, Accuracy: 77.16%\n",
      "Epoch [3/10], Step [1900/3432], Loss: 0.6506, Accuracy: 77.41%\n",
      "Epoch [3/10], Step [2000/3432], Loss: 0.6644, Accuracy: 76.53%\n",
      "Epoch [3/10], Step [2100/3432], Loss: 0.6441, Accuracy: 78.03%\n",
      "Epoch [3/10], Step [2200/3432], Loss: 0.6412, Accuracy: 78.75%\n",
      "Epoch [3/10], Step [2300/3432], Loss: 0.6538, Accuracy: 77.47%\n",
      "Epoch [3/10], Step [2400/3432], Loss: 0.6232, Accuracy: 77.91%\n",
      "Epoch [3/10], Step [2500/3432], Loss: 0.6442, Accuracy: 77.78%\n",
      "Epoch [3/10], Step [2600/3432], Loss: 0.6184, Accuracy: 78.41%\n",
      "Epoch [3/10], Step [2700/3432], Loss: 0.6244, Accuracy: 77.94%\n",
      "Epoch [3/10], Step [2800/3432], Loss: 0.6401, Accuracy: 77.28%\n",
      "Epoch [3/10], Step [2900/3432], Loss: 0.6572, Accuracy: 77.72%\n",
      "Epoch [3/10], Step [3000/3432], Loss: 0.6422, Accuracy: 77.91%\n",
      "Epoch [3/10], Step [3100/3432], Loss: 0.6193, Accuracy: 78.53%\n",
      "Epoch [3/10], Step [3200/3432], Loss: 0.6375, Accuracy: 77.91%\n",
      "Epoch [3/10], Step [3300/3432], Loss: 0.6046, Accuracy: 79.34%\n",
      "Epoch [3/10], Step [3400/3432], Loss: 0.6012, Accuracy: 79.62%\n",
      "Epoch [4/10], Step [100/3432], Loss: 0.6002, Accuracy: 80.12%\n",
      "Epoch [4/10], Step [200/3432], Loss: 0.6492, Accuracy: 76.69%\n",
      "Epoch [4/10], Step [300/3432], Loss: 0.6093, Accuracy: 79.16%\n",
      "Epoch [4/10], Step [400/3432], Loss: 0.6449, Accuracy: 77.78%\n",
      "Epoch [4/10], Step [500/3432], Loss: 0.6134, Accuracy: 78.50%\n",
      "Epoch [4/10], Step [600/3432], Loss: 0.6327, Accuracy: 78.34%\n",
      "Epoch [4/10], Step [700/3432], Loss: 0.6389, Accuracy: 78.00%\n",
      "Epoch [4/10], Step [800/3432], Loss: 0.6468, Accuracy: 77.94%\n",
      "Epoch [4/10], Step [900/3432], Loss: 0.6315, Accuracy: 78.72%\n",
      "Epoch [4/10], Step [1000/3432], Loss: 0.6202, Accuracy: 79.06%\n",
      "Epoch [4/10], Step [1100/3432], Loss: 0.6181, Accuracy: 78.25%\n",
      "Epoch [4/10], Step [1200/3432], Loss: 0.6067, Accuracy: 79.84%\n",
      "Epoch [4/10], Step [1300/3432], Loss: 0.6220, Accuracy: 78.47%\n",
      "Epoch [4/10], Step [1400/3432], Loss: 0.6315, Accuracy: 77.62%\n",
      "Epoch [4/10], Step [1500/3432], Loss: 0.6305, Accuracy: 78.09%\n",
      "Epoch [4/10], Step [1600/3432], Loss: 0.6231, Accuracy: 78.62%\n",
      "Epoch [4/10], Step [1700/3432], Loss: 0.6360, Accuracy: 78.28%\n",
      "Epoch [4/10], Step [1800/3432], Loss: 0.6460, Accuracy: 77.91%\n",
      "Epoch [4/10], Step [1900/3432], Loss: 0.5973, Accuracy: 79.75%\n",
      "Epoch [4/10], Step [2000/3432], Loss: 0.6036, Accuracy: 79.25%\n",
      "Epoch [4/10], Step [2100/3432], Loss: 0.5788, Accuracy: 79.91%\n",
      "Epoch [4/10], Step [2200/3432], Loss: 0.5920, Accuracy: 79.75%\n",
      "Epoch [4/10], Step [2300/3432], Loss: 0.6058, Accuracy: 78.88%\n",
      "Epoch [4/10], Step [2400/3432], Loss: 0.6098, Accuracy: 79.03%\n",
      "Epoch [4/10], Step [2500/3432], Loss: 0.6255, Accuracy: 78.72%\n",
      "Epoch [4/10], Step [2600/3432], Loss: 0.6005, Accuracy: 79.06%\n",
      "Epoch [4/10], Step [2700/3432], Loss: 0.5769, Accuracy: 80.22%\n",
      "Epoch [4/10], Step [2800/3432], Loss: 0.5931, Accuracy: 79.91%\n",
      "Epoch [4/10], Step [2900/3432], Loss: 0.5947, Accuracy: 79.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [3000/3432], Loss: 0.6106, Accuracy: 78.88%\n",
      "Epoch [4/10], Step [3100/3432], Loss: 0.5692, Accuracy: 80.41%\n",
      "Epoch [4/10], Step [3200/3432], Loss: 0.6426, Accuracy: 77.88%\n",
      "Epoch [4/10], Step [3300/3432], Loss: 0.6078, Accuracy: 79.09%\n",
      "Epoch [4/10], Step [3400/3432], Loss: 0.6007, Accuracy: 79.75%\n",
      "Epoch [5/10], Step [100/3432], Loss: 0.5866, Accuracy: 80.16%\n",
      "Epoch [5/10], Step [200/3432], Loss: 0.6032, Accuracy: 79.19%\n",
      "Epoch [5/10], Step [300/3432], Loss: 0.5804, Accuracy: 80.19%\n",
      "Epoch [5/10], Step [400/3432], Loss: 0.5997, Accuracy: 78.97%\n",
      "Epoch [5/10], Step [500/3432], Loss: 0.6207, Accuracy: 78.59%\n",
      "Epoch [5/10], Step [600/3432], Loss: 0.6047, Accuracy: 78.44%\n",
      "Epoch [5/10], Step [700/3432], Loss: 0.6024, Accuracy: 78.91%\n",
      "Epoch [5/10], Step [800/3432], Loss: 0.6067, Accuracy: 78.12%\n",
      "Epoch [5/10], Step [900/3432], Loss: 0.5876, Accuracy: 78.41%\n",
      "Epoch [5/10], Step [1000/3432], Loss: 0.6022, Accuracy: 79.03%\n",
      "Epoch [5/10], Step [1100/3432], Loss: 0.6194, Accuracy: 78.59%\n",
      "Epoch [5/10], Step [1200/3432], Loss: 0.6086, Accuracy: 78.91%\n",
      "Epoch [5/10], Step [1300/3432], Loss: 0.6260, Accuracy: 77.97%\n",
      "Epoch [5/10], Step [1400/3432], Loss: 0.5947, Accuracy: 79.59%\n",
      "Epoch [5/10], Step [1500/3432], Loss: 0.6225, Accuracy: 78.41%\n",
      "Epoch [5/10], Step [1600/3432], Loss: 0.6067, Accuracy: 79.34%\n",
      "Epoch [5/10], Step [1700/3432], Loss: 0.5764, Accuracy: 80.84%\n",
      "Epoch [5/10], Step [1800/3432], Loss: 0.5800, Accuracy: 79.53%\n",
      "Epoch [5/10], Step [1900/3432], Loss: 0.5959, Accuracy: 79.69%\n",
      "Epoch [5/10], Step [2000/3432], Loss: 0.5983, Accuracy: 79.06%\n",
      "Epoch [5/10], Step [2100/3432], Loss: 0.5800, Accuracy: 79.75%\n",
      "Epoch [5/10], Step [2200/3432], Loss: 0.5872, Accuracy: 80.28%\n",
      "Epoch [5/10], Step [2300/3432], Loss: 0.5898, Accuracy: 79.03%\n",
      "Epoch [5/10], Step [2400/3432], Loss: 0.5976, Accuracy: 79.50%\n",
      "Epoch [5/10], Step [2500/3432], Loss: 0.6070, Accuracy: 79.06%\n",
      "Epoch [5/10], Step [2600/3432], Loss: 0.5444, Accuracy: 81.34%\n",
      "Epoch [5/10], Step [2700/3432], Loss: 0.6131, Accuracy: 79.03%\n",
      "Epoch [5/10], Step [2800/3432], Loss: 0.6173, Accuracy: 78.91%\n",
      "Epoch [5/10], Step [2900/3432], Loss: 0.5896, Accuracy: 79.09%\n",
      "Epoch [5/10], Step [3000/3432], Loss: 0.5880, Accuracy: 79.75%\n",
      "Epoch [5/10], Step [3100/3432], Loss: 0.5946, Accuracy: 79.44%\n",
      "Epoch [5/10], Step [3200/3432], Loss: 0.6012, Accuracy: 78.78%\n",
      "Epoch [5/10], Step [3300/3432], Loss: 0.6234, Accuracy: 78.84%\n",
      "Epoch [5/10], Step [3400/3432], Loss: 0.5979, Accuracy: 79.44%\n",
      "Epoch [6/10], Step [100/3432], Loss: 0.5729, Accuracy: 80.31%\n",
      "Epoch [6/10], Step [200/3432], Loss: 0.6121, Accuracy: 78.94%\n",
      "Epoch [6/10], Step [300/3432], Loss: 0.5862, Accuracy: 79.94%\n",
      "Epoch [6/10], Step [400/3432], Loss: 0.5861, Accuracy: 79.38%\n",
      "Epoch [6/10], Step [500/3432], Loss: 0.6028, Accuracy: 79.94%\n",
      "Epoch [6/10], Step [600/3432], Loss: 0.6025, Accuracy: 79.47%\n",
      "Epoch [6/10], Step [700/3432], Loss: 0.5893, Accuracy: 80.41%\n",
      "Epoch [6/10], Step [800/3432], Loss: 0.5713, Accuracy: 80.12%\n",
      "Epoch [6/10], Step [900/3432], Loss: 0.5992, Accuracy: 78.72%\n",
      "Epoch [6/10], Step [1000/3432], Loss: 0.6013, Accuracy: 79.94%\n",
      "Epoch [6/10], Step [1100/3432], Loss: 0.5795, Accuracy: 79.53%\n",
      "Epoch [6/10], Step [1200/3432], Loss: 0.5887, Accuracy: 79.38%\n",
      "Epoch [6/10], Step [1300/3432], Loss: 0.5921, Accuracy: 79.66%\n",
      "Epoch [6/10], Step [1400/3432], Loss: 0.5527, Accuracy: 81.00%\n",
      "Epoch [6/10], Step [1500/3432], Loss: 0.5844, Accuracy: 80.00%\n",
      "Epoch [6/10], Step [1600/3432], Loss: 0.5938, Accuracy: 79.03%\n",
      "Epoch [6/10], Step [1700/3432], Loss: 0.6007, Accuracy: 79.47%\n",
      "Epoch [6/10], Step [1800/3432], Loss: 0.5989, Accuracy: 78.62%\n",
      "Epoch [6/10], Step [1900/3432], Loss: 0.5739, Accuracy: 79.94%\n",
      "Epoch [6/10], Step [2000/3432], Loss: 0.6144, Accuracy: 79.19%\n",
      "Epoch [6/10], Step [2100/3432], Loss: 0.6110, Accuracy: 78.94%\n",
      "Epoch [6/10], Step [2200/3432], Loss: 0.5800, Accuracy: 80.06%\n",
      "Epoch [6/10], Step [2300/3432], Loss: 0.5931, Accuracy: 79.59%\n",
      "Epoch [6/10], Step [2400/3432], Loss: 0.6033, Accuracy: 78.97%\n",
      "Epoch [6/10], Step [2500/3432], Loss: 0.6024, Accuracy: 78.62%\n",
      "Epoch [6/10], Step [2600/3432], Loss: 0.6201, Accuracy: 79.56%\n",
      "Epoch [6/10], Step [2700/3432], Loss: 0.5802, Accuracy: 80.06%\n",
      "Epoch [6/10], Step [2800/3432], Loss: 0.5796, Accuracy: 80.19%\n",
      "Epoch [6/10], Step [2900/3432], Loss: 0.5784, Accuracy: 79.84%\n",
      "Epoch [6/10], Step [3000/3432], Loss: 0.5890, Accuracy: 79.75%\n",
      "Epoch [6/10], Step [3100/3432], Loss: 0.5944, Accuracy: 79.50%\n",
      "Epoch [6/10], Step [3200/3432], Loss: 0.5875, Accuracy: 78.97%\n",
      "Epoch [6/10], Step [3300/3432], Loss: 0.6074, Accuracy: 79.16%\n",
      "Epoch [6/10], Step [3400/3432], Loss: 0.5895, Accuracy: 80.12%\n",
      "Epoch [7/10], Step [100/3432], Loss: 0.5651, Accuracy: 80.47%\n",
      "Epoch [7/10], Step [200/3432], Loss: 0.5642, Accuracy: 80.44%\n",
      "Epoch [7/10], Step [300/3432], Loss: 0.6027, Accuracy: 79.12%\n",
      "Epoch [7/10], Step [400/3432], Loss: 0.5601, Accuracy: 81.25%\n",
      "Epoch [7/10], Step [500/3432], Loss: 0.5590, Accuracy: 80.28%\n",
      "Epoch [7/10], Step [600/3432], Loss: 0.5621, Accuracy: 80.59%\n",
      "Epoch [7/10], Step [700/3432], Loss: 0.5833, Accuracy: 79.66%\n",
      "Epoch [7/10], Step [800/3432], Loss: 0.5874, Accuracy: 79.41%\n",
      "Epoch [7/10], Step [900/3432], Loss: 0.6082, Accuracy: 79.22%\n",
      "Epoch [7/10], Step [1000/3432], Loss: 0.6182, Accuracy: 79.09%\n",
      "Epoch [7/10], Step [1100/3432], Loss: 0.5883, Accuracy: 79.94%\n",
      "Epoch [7/10], Step [1200/3432], Loss: 0.5909, Accuracy: 79.28%\n",
      "Epoch [7/10], Step [1300/3432], Loss: 0.5810, Accuracy: 80.28%\n",
      "Epoch [7/10], Step [1400/3432], Loss: 0.5895, Accuracy: 79.03%\n",
      "Epoch [7/10], Step [1500/3432], Loss: 0.5804, Accuracy: 80.06%\n",
      "Epoch [7/10], Step [1600/3432], Loss: 0.5905, Accuracy: 79.75%\n",
      "Epoch [7/10], Step [1700/3432], Loss: 0.5823, Accuracy: 79.81%\n",
      "Epoch [7/10], Step [1800/3432], Loss: 0.5584, Accuracy: 80.12%\n",
      "Epoch [7/10], Step [1900/3432], Loss: 0.5974, Accuracy: 79.78%\n",
      "Epoch [7/10], Step [2000/3432], Loss: 0.5809, Accuracy: 80.47%\n",
      "Epoch [7/10], Step [2100/3432], Loss: 0.5710, Accuracy: 79.72%\n",
      "Epoch [7/10], Step [2200/3432], Loss: 0.5784, Accuracy: 79.47%\n",
      "Epoch [7/10], Step [2300/3432], Loss: 0.6037, Accuracy: 78.62%\n",
      "Epoch [7/10], Step [2400/3432], Loss: 0.5712, Accuracy: 80.16%\n",
      "Epoch [7/10], Step [2500/3432], Loss: 0.5909, Accuracy: 78.22%\n",
      "Epoch [7/10], Step [2600/3432], Loss: 0.5895, Accuracy: 80.06%\n",
      "Epoch [7/10], Step [2700/3432], Loss: 0.5801, Accuracy: 80.28%\n",
      "Epoch [7/10], Step [2800/3432], Loss: 0.5803, Accuracy: 80.00%\n",
      "Epoch [7/10], Step [2900/3432], Loss: 0.5915, Accuracy: 79.22%\n",
      "Epoch [7/10], Step [3000/3432], Loss: 0.5724, Accuracy: 79.94%\n",
      "Epoch [7/10], Step [3100/3432], Loss: 0.5972, Accuracy: 79.84%\n",
      "Epoch [7/10], Step [3200/3432], Loss: 0.5699, Accuracy: 80.28%\n",
      "Epoch [7/10], Step [3300/3432], Loss: 0.5485, Accuracy: 80.88%\n",
      "Epoch [7/10], Step [3400/3432], Loss: 0.5738, Accuracy: 80.62%\n",
      "Epoch [8/10], Step [100/3432], Loss: 0.5678, Accuracy: 80.31%\n",
      "Epoch [8/10], Step [200/3432], Loss: 0.5686, Accuracy: 80.56%\n",
      "Epoch [8/10], Step [300/3432], Loss: 0.5562, Accuracy: 80.81%\n",
      "Epoch [8/10], Step [400/3432], Loss: 0.5938, Accuracy: 78.94%\n",
      "Epoch [8/10], Step [500/3432], Loss: 0.5617, Accuracy: 79.91%\n",
      "Epoch [8/10], Step [600/3432], Loss: 0.5606, Accuracy: 80.81%\n",
      "Epoch [8/10], Step [700/3432], Loss: 0.5819, Accuracy: 79.78%\n",
      "Epoch [8/10], Step [800/3432], Loss: 0.5826, Accuracy: 80.00%\n",
      "Epoch [8/10], Step [900/3432], Loss: 0.5741, Accuracy: 80.00%\n",
      "Epoch [8/10], Step [1000/3432], Loss: 0.5327, Accuracy: 81.50%\n",
      "Epoch [8/10], Step [1100/3432], Loss: 0.5704, Accuracy: 80.47%\n",
      "Epoch [8/10], Step [1200/3432], Loss: 0.5619, Accuracy: 80.06%\n",
      "Epoch [8/10], Step [1300/3432], Loss: 0.5828, Accuracy: 79.75%\n",
      "Epoch [8/10], Step [1400/3432], Loss: 0.6050, Accuracy: 78.62%\n",
      "Epoch [8/10], Step [1500/3432], Loss: 0.5649, Accuracy: 80.03%\n",
      "Epoch [8/10], Step [1600/3432], Loss: 0.5857, Accuracy: 80.25%\n",
      "Epoch [8/10], Step [1700/3432], Loss: 0.5773, Accuracy: 80.06%\n",
      "Epoch [8/10], Step [1800/3432], Loss: 0.5728, Accuracy: 80.44%\n",
      "Epoch [8/10], Step [1900/3432], Loss: 0.5880, Accuracy: 79.59%\n",
      "Epoch [8/10], Step [2000/3432], Loss: 0.5857, Accuracy: 79.78%\n",
      "Epoch [8/10], Step [2100/3432], Loss: 0.5722, Accuracy: 79.97%\n",
      "Epoch [8/10], Step [2200/3432], Loss: 0.5678, Accuracy: 80.00%\n",
      "Epoch [8/10], Step [2300/3432], Loss: 0.5821, Accuracy: 79.78%\n",
      "Epoch [8/10], Step [2400/3432], Loss: 0.6058, Accuracy: 78.56%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [2500/3432], Loss: 0.5980, Accuracy: 79.19%\n",
      "Epoch [8/10], Step [2600/3432], Loss: 0.5833, Accuracy: 79.41%\n",
      "Epoch [8/10], Step [2700/3432], Loss: 0.5848, Accuracy: 79.47%\n",
      "Epoch [8/10], Step [2800/3432], Loss: 0.5817, Accuracy: 79.59%\n",
      "Epoch [8/10], Step [2900/3432], Loss: 0.5727, Accuracy: 80.09%\n",
      "Epoch [8/10], Step [3000/3432], Loss: 0.6105, Accuracy: 78.31%\n",
      "Epoch [8/10], Step [3100/3432], Loss: 0.5757, Accuracy: 79.88%\n",
      "Epoch [8/10], Step [3200/3432], Loss: 0.5896, Accuracy: 79.66%\n",
      "Epoch [8/10], Step [3300/3432], Loss: 0.5769, Accuracy: 79.47%\n",
      "Epoch [8/10], Step [3400/3432], Loss: 0.5933, Accuracy: 79.16%\n",
      "Epoch [9/10], Step [100/3432], Loss: 0.5749, Accuracy: 80.75%\n",
      "Epoch [9/10], Step [200/3432], Loss: 0.5563, Accuracy: 81.22%\n",
      "Epoch [9/10], Step [300/3432], Loss: 0.6075, Accuracy: 79.09%\n",
      "Epoch [9/10], Step [400/3432], Loss: 0.5772, Accuracy: 79.72%\n",
      "Epoch [9/10], Step [500/3432], Loss: 0.5794, Accuracy: 79.88%\n",
      "Epoch [9/10], Step [600/3432], Loss: 0.5742, Accuracy: 79.34%\n",
      "Epoch [9/10], Step [700/3432], Loss: 0.5539, Accuracy: 80.59%\n",
      "Epoch [9/10], Step [800/3432], Loss: 0.5598, Accuracy: 80.19%\n",
      "Epoch [9/10], Step [900/3432], Loss: 0.5672, Accuracy: 80.03%\n",
      "Epoch [9/10], Step [1000/3432], Loss: 0.5746, Accuracy: 80.56%\n",
      "Epoch [9/10], Step [1100/3432], Loss: 0.5977, Accuracy: 79.31%\n",
      "Epoch [9/10], Step [1200/3432], Loss: 0.5926, Accuracy: 79.16%\n",
      "Epoch [9/10], Step [1300/3432], Loss: 0.5688, Accuracy: 80.12%\n",
      "Epoch [9/10], Step [1400/3432], Loss: 0.5378, Accuracy: 81.59%\n",
      "Epoch [9/10], Step [1500/3432], Loss: 0.5886, Accuracy: 80.00%\n",
      "Epoch [9/10], Step [1600/3432], Loss: 0.5555, Accuracy: 81.16%\n",
      "Epoch [9/10], Step [1700/3432], Loss: 0.5577, Accuracy: 80.50%\n",
      "Epoch [9/10], Step [1800/3432], Loss: 0.5923, Accuracy: 79.59%\n",
      "Epoch [9/10], Step [1900/3432], Loss: 0.5693, Accuracy: 80.53%\n",
      "Epoch [9/10], Step [2000/3432], Loss: 0.5735, Accuracy: 80.19%\n",
      "Epoch [9/10], Step [2100/3432], Loss: 0.5965, Accuracy: 78.75%\n",
      "Epoch [9/10], Step [2200/3432], Loss: 0.5498, Accuracy: 81.19%\n",
      "Epoch [9/10], Step [2300/3432], Loss: 0.5608, Accuracy: 80.75%\n",
      "Epoch [9/10], Step [2400/3432], Loss: 0.5743, Accuracy: 80.12%\n",
      "Epoch [9/10], Step [2500/3432], Loss: 0.5392, Accuracy: 81.12%\n",
      "Epoch [9/10], Step [2600/3432], Loss: 0.5473, Accuracy: 80.38%\n",
      "Epoch [9/10], Step [2700/3432], Loss: 0.5789, Accuracy: 79.91%\n",
      "Epoch [9/10], Step [2800/3432], Loss: 0.5684, Accuracy: 79.72%\n",
      "Epoch [9/10], Step [2900/3432], Loss: 0.5779, Accuracy: 79.97%\n",
      "Epoch [9/10], Step [3000/3432], Loss: 0.5972, Accuracy: 79.22%\n",
      "Epoch [9/10], Step [3100/3432], Loss: 0.5737, Accuracy: 80.12%\n",
      "Epoch [9/10], Step [3200/3432], Loss: 0.5800, Accuracy: 80.44%\n",
      "Epoch [9/10], Step [3300/3432], Loss: 0.5724, Accuracy: 79.72%\n",
      "Epoch [9/10], Step [3400/3432], Loss: 0.5760, Accuracy: 79.53%\n",
      "Epoch [10/10], Step [100/3432], Loss: 0.5478, Accuracy: 80.53%\n",
      "Epoch [10/10], Step [200/3432], Loss: 0.5633, Accuracy: 79.50%\n",
      "Epoch [10/10], Step [300/3432], Loss: 0.5743, Accuracy: 80.16%\n",
      "Epoch [10/10], Step [400/3432], Loss: 0.5545, Accuracy: 81.72%\n",
      "Epoch [10/10], Step [500/3432], Loss: 0.5782, Accuracy: 79.28%\n",
      "Epoch [10/10], Step [600/3432], Loss: 0.5667, Accuracy: 80.38%\n",
      "Epoch [10/10], Step [700/3432], Loss: 0.5860, Accuracy: 79.62%\n",
      "Epoch [10/10], Step [800/3432], Loss: 0.5621, Accuracy: 80.81%\n",
      "Epoch [10/10], Step [900/3432], Loss: 0.5856, Accuracy: 79.25%\n",
      "Epoch [10/10], Step [1000/3432], Loss: 0.5519, Accuracy: 80.81%\n",
      "Epoch [10/10], Step [1100/3432], Loss: 0.5806, Accuracy: 79.22%\n",
      "Epoch [10/10], Step [1200/3432], Loss: 0.5702, Accuracy: 80.97%\n",
      "Epoch [10/10], Step [1300/3432], Loss: 0.5628, Accuracy: 80.41%\n",
      "Epoch [10/10], Step [1400/3432], Loss: 0.5908, Accuracy: 80.06%\n",
      "Epoch [10/10], Step [1500/3432], Loss: 0.5576, Accuracy: 81.06%\n",
      "Epoch [10/10], Step [1600/3432], Loss: 0.5518, Accuracy: 81.00%\n",
      "Epoch [10/10], Step [1700/3432], Loss: 0.5613, Accuracy: 80.66%\n",
      "Epoch [10/10], Step [1800/3432], Loss: 0.5837, Accuracy: 79.72%\n",
      "Epoch [10/10], Step [1900/3432], Loss: 0.5904, Accuracy: 78.91%\n",
      "Epoch [10/10], Step [2000/3432], Loss: 0.5679, Accuracy: 80.91%\n",
      "Epoch [10/10], Step [2100/3432], Loss: 0.5477, Accuracy: 81.47%\n",
      "Epoch [10/10], Step [2200/3432], Loss: 0.5671, Accuracy: 79.78%\n",
      "Epoch [10/10], Step [2300/3432], Loss: 0.5883, Accuracy: 79.00%\n",
      "Epoch [10/10], Step [2400/3432], Loss: 0.5570, Accuracy: 81.16%\n",
      "Epoch [10/10], Step [2500/3432], Loss: 0.5578, Accuracy: 80.81%\n",
      "Epoch [10/10], Step [2600/3432], Loss: 0.5697, Accuracy: 80.47%\n",
      "Epoch [10/10], Step [2700/3432], Loss: 0.5679, Accuracy: 80.72%\n",
      "Epoch [10/10], Step [2800/3432], Loss: 0.5919, Accuracy: 78.22%\n",
      "Epoch [10/10], Step [2900/3432], Loss: 0.5836, Accuracy: 79.81%\n",
      "Epoch [10/10], Step [3000/3432], Loss: 0.5554, Accuracy: 80.47%\n",
      "Epoch [10/10], Step [3100/3432], Loss: 0.5836, Accuracy: 79.75%\n",
      "Epoch [10/10], Step [3200/3432], Loss: 0.5552, Accuracy: 81.31%\n",
      "Epoch [10/10], Step [3300/3432], Loss: 0.5467, Accuracy: 80.88%\n",
      "Epoch [10/10], Step [3400/3432], Loss: 0.5570, Accuracy: 80.78%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], '\n",
    "                  f'Loss: {running_loss / 100:.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "# After training, you may want to save your model\n",
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "365f1ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8102\n",
      "Precision: 0.7828\n",
      "Recall: 0.8102\n",
      "F1 Score: 0.7732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Collect all predictions and labels to compute overall metrics\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert collected predictions and labels to arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9cbb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfd3612c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model size is 61.19 KB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Assume 'model' is the instance of TimeSeriesTransformer you have already defined and trained\n",
    "model_path = \"/Users/sandeep/Desktop/BUCourses/Project/saved_models/Pytorch/transformer_base.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Get the size of the saved model file\n",
    "model_size = os.path.getsize(model_path)\n",
    "print(f\"The model size is {model_size/1024:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b340fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model: 61.19 KB\n",
      "Accuracy on the test set: 81.02%\n",
      "CPU usage during inference: 35.85%\n",
      "Inference time: 1.5647 seconds\n"
     ]
    }
   ],
   "source": [
    "cpu_usage, inference_time, _ = measure_cpu_utilization_and_run(compute_metrics_base, model, X_test_tensor, y_test_tensor, model_path)\n",
    "\n",
    "print(f'CPU usage during inference: {cpu_usage:.2f}%')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38360f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization complete and model saved.\n"
     ]
    }
   ],
   "source": [
    "import torch.quantization\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "# Load the saved model's state dict\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Make sure the model is in evaluation mode before quantization\n",
    "model.eval()\n",
    "\n",
    "# Perform dynamic quantization\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model,  # the original model\n",
    "    {torch.nn.Linear},  # specify which layer types to quantize\n",
    "    dtype=torch.qint8  # the target data type for quantized weights\n",
    ")\n",
    "\n",
    "# Save the quantized model\n",
    "quantized_model_path = \"/Users/sandeep/Desktop/BUCourses/Project/saved_models/Pytorch/transformer_quantized.pth\"\n",
    "torch.save(quantized_model.state_dict(), quantized_model_path)\n",
    "\n",
    "# Now you can use quantized_model for inference\n",
    "print(\"Quantization complete and model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f4ebff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of quantized model: 37.35 KB\n"
     ]
    }
   ],
   "source": [
    "# Check the size of the quantized model\n",
    "quantized_model_size = os.path.getsize(quantized_model_path)\n",
    "print(f\"Size of quantized model: {quantized_model_size/1024:0.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0bc8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W qlinear_dynamic.cpp:247] Warning: Currently, qnnpack incorrectly ignores reduce_range when it is set to true; this may change in a future release. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8089\n",
      "Precision: 0.7793\n",
      "Recall: 0.8089\n",
      "F1 Score: 0.7712\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "quantized_model.eval()  # Set the model to evaluation mode\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = quantized_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Collect all predictions and labels to compute overall metrics\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert collected predictions and labels to arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ee39d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model: 37.35 KB\n",
      "Accuracy on the test set: 80.87%\n",
      "CPU usage during inference: 35.20%\n",
      "Inference time: 1.4896 seconds\n"
     ]
    }
   ],
   "source": [
    "cpu_usage, inference_time, _ = measure_cpu_utilization_and_run(compute_metrics_base, quantized_model, X_test_tensor, y_test_tensor, quantized_model_path)\n",
    "\n",
    "print(f'CPU usage during inference: {cpu_usage:.2f}%')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adee3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
