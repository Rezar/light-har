{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ol4WjzoLgfL4"
   },
   "outputs": [],
   "source": [
    "#syooress CPU warn\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "biDzD-1bhv4R"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lYdrtyr4hwBH"
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "x = genfromtxt('../Data/WISDM_x.csv', delimiter=',')\n",
    "y = pd.read_csv('../Data/WISDM_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpohnuw7if7V",
    "outputId": "7ccc52d8-676a-40aa-abd9-6e7856f5ffa4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sandeep/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E6rZSEmShwFS"
   },
   "outputs": [],
   "source": [
    "def create_series(x,y,timestep,overlap):\n",
    "\n",
    "    slide_step = int(timestep*(1-overlap))\n",
    "    data_num = int((len(x)/slide_step)-1)\n",
    "  \n",
    "    dataset = np.ndarray(shape=(data_num,timestep,len(x[0])))\n",
    "    labels = list()\n",
    "\n",
    "    for i in range(data_num):\n",
    "        labels.append(y[slide_step*(i+1)-1])\n",
    "        for j in range(timestep):\n",
    "            dataset[i,j,:] = x[slide_step*i+j,:]\n",
    "\n",
    "    return dataset,np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4PEeNLTehwIq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137275, 16, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred.append(\"5\")\n",
    "#arrange 16 lines data into a series\n",
    "#try to import time series in this way\n",
    "import numpy as np\n",
    "dataset,labels = create_series(x,y,16,0.5)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137275, 48, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.reshape(dataset,(len(dataset),len(dataset[0])*len(dataset[0,0]),1))\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3f_cmKjhwLx",
    "outputId": "fa03cf71-62a2-4720-eda2-000eac553075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96092, 48, 1), (41183, 48, 1), (96092,), (41183,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset,labels,test_size=0.3, random_state=412)\n",
    "# X_test, X_val, y_test, y_val = train_test_split(X_toSplit,y_toSplit,test_size=0.25, random_state=412)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ni82Le1JjX8g"
   },
   "outputs": [],
   "source": [
    "def trans_encoder(inputs, head_size, n_heads, ff_dim, drop=0.0):\n",
    "  # MultiHeadAttention\n",
    "    x = K.layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = K.layers.MultiHeadAttention(key_dim=head_size, num_heads=n_heads, dropout=drop)(x, x)\n",
    "    x = K.layers.Dropout(drop)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = K.layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = K.layers.Conv1D(filters=ff_dim, kernel_size=1,activation=\"relu\")(x)\n",
    "    x = K.layers.Dropout(drop)(x)\n",
    "    x = K.layers.Conv1D(filters=inputs.shape[-1],kernel_size=1)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Z3CP1k98jYcw"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape, head_size, n_heads, ff_dim,\n",
    "                 n_trans_blocks, mlp_units, drop=0.0, mlp_drop=0.0):\n",
    "\n",
    "    inpts = K.Input(shape=input_shape)\n",
    "    x = inpts\n",
    "    for _ in range(n_trans_blocks):\n",
    "        x = trans_encoder(x, head_size, n_heads, ff_dim, drop)\n",
    "\n",
    "    x = K.layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = K.layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = K.layers.Dropout(mlp_drop)(x)\n",
    "    \n",
    "    oupts = K.layers.Dense(6, activation=\"softmax\")(x) \n",
    "    return K.Model(inpts, oupts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96092, 48, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r5AaECG4jYfX",
    "outputId": "b2f86dec-d6d3-48f2-f252-725b18247585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin Transformer classification demo \n",
      "(96092, 48, 1)\n",
      "(41183, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as K\n",
    "\n",
    "# 0. get ready\n",
    "print(\"\\nBegin Transformer classification demo \")\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# 1. load training and test data\n",
    "r = x_train.shape[0]\n",
    "c = x_train.shape[1]\n",
    "x_train = x_train.reshape((r, c, 1))  # (3601, 500, 1)\n",
    "print(x_train.shape)\n",
    "\n",
    "r = x_test.shape[0]\n",
    "c = x_test.shape[1]\n",
    "x_test = x_test.reshape((r, c, 1))  # (1320, 500, 1)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Transformer model \n",
      "\n",
      "Starting training \n",
      "Epoch 1/30\n",
      "2136/2136 [==============================] - 283s 132ms/step - loss: 2.3497 - sparse_categorical_accuracy: 0.4972 - val_loss: 0.9084 - val_sparse_categorical_accuracy: 0.7277\n",
      "Epoch 2/30\n",
      "2136/2136 [==============================] - 289s 135ms/step - loss: 1.0704 - sparse_categorical_accuracy: 0.6660 - val_loss: 0.7390 - val_sparse_categorical_accuracy: 0.7691\n",
      "Epoch 3/30\n",
      "2136/2136 [==============================] - 292s 137ms/step - loss: 0.8562 - sparse_categorical_accuracy: 0.7243 - val_loss: 0.6545 - val_sparse_categorical_accuracy: 0.7838\n",
      "Epoch 4/30\n",
      "2136/2136 [==============================] - 288s 135ms/step - loss: 0.7504 - sparse_categorical_accuracy: 0.7508 - val_loss: 0.5991 - val_sparse_categorical_accuracy: 0.7887\n",
      "Epoch 5/30\n",
      "2136/2136 [==============================] - 288s 135ms/step - loss: 0.6884 - sparse_categorical_accuracy: 0.7632 - val_loss: 0.5666 - val_sparse_categorical_accuracy: 0.7943\n",
      "Epoch 6/30\n",
      "2136/2136 [==============================] - 289s 135ms/step - loss: 0.6509 - sparse_categorical_accuracy: 0.7718 - val_loss: 0.5446 - val_sparse_categorical_accuracy: 0.7976\n",
      "Epoch 7/30\n",
      "2136/2136 [==============================] - 289s 135ms/step - loss: 0.6267 - sparse_categorical_accuracy: 0.7780 - val_loss: 0.5324 - val_sparse_categorical_accuracy: 0.8012\n",
      "Epoch 8/30\n",
      "2136/2136 [==============================] - 290s 136ms/step - loss: 0.6065 - sparse_categorical_accuracy: 0.7840 - val_loss: 0.5176 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 9/30\n",
      "2136/2136 [==============================] - 290s 136ms/step - loss: 0.5946 - sparse_categorical_accuracy: 0.7882 - val_loss: 0.5073 - val_sparse_categorical_accuracy: 0.8056\n",
      "Epoch 10/30\n",
      "2136/2136 [==============================] - 299s 140ms/step - loss: 0.5820 - sparse_categorical_accuracy: 0.7914 - val_loss: 0.4995 - val_sparse_categorical_accuracy: 0.8067\n",
      "Epoch 11/30\n",
      "2136/2136 [==============================] - 292s 137ms/step - loss: 0.5734 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.4967 - val_sparse_categorical_accuracy: 0.8109\n",
      "Epoch 12/30\n",
      "2136/2136 [==============================] - 295s 138ms/step - loss: 0.5639 - sparse_categorical_accuracy: 0.7971 - val_loss: 0.4919 - val_sparse_categorical_accuracy: 0.8135\n",
      "Epoch 13/30\n",
      "2136/2136 [==============================] - 295s 138ms/step - loss: 0.5609 - sparse_categorical_accuracy: 0.7991 - val_loss: 0.4860 - val_sparse_categorical_accuracy: 0.8148\n",
      "Epoch 14/30\n",
      "2136/2136 [==============================] - 294s 138ms/step - loss: 0.5562 - sparse_categorical_accuracy: 0.8008 - val_loss: 0.4835 - val_sparse_categorical_accuracy: 0.8177\n",
      "Epoch 15/30\n",
      "2136/2136 [==============================] - 294s 138ms/step - loss: 0.5501 - sparse_categorical_accuracy: 0.8020 - val_loss: 0.4780 - val_sparse_categorical_accuracy: 0.8196\n",
      "Epoch 16/30\n",
      "2136/2136 [==============================] - 296s 139ms/step - loss: 0.5440 - sparse_categorical_accuracy: 0.8048 - val_loss: 0.4751 - val_sparse_categorical_accuracy: 0.8240\n",
      "Epoch 17/30\n",
      "2136/2136 [==============================] - 296s 139ms/step - loss: 0.5422 - sparse_categorical_accuracy: 0.8054 - val_loss: 0.4718 - val_sparse_categorical_accuracy: 0.8240\n",
      "Epoch 18/30\n",
      "2136/2136 [==============================] - 295s 138ms/step - loss: 0.5375 - sparse_categorical_accuracy: 0.8088 - val_loss: 0.4693 - val_sparse_categorical_accuracy: 0.8251\n",
      "Epoch 19/30\n",
      "2136/2136 [==============================] - 296s 139ms/step - loss: 0.5358 - sparse_categorical_accuracy: 0.8081 - val_loss: 0.4692 - val_sparse_categorical_accuracy: 0.8240\n",
      "Epoch 20/30\n",
      "2136/2136 [==============================] - 295s 138ms/step - loss: 0.5298 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.4647 - val_sparse_categorical_accuracy: 0.8275\n",
      "Epoch 21/30\n",
      "2136/2136 [==============================] - 300s 140ms/step - loss: 0.5289 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.4640 - val_sparse_categorical_accuracy: 0.8279\n",
      "Epoch 22/30\n",
      "2136/2136 [==============================] - 294s 138ms/step - loss: 0.5246 - sparse_categorical_accuracy: 0.8115 - val_loss: 0.4593 - val_sparse_categorical_accuracy: 0.8298\n",
      "Epoch 23/30\n",
      "2136/2136 [==============================] - 294s 138ms/step - loss: 0.5243 - sparse_categorical_accuracy: 0.8129 - val_loss: 0.4557 - val_sparse_categorical_accuracy: 0.8340\n",
      "Epoch 24/30\n",
      "2136/2136 [==============================] - 293s 137ms/step - loss: 0.5204 - sparse_categorical_accuracy: 0.8137 - val_loss: 0.4554 - val_sparse_categorical_accuracy: 0.8334\n",
      "Epoch 25/30\n",
      "2136/2136 [==============================] - 299s 140ms/step - loss: 0.5202 - sparse_categorical_accuracy: 0.8142 - val_loss: 0.4524 - val_sparse_categorical_accuracy: 0.8370\n",
      "Epoch 26/30\n",
      "2136/2136 [==============================] - 297s 139ms/step - loss: 0.5142 - sparse_categorical_accuracy: 0.8168 - val_loss: 0.4530 - val_sparse_categorical_accuracy: 0.8341\n",
      "Epoch 27/30\n",
      "2136/2136 [==============================] - 293s 137ms/step - loss: 0.5159 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.4475 - val_sparse_categorical_accuracy: 0.8357\n",
      "Epoch 28/30\n",
      "2136/2136 [==============================] - 294s 138ms/step - loss: 0.5103 - sparse_categorical_accuracy: 0.8170 - val_loss: 0.4466 - val_sparse_categorical_accuracy: 0.8354\n",
      "Epoch 29/30\n",
      "2136/2136 [==============================] - 300s 141ms/step - loss: 0.5095 - sparse_categorical_accuracy: 0.8178 - val_loss: 0.4484 - val_sparse_categorical_accuracy: 0.8317\n",
      "Epoch 30/30\n",
      "2076/2136 [============================>.] - ETA: 7s - loss: 0.5090 - sparse_categorical_accuracy: 0.8170"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating Transformer model \")\n",
    "input_shape = x_train.shape[1:]  # (500,1)\n",
    "\n",
    "model = create_model(input_shape, head_size=256, n_heads=4,\n",
    "                     ff_dim=4, n_trans_blocks=4, mlp_units=[128],\n",
    "                     drop=0.25, mlp_drop=0.4)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=K.optimizers.Adam(learning_rate=1.0e-4),\n",
    "              metrics=[\"sparse_categorical_accuracy\"])\n",
    "# Uncomment below if you want to use EarlyStopping\n",
    "# c_backs = [K.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "print(\"\\nStarting training \")\n",
    "model.fit(x_train, y_train, validation_split=0.2,\n",
    "          epochs=30, batch_size=36, shuffle=True)\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/Users/sandeep/Desktop/BUCourses/Project/saved_models/Transformer'\n",
    "model.save(model_dir).lo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from helper import compute_metrics_base, compute_metrics, measure_cpu_utilization_and_run\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_metrics_base(model, x_test, y_test, model_dir):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of the TensorFlow model.\n",
    "\n",
    "    :param model: TensorFlow model.\n",
    "    :param x_test: Test dataset features.\n",
    "    :param y_test: Test dataset labels.\n",
    "    :param model_dir: Directory path of the model.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the model's predictions\n",
    "    predictions = model.predict(x_test)\n",
    "\n",
    "    # Convert predictions to label format\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Given the error, it seems y_test is already in label format.\n",
    "    # So, no need to use np.argmax on it.\n",
    "    true_labels = y_test\n",
    "    \n",
    "    model_size = sum(f.stat().st_size for f in Path(model_dir).rglob('*'))\n",
    "    print(f'Size of the model: {model_size/1024:.2f} KB')\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    print(f'Accuracy on the test set: {accuracy:.2%}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1287/1287 [==============================] - 57s 44ms/step\n",
      "Size of the model: 1642.83 KB\n",
      "Accuracy on the test set: 83.46%\n",
      "Elapsed time: 57.10 seconds\n",
      "Average CPU utilization: 31.85%\n"
     ]
    }
   ],
   "source": [
    "model_dir = '/Users/sandeep/Desktop/BUCourses/Project/saved_models/Transformer'\n",
    "model = tf.keras.models.load_model(model_dir)\n",
    "average_cpu_utilization, elapsed_time, result = measure_cpu_utilization_and_run(\n",
    "                                                compute_metrics_base, model, x_test, y_test, model_dir)\n",
    "\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"Average CPU utilization: {average_cpu_utilization:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(tflite_quant_model, X_test, y_test, input_type='float32'):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of the TFLite model.\n",
    "\n",
    "    :param tflite_quant_model: Quantized TFLite model.\n",
    "    :param X_test: Test dataset features.\n",
    "    :param y_test: Test dataset labels.\n",
    "    :param input_type: The type of the input data ('float32' or 'int8').\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_quant_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_tensor_index = interpreter.get_input_details()[0]['index']\n",
    "    \n",
    "    model_size = len(tflite_quant_model)\n",
    "    print(f\"Size of TFLite model: {model_size/1024:.2f} KB\")\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        if input_type == 'float32':\n",
    "            input_data = X_test[i:i + 1].astype(np.float32)\n",
    "        elif input_type == 'int8':\n",
    "            input_data = (X_test[i:i + 1] * 255).astype(np.int8)\n",
    "        elif input_type == 'uint8':\n",
    "            input_data = (X_test[i:i + 1] * 255).astype(np.uint8)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported input_type: {input_type}\")\n",
    "\n",
    "        interpreter.set_tensor(input_tensor_index, input_data)\n",
    "        interpreter.invoke()\n",
    "\n",
    "        output_details = interpreter.get_output_details()[0]\n",
    "        output_data = interpreter.get_tensor(output_details['index'])\n",
    "        predicted_label = np.argmax(output_data)\n",
    "        predictions.append(predicted_label)\n",
    "\n",
    "    predictions = np.array(predictions)\n",
    "    # Given the context, y_test is already in label format.\n",
    "    # So, no need to use np.argmax on it.\n",
    "    true_labels = y_test\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    print(f'Accuracy on the test set: {accuracy:.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/l4/2y2z7y6s4f39zqdkw_9jv51h0000gn/T/tmpedp37fc2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/l4/2y2z7y6s4f39zqdkw_9jv51h0000gn/T/tmpedp37fc2/assets\n"
     ]
    }
   ],
   "source": [
    "#Implemented Dynamic Range Quantization\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "\n",
    "#Load saved model\n",
    "model = tf.keras.models.load_model(model_dir)\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "# Now, convert the model\n",
    "transformer_dynamicQ_tflite_model = converter.convert()\n",
    "\n",
    "\n",
    "# Save the quantized model to a file\n",
    "with open('/Users/sandeep/Desktop/BUCourses/Project/saved_models/transformer_dynamicQ_model.tflite', 'wb') as f:\n",
    "    f.write(transformer_dynamicQ_tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of TFLite model: 116.67 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 83.48%\n",
      "Elapsed time: 51.69 seconds\n",
      "Average CPU utilization: 22.25%\n"
     ]
    }
   ],
   "source": [
    "average_cpu_utilization, elapsed_time, result = measure_cpu_utilization_and_run(\n",
    "                                                compute_metrics, transformer_dynamicQ_tflite_model, x_test, y_test, input_type='float32'\n",
    "                                                )\n",
    "\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"Average CPU utilization: {average_cpu_utilization:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
