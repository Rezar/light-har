{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fee4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2738544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import time\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_metrics_base(model, x_test, y_test, model_path):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of the PyTorch model.\n",
    "\n",
    "    :param model: PyTorch model.\n",
    "    :param x_test: Test dataset features (as a PyTorch Tensor).\n",
    "    :param y_test: Test dataset labels (as a NumPy array).\n",
    "    :param model_dir: Directory where the PyTorch model files are stored.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get the model's predictions\n",
    "        outputs = model(x_test)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "\n",
    "        # Convert y_test to tensor if it's not already\n",
    "        true_labels = torch.tensor(y_test) if not isinstance(y_test, torch.Tensor) else y_test\n",
    "        true_labels = true_labels.squeeze()  # Remove unnecessary dimensions\n",
    "\n",
    "    model_file = Path(model_path)\n",
    "\n",
    "    # Size in bytes\n",
    "    model_size_bytes = model_file.stat().st_size\n",
    "\n",
    "    # Convert size to kilobytes (optional)\n",
    "    model_size_kb = model_size_bytes / 1024\n",
    "    print(f\"Size of the model: {model_size_kb:.2f} KB\")\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels.numpy(), predicted_labels.numpy())\n",
    "    print(f'Accuracy on the test set: {accuracy:.2%}')\n",
    "def measure_cpu_utilization_and_run(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Measure CPU utilization while running a function.\n",
    "\n",
    "    Parameters:\n",
    "        func (function): The function to be executed.\n",
    "        *args: Arguments to be passed to func.\n",
    "        **kwargs: Keyword arguments to be passed to func.\n",
    "\n",
    "    Returns:\n",
    "        float: CPU utilization percentage during the execution of func.\n",
    "        float: The elapsed time during the execution of func.\n",
    "        any: The result of func execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Measure CPU utilization before execution\n",
    "    cpu_percent_before = psutil.cpu_percent(interval=None)\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Execute the function and store its result\n",
    "    result = func(*args, **kwargs)\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Measure CPU utilization after execution\n",
    "    cpu_percent_after = psutil.cpu_percent(interval=None)\n",
    "\n",
    "    # Calculate elapsed time and average CPU utilization\n",
    "    elapsed_time = end_time - start_time\n",
    "    average_cpu_utilization = (cpu_percent_before + cpu_percent_after) / 2\n",
    "\n",
    "    return average_cpu_utilization, elapsed_time, result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c2ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x = genfromtxt('../Data/WISDM_x.csv', delimiter=',')\n",
    "y_df = pd.read_csv('../Data/WISDM_y.csv')\n",
    "y = y_df.values.flatten()  # Flatten if y is 2D\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Function to create time series dataset\n",
    "def create_series(x, y, timestep, overlap):\n",
    "    slide_step = int(timestep * (1 - overlap))\n",
    "    data_num = int((len(x) / slide_step) - 1)\n",
    "    dataset = np.ndarray(shape=(data_num, timestep, x.shape[1]))\n",
    "    labels = []\n",
    "\n",
    "    for i in range(data_num):\n",
    "        labels.append(y[slide_step * (i + 1) - 1])\n",
    "        for j in range(timestep):\n",
    "            dataset[i, j, :] = x[slide_step * i + j, :]\n",
    "\n",
    "    return dataset, np.array(labels)\n",
    "\n",
    "# Create time series\n",
    "timestep = 16  # Replace with your value\n",
    "overlap = 0.5  # Replace with your value\n",
    "X_series, y_series = create_series(x, y_encoded, timestep, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7842f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(109820, 16, 3), X_test shape:(27455, 16, 3), y_train shape:(109820,), y_test shape:(27455,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_series, y_series, test_size=0.2, random_state=42)\n",
    "print(f'X_train shape:{X_train.shape}, X_test shape:{X_test.shape}, y_train shape:{y_train.shape}, y_test shape:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86d475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64)  # Assuming y_train is already encoded as class indexes\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d9c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56b1440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Transformer model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, head_size, n_heads, ff_dim, dropout=0.0):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=input_dim, num_heads=n_heads, dropout=dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=ff_dim, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=ff_dim, out_channels=input_dim, kernel_size=1)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # LayerNorm and Multi-head Attention\n",
    "        x = self.norm1(src)\n",
    "        x, _ = self.attention(x, x, x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x + src  # skip connection\n",
    "\n",
    "        # Feed Forward\n",
    "        x = self.norm2(x)\n",
    "        x = x.permute(1, 2, 0)  # Conv1D expects (batch_size, channels, length)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.permute(2, 0, 1)  # back to (length, batch_size, channels)\n",
    "        x = x + src  # skip connection\n",
    "        return x\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, sequence_length, num_features, head_size, n_heads, ff_dim, n_trans_blocks, mlp_units, drop=0.0, mlp_drop=0.0):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.encoders = nn.ModuleList([TransformerEncoderBlock(num_features, head_size, n_heads, ff_dim, drop) for _ in range(n_trans_blocks)])\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        mlp_layers = []\n",
    "        current_dim = num_features\n",
    "        for dim in mlp_units:\n",
    "            mlp_layers.append(nn.Linear(current_dim, dim))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(mlp_drop))\n",
    "            current_dim = dim  # Set input dim for the next layer\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        self.final_layer = nn.Linear(mlp_units[-1], 6)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = src.permute(1, 0, 2)  # Transformer expects (seq_len, batch_size, features)\n",
    "        for encoder in self.encoders:\n",
    "            src = encoder(src)\n",
    "\n",
    "        # Global average pooling\n",
    "        src = src.permute(1, 2, 0)  # pooling expects (batch_size, channels, length)\n",
    "        src = self.global_avg_pooling(src)\n",
    "        src = torch.flatten(src, 1)  # Flatten the output for the MLP\n",
    "\n",
    "        # MLP\n",
    "        src = self.mlp(src)\n",
    "        output = self.final_layer(src)\n",
    "        return output\n",
    "\n",
    "# Input parameters for your data\n",
    "sequence_length = 16  # The length of the time series sequences in your data\n",
    "num_features = 3     # The number of features in each time step of your data sequence\n",
    "\n",
    "# Instantiate the model\n",
    "# Instantiate the model with an adjusted number of heads and head size\n",
    "# The head size must be a multiple of num_features.\n",
    "model = TimeSeriesTransformer(\n",
    "    sequence_length=16, \n",
    "    num_features=3, \n",
    "    head_size=3,  # Each head will now have an embed size of 1 (3 / 3)\n",
    "    n_heads=1,  # Only one head since our embed_dim is 3\n",
    "    ff_dim=64, \n",
    "    n_trans_blocks=4, \n",
    "    mlp_units=[128, 64], \n",
    "    drop=0.1, \n",
    "    mlp_drop=0.1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bde95e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformer(\n",
       "  (encoders): ModuleList(\n",
       "    (0-3): 4 x TransformerEncoderBlock(\n",
       "      (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
       "      )\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
       "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 3, kernel_size=(1,), stride=(1,))\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (global_avg_pooling): AdaptiveAvgPool1d(output_size=1)\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=64, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab86147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/3432], Loss: 1.2991, Accuracy: 51.56%\n",
      "Epoch [1/10], Step [200/3432], Loss: 1.1044, Accuracy: 61.22%\n",
      "Epoch [1/10], Step [300/3432], Loss: 0.9828, Accuracy: 64.97%\n",
      "Epoch [1/10], Step [400/3432], Loss: 0.9224, Accuracy: 68.31%\n",
      "Epoch [1/10], Step [500/3432], Loss: 0.8644, Accuracy: 70.19%\n",
      "Epoch [1/10], Step [600/3432], Loss: 0.8419, Accuracy: 70.38%\n",
      "Epoch [1/10], Step [700/3432], Loss: 0.7770, Accuracy: 73.59%\n",
      "Epoch [1/10], Step [800/3432], Loss: 0.7961, Accuracy: 72.78%\n",
      "Epoch [1/10], Step [900/3432], Loss: 0.7457, Accuracy: 74.09%\n",
      "Epoch [1/10], Step [1000/3432], Loss: 0.7648, Accuracy: 73.53%\n",
      "Epoch [1/10], Step [1100/3432], Loss: 0.7299, Accuracy: 75.09%\n",
      "Epoch [1/10], Step [1200/3432], Loss: 0.7569, Accuracy: 74.03%\n",
      "Epoch [1/10], Step [1300/3432], Loss: 0.7578, Accuracy: 74.12%\n",
      "Epoch [1/10], Step [1400/3432], Loss: 0.7181, Accuracy: 75.16%\n",
      "Epoch [1/10], Step [1500/3432], Loss: 0.7160, Accuracy: 75.72%\n",
      "Epoch [1/10], Step [1600/3432], Loss: 0.7228, Accuracy: 75.88%\n",
      "Epoch [1/10], Step [1700/3432], Loss: 0.7499, Accuracy: 74.22%\n",
      "Epoch [1/10], Step [1800/3432], Loss: 0.7064, Accuracy: 75.75%\n",
      "Epoch [1/10], Step [1900/3432], Loss: 0.6736, Accuracy: 77.00%\n",
      "Epoch [1/10], Step [2000/3432], Loss: 0.7053, Accuracy: 75.41%\n",
      "Epoch [1/10], Step [2100/3432], Loss: 0.7481, Accuracy: 73.66%\n",
      "Epoch [1/10], Step [2200/3432], Loss: 0.7220, Accuracy: 74.97%\n",
      "Epoch [1/10], Step [2300/3432], Loss: 0.6710, Accuracy: 76.06%\n",
      "Epoch [1/10], Step [2400/3432], Loss: 0.6914, Accuracy: 75.84%\n",
      "Epoch [1/10], Step [2500/3432], Loss: 0.6994, Accuracy: 74.50%\n",
      "Epoch [1/10], Step [2600/3432], Loss: 0.6882, Accuracy: 75.53%\n",
      "Epoch [1/10], Step [2700/3432], Loss: 0.6855, Accuracy: 76.31%\n",
      "Epoch [1/10], Step [2800/3432], Loss: 0.6552, Accuracy: 77.56%\n",
      "Epoch [1/10], Step [2900/3432], Loss: 0.6675, Accuracy: 76.59%\n",
      "Epoch [1/10], Step [3000/3432], Loss: 0.6897, Accuracy: 75.66%\n",
      "Epoch [1/10], Step [3100/3432], Loss: 0.6668, Accuracy: 76.78%\n",
      "Epoch [1/10], Step [3200/3432], Loss: 0.6909, Accuracy: 76.03%\n",
      "Epoch [1/10], Step [3300/3432], Loss: 0.6739, Accuracy: 76.56%\n",
      "Epoch [1/10], Step [3400/3432], Loss: 0.6940, Accuracy: 75.69%\n",
      "Epoch [2/10], Step [100/3432], Loss: 0.6737, Accuracy: 76.97%\n",
      "Epoch [2/10], Step [200/3432], Loss: 0.6674, Accuracy: 76.94%\n",
      "Epoch [2/10], Step [300/3432], Loss: 0.6866, Accuracy: 75.47%\n",
      "Epoch [2/10], Step [400/3432], Loss: 0.6633, Accuracy: 76.94%\n",
      "Epoch [2/10], Step [500/3432], Loss: 0.6741, Accuracy: 75.91%\n",
      "Epoch [2/10], Step [600/3432], Loss: 0.6471, Accuracy: 77.59%\n",
      "Epoch [2/10], Step [700/3432], Loss: 0.6574, Accuracy: 77.47%\n",
      "Epoch [2/10], Step [800/3432], Loss: 0.6962, Accuracy: 75.66%\n",
      "Epoch [2/10], Step [900/3432], Loss: 0.6271, Accuracy: 78.88%\n",
      "Epoch [2/10], Step [1000/3432], Loss: 0.6473, Accuracy: 77.09%\n",
      "Epoch [2/10], Step [1100/3432], Loss: 0.6709, Accuracy: 76.22%\n",
      "Epoch [2/10], Step [1200/3432], Loss: 0.6508, Accuracy: 77.66%\n",
      "Epoch [2/10], Step [1300/3432], Loss: 0.6792, Accuracy: 75.69%\n",
      "Epoch [2/10], Step [1400/3432], Loss: 0.6711, Accuracy: 76.06%\n",
      "Epoch [2/10], Step [1500/3432], Loss: 0.6637, Accuracy: 77.22%\n",
      "Epoch [2/10], Step [1600/3432], Loss: 0.6552, Accuracy: 77.38%\n",
      "Epoch [2/10], Step [1700/3432], Loss: 0.6357, Accuracy: 77.84%\n",
      "Epoch [2/10], Step [1800/3432], Loss: 0.6789, Accuracy: 75.84%\n",
      "Epoch [2/10], Step [1900/3432], Loss: 0.6280, Accuracy: 78.59%\n",
      "Epoch [2/10], Step [2000/3432], Loss: 0.6463, Accuracy: 77.25%\n",
      "Epoch [2/10], Step [2100/3432], Loss: 0.6436, Accuracy: 77.50%\n",
      "Epoch [2/10], Step [2200/3432], Loss: 0.6459, Accuracy: 76.62%\n",
      "Epoch [2/10], Step [2300/3432], Loss: 0.6487, Accuracy: 76.50%\n",
      "Epoch [2/10], Step [2400/3432], Loss: 0.6540, Accuracy: 78.12%\n",
      "Epoch [2/10], Step [2500/3432], Loss: 0.6261, Accuracy: 78.09%\n",
      "Epoch [2/10], Step [2600/3432], Loss: 0.6640, Accuracy: 76.75%\n",
      "Epoch [2/10], Step [2700/3432], Loss: 0.6687, Accuracy: 76.19%\n",
      "Epoch [2/10], Step [2800/3432], Loss: 0.6527, Accuracy: 76.47%\n",
      "Epoch [2/10], Step [2900/3432], Loss: 0.6316, Accuracy: 77.81%\n",
      "Epoch [2/10], Step [3000/3432], Loss: 0.6429, Accuracy: 77.56%\n",
      "Epoch [2/10], Step [3100/3432], Loss: 0.6375, Accuracy: 77.91%\n",
      "Epoch [2/10], Step [3200/3432], Loss: 0.6511, Accuracy: 77.47%\n",
      "Epoch [2/10], Step [3300/3432], Loss: 0.6538, Accuracy: 76.84%\n",
      "Epoch [2/10], Step [3400/3432], Loss: 0.6520, Accuracy: 76.81%\n",
      "Epoch [3/10], Step [100/3432], Loss: 0.6339, Accuracy: 78.38%\n",
      "Epoch [3/10], Step [200/3432], Loss: 0.6222, Accuracy: 77.69%\n",
      "Epoch [3/10], Step [300/3432], Loss: 0.6422, Accuracy: 78.25%\n",
      "Epoch [3/10], Step [400/3432], Loss: 0.6570, Accuracy: 77.09%\n",
      "Epoch [3/10], Step [500/3432], Loss: 0.6691, Accuracy: 76.03%\n",
      "Epoch [3/10], Step [600/3432], Loss: 0.6397, Accuracy: 77.59%\n",
      "Epoch [3/10], Step [700/3432], Loss: 0.6367, Accuracy: 77.75%\n",
      "Epoch [3/10], Step [800/3432], Loss: 0.6218, Accuracy: 78.81%\n",
      "Epoch [3/10], Step [900/3432], Loss: 0.6380, Accuracy: 77.25%\n",
      "Epoch [3/10], Step [1000/3432], Loss: 0.6383, Accuracy: 77.06%\n",
      "Epoch [3/10], Step [1100/3432], Loss: 0.6269, Accuracy: 78.41%\n",
      "Epoch [3/10], Step [1200/3432], Loss: 0.6076, Accuracy: 78.56%\n",
      "Epoch [3/10], Step [1300/3432], Loss: 0.6487, Accuracy: 77.69%\n",
      "Epoch [3/10], Step [1400/3432], Loss: 0.6260, Accuracy: 78.12%\n",
      "Epoch [3/10], Step [1500/3432], Loss: 0.6372, Accuracy: 77.22%\n",
      "Epoch [3/10], Step [1600/3432], Loss: 0.6254, Accuracy: 78.53%\n",
      "Epoch [3/10], Step [1700/3432], Loss: 0.6938, Accuracy: 75.50%\n",
      "Epoch [3/10], Step [1800/3432], Loss: 0.6574, Accuracy: 76.53%\n",
      "Epoch [3/10], Step [1900/3432], Loss: 0.5933, Accuracy: 79.41%\n",
      "Epoch [3/10], Step [2000/3432], Loss: 0.6254, Accuracy: 78.91%\n",
      "Epoch [3/10], Step [2100/3432], Loss: 0.6156, Accuracy: 77.97%\n",
      "Epoch [3/10], Step [2200/3432], Loss: 0.6114, Accuracy: 77.97%\n",
      "Epoch [3/10], Step [2300/3432], Loss: 0.6506, Accuracy: 77.19%\n",
      "Epoch [3/10], Step [2400/3432], Loss: 0.6058, Accuracy: 79.38%\n",
      "Epoch [3/10], Step [2500/3432], Loss: 0.6108, Accuracy: 78.66%\n",
      "Epoch [3/10], Step [2600/3432], Loss: 0.6217, Accuracy: 78.34%\n",
      "Epoch [3/10], Step [2700/3432], Loss: 0.6481, Accuracy: 77.41%\n",
      "Epoch [3/10], Step [2800/3432], Loss: 0.6297, Accuracy: 78.12%\n",
      "Epoch [3/10], Step [2900/3432], Loss: 0.6429, Accuracy: 76.78%\n",
      "Epoch [3/10], Step [3000/3432], Loss: 0.6293, Accuracy: 77.81%\n",
      "Epoch [3/10], Step [3100/3432], Loss: 0.6538, Accuracy: 76.69%\n",
      "Epoch [3/10], Step [3200/3432], Loss: 0.6323, Accuracy: 77.62%\n",
      "Epoch [3/10], Step [3300/3432], Loss: 0.6448, Accuracy: 77.34%\n",
      "Epoch [3/10], Step [3400/3432], Loss: 0.6421, Accuracy: 76.97%\n",
      "Epoch [4/10], Step [100/3432], Loss: 0.6103, Accuracy: 78.50%\n",
      "Epoch [4/10], Step [200/3432], Loss: 0.6376, Accuracy: 78.09%\n",
      "Epoch [4/10], Step [300/3432], Loss: 0.6230, Accuracy: 77.53%\n",
      "Epoch [4/10], Step [400/3432], Loss: 0.6440, Accuracy: 76.91%\n",
      "Epoch [4/10], Step [500/3432], Loss: 0.6323, Accuracy: 78.34%\n",
      "Epoch [4/10], Step [600/3432], Loss: 0.6180, Accuracy: 78.69%\n",
      "Epoch [4/10], Step [700/3432], Loss: 0.6108, Accuracy: 79.16%\n",
      "Epoch [4/10], Step [800/3432], Loss: 0.6409, Accuracy: 77.81%\n",
      "Epoch [4/10], Step [900/3432], Loss: 0.6833, Accuracy: 75.84%\n",
      "Epoch [4/10], Step [1000/3432], Loss: 0.6389, Accuracy: 77.59%\n",
      "Epoch [4/10], Step [1100/3432], Loss: 0.6141, Accuracy: 78.31%\n",
      "Epoch [4/10], Step [1200/3432], Loss: 0.6334, Accuracy: 77.41%\n",
      "Epoch [4/10], Step [1300/3432], Loss: 0.6150, Accuracy: 77.72%\n",
      "Epoch [4/10], Step [1400/3432], Loss: 0.6430, Accuracy: 76.97%\n",
      "Epoch [4/10], Step [1500/3432], Loss: 0.6304, Accuracy: 77.97%\n",
      "Epoch [4/10], Step [1600/3432], Loss: 0.6419, Accuracy: 76.88%\n",
      "Epoch [4/10], Step [1700/3432], Loss: 0.6035, Accuracy: 77.78%\n",
      "Epoch [4/10], Step [1800/3432], Loss: 0.6323, Accuracy: 77.66%\n",
      "Epoch [4/10], Step [1900/3432], Loss: 0.6331, Accuracy: 77.22%\n",
      "Epoch [4/10], Step [2000/3432], Loss: 0.6331, Accuracy: 77.03%\n",
      "Epoch [4/10], Step [2100/3432], Loss: 0.6192, Accuracy: 78.06%\n",
      "Epoch [4/10], Step [2200/3432], Loss: 0.6289, Accuracy: 77.94%\n",
      "Epoch [4/10], Step [2300/3432], Loss: 0.6442, Accuracy: 77.38%\n",
      "Epoch [4/10], Step [2400/3432], Loss: 0.6130, Accuracy: 77.94%\n",
      "Epoch [4/10], Step [2500/3432], Loss: 0.6292, Accuracy: 77.56%\n",
      "Epoch [4/10], Step [2600/3432], Loss: 0.6252, Accuracy: 77.53%\n",
      "Epoch [4/10], Step [2700/3432], Loss: 0.6283, Accuracy: 78.19%\n",
      "Epoch [4/10], Step [2800/3432], Loss: 0.5946, Accuracy: 79.41%\n",
      "Epoch [4/10], Step [2900/3432], Loss: 0.6077, Accuracy: 78.66%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [3000/3432], Loss: 0.6234, Accuracy: 77.97%\n",
      "Epoch [4/10], Step [3100/3432], Loss: 0.6137, Accuracy: 78.47%\n",
      "Epoch [4/10], Step [3200/3432], Loss: 0.5976, Accuracy: 78.84%\n",
      "Epoch [4/10], Step [3300/3432], Loss: 0.6454, Accuracy: 77.38%\n",
      "Epoch [4/10], Step [3400/3432], Loss: 0.6037, Accuracy: 78.91%\n",
      "Epoch [5/10], Step [100/3432], Loss: 0.5985, Accuracy: 78.88%\n",
      "Epoch [5/10], Step [200/3432], Loss: 0.6211, Accuracy: 77.97%\n",
      "Epoch [5/10], Step [300/3432], Loss: 0.6312, Accuracy: 76.75%\n",
      "Epoch [5/10], Step [400/3432], Loss: 0.5950, Accuracy: 79.78%\n",
      "Epoch [5/10], Step [500/3432], Loss: 0.6104, Accuracy: 77.94%\n",
      "Epoch [5/10], Step [600/3432], Loss: 0.6259, Accuracy: 77.91%\n",
      "Epoch [5/10], Step [700/3432], Loss: 0.6441, Accuracy: 77.22%\n",
      "Epoch [5/10], Step [800/3432], Loss: 0.6333, Accuracy: 77.84%\n",
      "Epoch [5/10], Step [900/3432], Loss: 0.6242, Accuracy: 78.28%\n",
      "Epoch [5/10], Step [1000/3432], Loss: 0.6347, Accuracy: 77.81%\n",
      "Epoch [5/10], Step [1100/3432], Loss: 0.6060, Accuracy: 78.12%\n",
      "Epoch [5/10], Step [1200/3432], Loss: 0.6123, Accuracy: 78.41%\n",
      "Epoch [5/10], Step [1300/3432], Loss: 0.6496, Accuracy: 77.00%\n",
      "Epoch [5/10], Step [1400/3432], Loss: 0.6159, Accuracy: 78.16%\n",
      "Epoch [5/10], Step [1500/3432], Loss: 0.6079, Accuracy: 78.53%\n",
      "Epoch [5/10], Step [1600/3432], Loss: 0.6124, Accuracy: 78.75%\n",
      "Epoch [5/10], Step [1700/3432], Loss: 0.5987, Accuracy: 78.53%\n",
      "Epoch [5/10], Step [1800/3432], Loss: 0.6045, Accuracy: 78.47%\n",
      "Epoch [5/10], Step [1900/3432], Loss: 0.6104, Accuracy: 78.75%\n",
      "Epoch [5/10], Step [2000/3432], Loss: 0.6028, Accuracy: 79.25%\n",
      "Epoch [5/10], Step [2100/3432], Loss: 0.5893, Accuracy: 80.22%\n",
      "Epoch [5/10], Step [2200/3432], Loss: 0.6267, Accuracy: 78.09%\n",
      "Epoch [5/10], Step [2300/3432], Loss: 0.6046, Accuracy: 79.03%\n",
      "Epoch [5/10], Step [2400/3432], Loss: 0.6381, Accuracy: 77.34%\n",
      "Epoch [5/10], Step [2500/3432], Loss: 0.5853, Accuracy: 78.59%\n",
      "Epoch [5/10], Step [2600/3432], Loss: 0.5855, Accuracy: 79.59%\n",
      "Epoch [5/10], Step [2700/3432], Loss: 0.6094, Accuracy: 78.72%\n",
      "Epoch [5/10], Step [2800/3432], Loss: 0.5934, Accuracy: 79.38%\n",
      "Epoch [5/10], Step [2900/3432], Loss: 0.6058, Accuracy: 78.06%\n",
      "Epoch [5/10], Step [3000/3432], Loss: 0.6014, Accuracy: 78.72%\n",
      "Epoch [5/10], Step [3100/3432], Loss: 0.6192, Accuracy: 78.19%\n",
      "Epoch [5/10], Step [3200/3432], Loss: 0.5984, Accuracy: 78.62%\n",
      "Epoch [5/10], Step [3300/3432], Loss: 0.5824, Accuracy: 79.38%\n",
      "Epoch [5/10], Step [3400/3432], Loss: 0.5654, Accuracy: 79.88%\n",
      "Epoch [6/10], Step [100/3432], Loss: 0.5976, Accuracy: 78.34%\n",
      "Epoch [6/10], Step [200/3432], Loss: 0.6003, Accuracy: 78.56%\n",
      "Epoch [6/10], Step [300/3432], Loss: 0.5637, Accuracy: 80.12%\n",
      "Epoch [6/10], Step [400/3432], Loss: 0.5799, Accuracy: 79.84%\n",
      "Epoch [6/10], Step [500/3432], Loss: 0.5925, Accuracy: 79.00%\n",
      "Epoch [6/10], Step [600/3432], Loss: 0.5769, Accuracy: 79.78%\n",
      "Epoch [6/10], Step [700/3432], Loss: 0.5900, Accuracy: 79.50%\n",
      "Epoch [6/10], Step [800/3432], Loss: 0.5975, Accuracy: 78.94%\n",
      "Epoch [6/10], Step [900/3432], Loss: 0.6172, Accuracy: 77.66%\n",
      "Epoch [6/10], Step [1000/3432], Loss: 0.6170, Accuracy: 78.72%\n",
      "Epoch [6/10], Step [1100/3432], Loss: 0.6094, Accuracy: 78.22%\n",
      "Epoch [6/10], Step [1200/3432], Loss: 0.6208, Accuracy: 77.47%\n",
      "Epoch [6/10], Step [1300/3432], Loss: 0.5881, Accuracy: 79.78%\n",
      "Epoch [6/10], Step [1400/3432], Loss: 0.5756, Accuracy: 79.62%\n",
      "Epoch [6/10], Step [1500/3432], Loss: 0.5980, Accuracy: 78.69%\n",
      "Epoch [6/10], Step [1600/3432], Loss: 0.5890, Accuracy: 78.84%\n",
      "Epoch [6/10], Step [1700/3432], Loss: 0.5948, Accuracy: 78.91%\n",
      "Epoch [6/10], Step [1800/3432], Loss: 0.5749, Accuracy: 79.84%\n",
      "Epoch [6/10], Step [1900/3432], Loss: 0.5966, Accuracy: 78.81%\n",
      "Epoch [6/10], Step [2000/3432], Loss: 0.5928, Accuracy: 78.59%\n",
      "Epoch [6/10], Step [2100/3432], Loss: 0.5756, Accuracy: 79.12%\n",
      "Epoch [6/10], Step [2200/3432], Loss: 0.5797, Accuracy: 80.00%\n",
      "Epoch [6/10], Step [2300/3432], Loss: 0.5993, Accuracy: 78.47%\n",
      "Epoch [6/10], Step [2400/3432], Loss: 0.6154, Accuracy: 78.00%\n",
      "Epoch [6/10], Step [2500/3432], Loss: 0.5699, Accuracy: 80.16%\n",
      "Epoch [6/10], Step [2600/3432], Loss: 0.5549, Accuracy: 80.72%\n",
      "Epoch [6/10], Step [2700/3432], Loss: 0.5803, Accuracy: 79.44%\n",
      "Epoch [6/10], Step [2800/3432], Loss: 0.6028, Accuracy: 77.84%\n",
      "Epoch [6/10], Step [2900/3432], Loss: 0.5926, Accuracy: 78.94%\n",
      "Epoch [6/10], Step [3000/3432], Loss: 0.6120, Accuracy: 78.66%\n",
      "Epoch [6/10], Step [3100/3432], Loss: 0.6070, Accuracy: 78.31%\n",
      "Epoch [6/10], Step [3200/3432], Loss: 0.5799, Accuracy: 79.84%\n",
      "Epoch [6/10], Step [3300/3432], Loss: 0.5834, Accuracy: 79.88%\n",
      "Epoch [6/10], Step [3400/3432], Loss: 0.5543, Accuracy: 80.56%\n",
      "Epoch [7/10], Step [100/3432], Loss: 0.5502, Accuracy: 80.62%\n",
      "Epoch [7/10], Step [200/3432], Loss: 0.5798, Accuracy: 79.19%\n",
      "Epoch [7/10], Step [300/3432], Loss: 0.5868, Accuracy: 79.59%\n",
      "Epoch [7/10], Step [400/3432], Loss: 0.5670, Accuracy: 80.12%\n",
      "Epoch [7/10], Step [500/3432], Loss: 0.5928, Accuracy: 78.78%\n",
      "Epoch [7/10], Step [600/3432], Loss: 0.5918, Accuracy: 78.66%\n",
      "Epoch [7/10], Step [700/3432], Loss: 0.5859, Accuracy: 78.84%\n",
      "Epoch [7/10], Step [800/3432], Loss: 0.5652, Accuracy: 79.56%\n",
      "Epoch [7/10], Step [900/3432], Loss: 0.5823, Accuracy: 79.09%\n",
      "Epoch [7/10], Step [1000/3432], Loss: 0.5891, Accuracy: 78.75%\n",
      "Epoch [7/10], Step [1100/3432], Loss: 0.5779, Accuracy: 80.25%\n",
      "Epoch [7/10], Step [1200/3432], Loss: 0.6119, Accuracy: 78.53%\n",
      "Epoch [7/10], Step [1300/3432], Loss: 0.6120, Accuracy: 77.75%\n",
      "Epoch [7/10], Step [1400/3432], Loss: 0.6058, Accuracy: 78.72%\n",
      "Epoch [7/10], Step [1500/3432], Loss: 0.5814, Accuracy: 79.66%\n",
      "Epoch [7/10], Step [1600/3432], Loss: 0.5782, Accuracy: 79.94%\n",
      "Epoch [7/10], Step [1700/3432], Loss: 0.6055, Accuracy: 77.81%\n",
      "Epoch [7/10], Step [1800/3432], Loss: 0.6252, Accuracy: 77.91%\n",
      "Epoch [7/10], Step [1900/3432], Loss: 0.5975, Accuracy: 79.06%\n",
      "Epoch [7/10], Step [2000/3432], Loss: 0.6076, Accuracy: 78.88%\n",
      "Epoch [7/10], Step [2100/3432], Loss: 0.5680, Accuracy: 80.12%\n",
      "Epoch [7/10], Step [2200/3432], Loss: 0.5800, Accuracy: 80.00%\n",
      "Epoch [7/10], Step [2300/3432], Loss: 0.6338, Accuracy: 76.97%\n",
      "Epoch [7/10], Step [2400/3432], Loss: 0.6015, Accuracy: 78.78%\n",
      "Epoch [7/10], Step [2500/3432], Loss: 0.5742, Accuracy: 79.75%\n",
      "Epoch [7/10], Step [2600/3432], Loss: 0.5743, Accuracy: 79.81%\n",
      "Epoch [7/10], Step [2700/3432], Loss: 0.5555, Accuracy: 80.44%\n",
      "Epoch [7/10], Step [2800/3432], Loss: 0.5923, Accuracy: 79.06%\n",
      "Epoch [7/10], Step [2900/3432], Loss: 0.5861, Accuracy: 78.78%\n",
      "Epoch [7/10], Step [3000/3432], Loss: 0.5828, Accuracy: 79.00%\n",
      "Epoch [7/10], Step [3100/3432], Loss: 0.5760, Accuracy: 79.78%\n",
      "Epoch [7/10], Step [3200/3432], Loss: 0.5876, Accuracy: 79.97%\n",
      "Epoch [7/10], Step [3300/3432], Loss: 0.5964, Accuracy: 78.44%\n",
      "Epoch [7/10], Step [3400/3432], Loss: 0.5947, Accuracy: 79.25%\n",
      "Epoch [8/10], Step [100/3432], Loss: 0.6110, Accuracy: 78.00%\n",
      "Epoch [8/10], Step [200/3432], Loss: 0.5893, Accuracy: 79.38%\n",
      "Epoch [8/10], Step [300/3432], Loss: 0.6115, Accuracy: 78.84%\n",
      "Epoch [8/10], Step [400/3432], Loss: 0.6065, Accuracy: 79.16%\n",
      "Epoch [8/10], Step [500/3432], Loss: 0.5882, Accuracy: 79.31%\n",
      "Epoch [8/10], Step [600/3432], Loss: 0.6162, Accuracy: 77.50%\n",
      "Epoch [8/10], Step [700/3432], Loss: 0.6038, Accuracy: 78.94%\n",
      "Epoch [8/10], Step [800/3432], Loss: 0.5874, Accuracy: 79.62%\n",
      "Epoch [8/10], Step [900/3432], Loss: 0.5608, Accuracy: 79.88%\n",
      "Epoch [8/10], Step [1000/3432], Loss: 0.5825, Accuracy: 79.94%\n",
      "Epoch [8/10], Step [1100/3432], Loss: 0.6152, Accuracy: 77.22%\n",
      "Epoch [8/10], Step [1200/3432], Loss: 0.6080, Accuracy: 78.53%\n",
      "Epoch [8/10], Step [1300/3432], Loss: 0.6199, Accuracy: 77.25%\n",
      "Epoch [8/10], Step [1400/3432], Loss: 0.5789, Accuracy: 79.59%\n",
      "Epoch [8/10], Step [1500/3432], Loss: 0.5939, Accuracy: 78.25%\n",
      "Epoch [8/10], Step [1600/3432], Loss: 0.5565, Accuracy: 80.22%\n",
      "Epoch [8/10], Step [1700/3432], Loss: 0.5769, Accuracy: 79.41%\n",
      "Epoch [8/10], Step [1800/3432], Loss: 0.5703, Accuracy: 80.09%\n",
      "Epoch [8/10], Step [1900/3432], Loss: 0.5707, Accuracy: 79.81%\n",
      "Epoch [8/10], Step [2000/3432], Loss: 0.5742, Accuracy: 79.75%\n",
      "Epoch [8/10], Step [2100/3432], Loss: 0.5660, Accuracy: 80.50%\n",
      "Epoch [8/10], Step [2200/3432], Loss: 0.5697, Accuracy: 79.97%\n",
      "Epoch [8/10], Step [2300/3432], Loss: 0.5738, Accuracy: 80.19%\n",
      "Epoch [8/10], Step [2400/3432], Loss: 0.5794, Accuracy: 79.66%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [2500/3432], Loss: 0.5872, Accuracy: 79.28%\n",
      "Epoch [8/10], Step [2600/3432], Loss: 0.5947, Accuracy: 79.25%\n",
      "Epoch [8/10], Step [2700/3432], Loss: 0.5777, Accuracy: 79.12%\n",
      "Epoch [8/10], Step [2800/3432], Loss: 0.5911, Accuracy: 78.97%\n",
      "Epoch [8/10], Step [2900/3432], Loss: 0.5655, Accuracy: 80.44%\n",
      "Epoch [8/10], Step [3000/3432], Loss: 0.5689, Accuracy: 80.16%\n",
      "Epoch [8/10], Step [3100/3432], Loss: 0.5527, Accuracy: 80.78%\n",
      "Epoch [8/10], Step [3200/3432], Loss: 0.5665, Accuracy: 80.50%\n",
      "Epoch [8/10], Step [3300/3432], Loss: 0.5540, Accuracy: 80.16%\n",
      "Epoch [8/10], Step [3400/3432], Loss: 0.5765, Accuracy: 79.66%\n",
      "Epoch [9/10], Step [100/3432], Loss: 0.5832, Accuracy: 78.94%\n",
      "Epoch [9/10], Step [200/3432], Loss: 0.5900, Accuracy: 78.62%\n",
      "Epoch [9/10], Step [300/3432], Loss: 0.5460, Accuracy: 81.09%\n",
      "Epoch [9/10], Step [400/3432], Loss: 0.5706, Accuracy: 80.09%\n",
      "Epoch [9/10], Step [500/3432], Loss: 0.6053, Accuracy: 79.06%\n",
      "Epoch [9/10], Step [600/3432], Loss: 0.5678, Accuracy: 79.62%\n",
      "Epoch [9/10], Step [700/3432], Loss: 0.5537, Accuracy: 80.06%\n",
      "Epoch [9/10], Step [800/3432], Loss: 0.5833, Accuracy: 79.03%\n",
      "Epoch [9/10], Step [900/3432], Loss: 0.5701, Accuracy: 79.72%\n",
      "Epoch [9/10], Step [1000/3432], Loss: 0.5419, Accuracy: 80.75%\n",
      "Epoch [9/10], Step [1100/3432], Loss: 0.5673, Accuracy: 79.91%\n",
      "Epoch [9/10], Step [1200/3432], Loss: 0.5542, Accuracy: 80.88%\n",
      "Epoch [9/10], Step [1300/3432], Loss: 0.6068, Accuracy: 78.41%\n",
      "Epoch [9/10], Step [1400/3432], Loss: 0.6049, Accuracy: 77.97%\n",
      "Epoch [9/10], Step [1500/3432], Loss: 0.5842, Accuracy: 79.25%\n",
      "Epoch [9/10], Step [1600/3432], Loss: 0.6216, Accuracy: 77.38%\n",
      "Epoch [9/10], Step [1700/3432], Loss: 0.5817, Accuracy: 79.66%\n",
      "Epoch [9/10], Step [1800/3432], Loss: 0.5819, Accuracy: 79.50%\n",
      "Epoch [9/10], Step [1900/3432], Loss: 0.5884, Accuracy: 78.69%\n",
      "Epoch [9/10], Step [2000/3432], Loss: 0.5584, Accuracy: 80.41%\n",
      "Epoch [9/10], Step [2100/3432], Loss: 0.5362, Accuracy: 81.28%\n",
      "Epoch [9/10], Step [2200/3432], Loss: 0.5530, Accuracy: 80.31%\n",
      "Epoch [9/10], Step [2300/3432], Loss: 0.5931, Accuracy: 78.66%\n",
      "Epoch [9/10], Step [2400/3432], Loss: 0.5790, Accuracy: 79.72%\n",
      "Epoch [9/10], Step [2500/3432], Loss: 0.5894, Accuracy: 79.41%\n",
      "Epoch [9/10], Step [2600/3432], Loss: 0.5772, Accuracy: 79.97%\n",
      "Epoch [9/10], Step [2700/3432], Loss: 0.5484, Accuracy: 80.84%\n",
      "Epoch [9/10], Step [2800/3432], Loss: 0.5718, Accuracy: 78.72%\n",
      "Epoch [9/10], Step [2900/3432], Loss: 0.5555, Accuracy: 80.62%\n",
      "Epoch [9/10], Step [3000/3432], Loss: 0.5499, Accuracy: 80.47%\n",
      "Epoch [9/10], Step [3100/3432], Loss: 0.5653, Accuracy: 79.47%\n",
      "Epoch [9/10], Step [3200/3432], Loss: 0.5966, Accuracy: 79.09%\n",
      "Epoch [9/10], Step [3300/3432], Loss: 0.6004, Accuracy: 78.50%\n",
      "Epoch [9/10], Step [3400/3432], Loss: 0.5841, Accuracy: 79.25%\n",
      "Epoch [10/10], Step [100/3432], Loss: 0.5740, Accuracy: 79.31%\n",
      "Epoch [10/10], Step [200/3432], Loss: 0.5728, Accuracy: 79.31%\n",
      "Epoch [10/10], Step [300/3432], Loss: 0.5936, Accuracy: 79.06%\n",
      "Epoch [10/10], Step [400/3432], Loss: 0.5789, Accuracy: 79.88%\n",
      "Epoch [10/10], Step [500/3432], Loss: 0.6048, Accuracy: 78.50%\n",
      "Epoch [10/10], Step [600/3432], Loss: 0.5826, Accuracy: 79.75%\n",
      "Epoch [10/10], Step [700/3432], Loss: 0.5731, Accuracy: 79.91%\n",
      "Epoch [10/10], Step [800/3432], Loss: 0.5645, Accuracy: 80.00%\n",
      "Epoch [10/10], Step [900/3432], Loss: 0.5841, Accuracy: 79.38%\n",
      "Epoch [10/10], Step [1000/3432], Loss: 0.5608, Accuracy: 80.38%\n",
      "Epoch [10/10], Step [1100/3432], Loss: 0.6031, Accuracy: 78.31%\n",
      "Epoch [10/10], Step [1200/3432], Loss: 0.5966, Accuracy: 78.91%\n",
      "Epoch [10/10], Step [1300/3432], Loss: 0.5549, Accuracy: 80.06%\n",
      "Epoch [10/10], Step [1400/3432], Loss: 0.5717, Accuracy: 79.81%\n",
      "Epoch [10/10], Step [1500/3432], Loss: 0.5549, Accuracy: 79.75%\n",
      "Epoch [10/10], Step [1600/3432], Loss: 0.5748, Accuracy: 79.53%\n",
      "Epoch [10/10], Step [1700/3432], Loss: 0.5666, Accuracy: 79.91%\n",
      "Epoch [10/10], Step [1800/3432], Loss: 0.5447, Accuracy: 80.75%\n",
      "Epoch [10/10], Step [1900/3432], Loss: 0.5916, Accuracy: 79.06%\n",
      "Epoch [10/10], Step [2000/3432], Loss: 0.5694, Accuracy: 79.16%\n",
      "Epoch [10/10], Step [2100/3432], Loss: 0.5630, Accuracy: 80.50%\n",
      "Epoch [10/10], Step [2200/3432], Loss: 0.5801, Accuracy: 80.06%\n",
      "Epoch [10/10], Step [2300/3432], Loss: 0.5878, Accuracy: 79.00%\n",
      "Epoch [10/10], Step [2400/3432], Loss: 0.5844, Accuracy: 79.50%\n",
      "Epoch [10/10], Step [2500/3432], Loss: 0.5799, Accuracy: 79.12%\n",
      "Epoch [10/10], Step [2600/3432], Loss: 0.5725, Accuracy: 80.28%\n",
      "Epoch [10/10], Step [2700/3432], Loss: 0.5509, Accuracy: 80.56%\n",
      "Epoch [10/10], Step [2800/3432], Loss: 0.5653, Accuracy: 79.88%\n",
      "Epoch [10/10], Step [2900/3432], Loss: 0.5516, Accuracy: 80.41%\n",
      "Epoch [10/10], Step [3000/3432], Loss: 0.5455, Accuracy: 80.38%\n",
      "Epoch [10/10], Step [3100/3432], Loss: 0.5511, Accuracy: 80.34%\n",
      "Epoch [10/10], Step [3200/3432], Loss: 0.5753, Accuracy: 79.16%\n",
      "Epoch [10/10], Step [3300/3432], Loss: 0.5628, Accuracy: 80.41%\n",
      "Epoch [10/10], Step [3400/3432], Loss: 0.5715, Accuracy: 79.88%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], '\n",
    "                  f'Loss: {running_loss / 100:.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "# After training, you may want to save your model\n",
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "365f1ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8068\n",
      "Precision: 0.7910\n",
      "Recall: 0.8068\n",
      "F1 Score: 0.7709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Collect all predictions and labels to compute overall metrics\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert collected predictions and labels to arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9cbb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfd3612c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model size is 61.12 KB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Assume 'model' is the instance of TimeSeriesTransformer you have already defined and trained\n",
    "model_path = \"/Users/sandeep/Desktop/BUCourses/Reza_HAR_Project/light-har-local/code/transformer_base.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Get the size of the saved model file\n",
    "model_size = os.path.getsize(model_path)\n",
    "print(f\"The model size is {model_size/1024:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b340fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model: 61.12 KB\n",
      "Accuracy on the test set: 80.68%\n",
      "CPU usage during inference: 38.45%\n",
      "Inference time: 1.6204 seconds\n"
     ]
    }
   ],
   "source": [
    "cpu_usage, inference_time, _ = measure_cpu_utilization_and_run(compute_metrics_base, model, X_test_tensor, y_test_tensor, model_path)\n",
    "\n",
    "print(f'CPU usage during inference: {cpu_usage:.2f}%')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834f3e1",
   "metadata": {},
   "source": [
    "### Coreml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8334c01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops: 100%|██████████████████████████████████████████████████████▊| 395/396 [00:00<00:00, 13692.94 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 972.34 passes/s]\n",
      "Running MIL default pipeline: 100%|███████████████████████████████████████████████████████████████████| 71/71 [00:00<00:00, 326.09 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 2265.35 passes/s]\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "example_input = torch.rand(1,16, 3) \n",
    "\n",
    "model.eval()\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "out = traced_model(example_input)\n",
    "\n",
    "# Convert to Core ML program using the Unified Conversion API.\n",
    "transformer_coreml_model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.TensorType(shape=example_input.shape)]\n",
    " )\n",
    "\n",
    "transformer_coreml_model.save(\"transformer.mlpackage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db3e3715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input {\n",
       "  name: \"src_1\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 1\n",
       "      shape: 16\n",
       "      shape: 3\n",
       "      dataType: FLOAT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "output {\n",
       "  name: \"linear_10\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 1\n",
       "      shape: 6\n",
       "      dataType: FLOAT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "metadata {\n",
       "  userDefined {\n",
       "    key: \"com.github.apple.coremltools.source\"\n",
       "    value: \"torch==2.1.0\"\n",
       "  }\n",
       "  userDefined {\n",
       "    key: \"com.github.apple.coremltools.source_dialect\"\n",
       "    value: \"TorchScript\"\n",
       "  }\n",
       "  userDefined {\n",
       "    key: \"com.github.apple.coremltools.version\"\n",
       "    value: \"7.1\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_coreml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4982fa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def coreml_metrics(model_name, X_test, y_test, model_path):\n",
    "    predictions = []\n",
    "    for id in range(len(X_test)):\n",
    "        X_test_new = np.expand_dims(X_test[id], axis=0)\n",
    "        output_dict = model_name.predict({'src_1': X_test_new})\n",
    "        pred_class = np.argmax(output_dict['linear_10'])\n",
    "        predictions.append(pred_class)\n",
    "    \n",
    "    accuracy = np.sum(predictions == y_test) / len(predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    model_file = Path(model_path)\n",
    "    \n",
    "    # Size in bytes\n",
    "    model_size_bytes = model_file.stat().st_size\n",
    "    \n",
    "    # Convert size to kilobytes (optional)\n",
    "    model_size_kb = model_size_bytes / 1024\n",
    "    print(f\"Size of the model: {model_size_kb:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d06bf0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "import coremltools.optimize.coreml as cto\n",
    "\n",
    "gru_coreml_model = ct.models.MLModel(\"transformer.mlpackage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e639e745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8069204152249135\n",
      "Size of the model: 0.12 KB\n"
     ]
    }
   ],
   "source": [
    "model_name = transformer_coreml_model\n",
    "model_path = \"transformer.mlpackage\"\n",
    "\n",
    "coreml_metrics(model_name, X_test, y_test, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c3f6ac",
   "metadata": {},
   "source": [
    "### Dynamic 8-bit quantization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "131cbe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass linear_quantize_weights: 100%|████████████████████████████████████████████████| 21/21 [00:00<00:00, 23382.10 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|███████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 502.74 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 1127.91 passes/s]\n"
     ]
    }
   ],
   "source": [
    "import coremltools.optimize.coreml as cto\n",
    "\n",
    "op_config = cto.OpLinearQuantizerConfig(mode=\"linear_symmetric\", weight_threshold=512)\n",
    "config = cto.OptimizationConfig(global_config=op_config)\n",
    "\n",
    "compressed_8_bit_model = cto.linear_quantize_weights(transformer_coreml_model, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc412237",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_8_bit_model.save(\"transformer_8bitQuantized_mlmodel.mlpackage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9da175c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8070296849389911\n",
      "Size of the model: 0.12 KB\n"
     ]
    }
   ],
   "source": [
    "model_name = compressed_8_bit_model\n",
    "model_path = \"transformer_8bitQuantized_mlmodel.mlpackage\"\n",
    "\n",
    "coreml_metrics(model_name, X_test, y_test, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3baf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
