{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip install torch\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install coremltools"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1817e2979d12532f"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fee4936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:05:46.437930Z",
     "start_time": "2024-04-11T22:05:46.419599Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import psutil\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import coremltools as ct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Set up the paths\n",
    "HOME_PATH = os.path.expanduser('~')\n",
    "MODELS_PATH = f'{HOME_PATH}/Developer/BU/research/models'\n",
    "DATASET_PATH = f'../../../data/'\n",
    "data_features = f'{DATASET_PATH}/WISDM_x.csv'\n",
    "data_labels = f'{DATASET_PATH}/WISDM_y.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T22:05:47.320407Z",
     "start_time": "2024-04-11T22:05:47.302635Z"
    }
   },
   "id": "8acb014253e560c7"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2738544e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:05:48.393384Z",
     "start_time": "2024-04-11T22:05:48.377395Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics_base(model, x_test, y_test, model_path):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of the PyTorch model.\n",
    "\n",
    "    :param model: PyTorch model.\n",
    "    :param x_test: Test dataset features (as a PyTorch Tensor).\n",
    "    :param y_test: Test dataset labels (as a NumPy array).\n",
    "    :param model_dir: Directory where the PyTorch model files are stored.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get the model's predictions\n",
    "        outputs = model(x_test)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "\n",
    "        # Convert y_test to tensor if it's not already\n",
    "        true_labels = torch.tensor(y_test) if not isinstance(y_test, torch.Tensor) else y_test\n",
    "        true_labels = true_labels.squeeze()  # Remove unnecessary dimensions\n",
    "\n",
    "    model_file = Path(model_path)\n",
    "\n",
    "    # Size in bytes\n",
    "    model_size_bytes = model_file.stat().st_size\n",
    "\n",
    "    # Convert size to kilobytes (optional)\n",
    "    model_size_kb = model_size_bytes / 1024\n",
    "    print(f\"Size of the model: {model_size_kb:.2f} KB\")\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels.numpy(), predicted_labels.numpy())\n",
    "    print(f'Accuracy on the test set: {accuracy:.2%}')\n",
    "def measure_cpu_utilization_and_run(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Measure CPU utilization while running a function.\n",
    "\n",
    "    Parameters:\n",
    "        func (function): The function to be executed.\n",
    "        *args: Arguments to be passed to func.\n",
    "        **kwargs: Keyword arguments to be passed to func.\n",
    "\n",
    "    Returns:\n",
    "        float: CPU utilization percentage during the execution of func.\n",
    "        float: The elapsed time during the execution of func.\n",
    "        any: The result of func execution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Measure CPU utilization before execution\n",
    "    cpu_percent_before = psutil.cpu_percent(interval=None)\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Execute the function and store its result\n",
    "    result = func(*args, **kwargs)\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Measure CPU utilization after execution\n",
    "    cpu_percent_after = psutil.cpu_percent(interval=None)\n",
    "\n",
    "    # Calculate elapsed time and average CPU utilization\n",
    "    elapsed_time = end_time - start_time\n",
    "    average_cpu_utilization = (cpu_percent_before + cpu_percent_after) / 2\n",
    "\n",
    "    return average_cpu_utilization, elapsed_time, result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15c2ac40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:05:51.425990Z",
     "start_time": "2024-04-11T22:05:49.200542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x = genfromtxt(data_features, delimiter=',')\n",
    "y_df = pd.read_csv(data_labels)\n",
    "y = y_df.values.flatten()  # Flatten if y is 2D\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Function to create time series dataset\n",
    "def create_series(x, y, timestep, overlap):\n",
    "    slide_step = int(timestep * (1 - overlap))\n",
    "    data_num = int((len(x) / slide_step) - 1)\n",
    "    dataset = np.ndarray(shape=(data_num, timestep, x.shape[1]))\n",
    "    labels = []\n",
    "\n",
    "    for i in range(data_num):\n",
    "        labels.append(y[slide_step * (i + 1) - 1])\n",
    "        for j in range(timestep):\n",
    "            dataset[i, j, :] = x[slide_step * i + j, :]\n",
    "\n",
    "    return dataset, np.array(labels)\n",
    "\n",
    "# Create time series\n",
    "timestep = 16  # Replace with your value\n",
    "overlap = 0.5  # Replace with your value\n",
    "X_series, y_series = create_series(x, y_encoded, timestep, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7842f098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:05:52.868073Z",
     "start_time": "2024-04-11T22:05:52.837641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(104856, 16, 3), X_test shape:(26214, 16, 3), y_train shape:(104856,), y_test shape:(26214,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_series, y_series, test_size=0.2, random_state=42)\n",
    "print(f'X_train shape:{X_train.shape}, X_test shape:{X_test.shape}, y_train shape:{y_train.shape}, y_test shape:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c86d475a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:05:54.219653Z",
     "start_time": "2024-04-11T22:05:54.201448Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64)  # Assuming y_train is already encoded as class indexes\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3d9c472",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:05:55.599325Z",
     "start_time": "2024-04-11T22:05:55.584803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56b1440b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:05:56.885981Z",
     "start_time": "2024-04-11T22:05:56.878161Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the Transformer model\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, input_dim, head_size, n_heads, ff_dim, dropout=0.0):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=input_dim, num_heads=n_heads, dropout=dropout)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=ff_dim, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=ff_dim, out_channels=input_dim, kernel_size=1)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # LayerNorm and Multi-head Attention\n",
    "        x = self.norm1(src)\n",
    "        x, _ = self.attention(x, x, x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x + src  # skip connection\n",
    "\n",
    "        # Feed Forward\n",
    "        x = self.norm2(x)\n",
    "        x = x.permute(1, 2, 0)  # Conv1D expects (batch_size, channels, length)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.permute(2, 0, 1)  # back to (length, batch_size, channels)\n",
    "        x = x + src  # skip connection\n",
    "        return x\n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, sequence_length, num_features, head_size, n_heads, ff_dim, n_trans_blocks, mlp_units, drop=0.0, mlp_drop=0.0):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        self.encoders = nn.ModuleList([TransformerEncoderBlock(num_features, head_size, n_heads, ff_dim, drop) for _ in range(n_trans_blocks)])\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        mlp_layers = []\n",
    "        current_dim = num_features\n",
    "        for dim in mlp_units:\n",
    "            mlp_layers.append(nn.Linear(current_dim, dim))\n",
    "            mlp_layers.append(nn.ReLU())\n",
    "            mlp_layers.append(nn.Dropout(mlp_drop))\n",
    "            current_dim = dim  # Set input dim for the next layer\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        self.final_layer = nn.Linear(mlp_units[-1], 6)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = src.permute(1, 0, 2)  # Transformer expects (seq_len, batch_size, features)\n",
    "        for encoder in self.encoders:\n",
    "            src = encoder(src)\n",
    "\n",
    "        # Global average pooling\n",
    "        src = src.permute(1, 2, 0)  # pooling expects (batch_size, channels, length)\n",
    "        src = self.global_avg_pooling(src)\n",
    "        src = torch.flatten(src, 1)  # Flatten the output for the MLP\n",
    "\n",
    "        # MLP\n",
    "        src = self.mlp(src)\n",
    "        output = self.final_layer(src)\n",
    "        return output\n",
    "\n",
    "# Input parameters for your data\n",
    "sequence_length = 16  # The length of the time series sequences in your data\n",
    "num_features = 3     # The number of features in each time step of your data sequence\n",
    "\n",
    "# Instantiate the model\n",
    "# Instantiate the model with an adjusted number of heads and head size\n",
    "# The head size must be a multiple of num_features.\n",
    "model = TimeSeriesTransformer(\n",
    "    sequence_length=16, \n",
    "    num_features=3, \n",
    "    head_size=3,  # Each head will now have an embed size of 1 (3 / 3)\n",
    "    n_heads=1,  # Only one head since our embed_dim is 3\n",
    "    ff_dim=64, \n",
    "    n_trans_blocks=4, \n",
    "    mlp_units=[128, 64], \n",
    "    drop=0.1, \n",
    "    mlp_drop=0.1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bde95e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:05:59.338632Z",
     "start_time": "2024-04-11T22:05:59.327026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "TimeSeriesTransformer(\n  (encoders): ModuleList(\n    (0-3): 4 x TransformerEncoderBlock(\n      (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n      (attention): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n      )\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n      (conv2): Conv1d(64, 3, kernel_size=(1,), stride=(1,))\n      (dropout2): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (global_avg_pooling): AdaptiveAvgPool1d(output_size=1)\n  (mlp): Sequential(\n    (0): Linear(in_features=3, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=128, out_features=64, bias=True)\n    (4): ReLU()\n    (5): Dropout(p=0.1, inplace=False)\n  )\n  (final_layer): Linear(in_features=64, out_features=6, bias=True)\n)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ab86147",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:17:00.006116Z",
     "start_time": "2024-04-11T22:06:17.110118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/3277], Loss: 1.3120, Accuracy: 50.72%\n",
      "Epoch [1/10], Step [200/3277], Loss: 1.1600, Accuracy: 57.59%\n",
      "Epoch [1/10], Step [300/3277], Loss: 1.0515, Accuracy: 62.16%\n",
      "Epoch [1/10], Step [400/3277], Loss: 0.9524, Accuracy: 66.78%\n",
      "Epoch [1/10], Step [500/3277], Loss: 0.8611, Accuracy: 70.25%\n",
      "Epoch [1/10], Step [600/3277], Loss: 0.8112, Accuracy: 72.88%\n",
      "Epoch [1/10], Step [700/3277], Loss: 0.8269, Accuracy: 71.94%\n",
      "Epoch [1/10], Step [800/3277], Loss: 0.7590, Accuracy: 72.72%\n",
      "Epoch [1/10], Step [900/3277], Loss: 0.7629, Accuracy: 74.47%\n",
      "Epoch [1/10], Step [1000/3277], Loss: 0.7459, Accuracy: 74.84%\n",
      "Epoch [1/10], Step [1100/3277], Loss: 0.7474, Accuracy: 73.66%\n",
      "Epoch [1/10], Step [1200/3277], Loss: 0.7222, Accuracy: 74.94%\n",
      "Epoch [1/10], Step [1300/3277], Loss: 0.7406, Accuracy: 74.41%\n",
      "Epoch [1/10], Step [1400/3277], Loss: 0.6964, Accuracy: 75.81%\n",
      "Epoch [1/10], Step [1500/3277], Loss: 0.7492, Accuracy: 73.72%\n",
      "Epoch [1/10], Step [1600/3277], Loss: 0.7413, Accuracy: 73.56%\n",
      "Epoch [1/10], Step [1700/3277], Loss: 0.7236, Accuracy: 74.16%\n",
      "Epoch [1/10], Step [1800/3277], Loss: 0.6924, Accuracy: 75.91%\n",
      "Epoch [1/10], Step [1900/3277], Loss: 0.6818, Accuracy: 76.72%\n",
      "Epoch [1/10], Step [2000/3277], Loss: 0.7082, Accuracy: 74.97%\n",
      "Epoch [1/10], Step [2100/3277], Loss: 0.6996, Accuracy: 76.25%\n",
      "Epoch [1/10], Step [2200/3277], Loss: 0.6744, Accuracy: 76.62%\n",
      "Epoch [1/10], Step [2300/3277], Loss: 0.7087, Accuracy: 74.72%\n",
      "Epoch [1/10], Step [2400/3277], Loss: 0.6802, Accuracy: 76.31%\n",
      "Epoch [1/10], Step [2500/3277], Loss: 0.7252, Accuracy: 75.12%\n",
      "Epoch [1/10], Step [2600/3277], Loss: 0.6814, Accuracy: 76.16%\n",
      "Epoch [1/10], Step [2700/3277], Loss: 0.6528, Accuracy: 77.78%\n",
      "Epoch [1/10], Step [2800/3277], Loss: 0.7048, Accuracy: 75.25%\n",
      "Epoch [1/10], Step [2900/3277], Loss: 0.6585, Accuracy: 76.25%\n",
      "Epoch [1/10], Step [3000/3277], Loss: 0.6667, Accuracy: 77.06%\n",
      "Epoch [1/10], Step [3100/3277], Loss: 0.6793, Accuracy: 75.66%\n",
      "Epoch [1/10], Step [3200/3277], Loss: 0.6618, Accuracy: 76.94%\n",
      "Epoch [2/10], Step [100/3277], Loss: 0.6394, Accuracy: 78.12%\n",
      "Epoch [2/10], Step [200/3277], Loss: 0.6511, Accuracy: 77.44%\n",
      "Epoch [2/10], Step [300/3277], Loss: 0.6500, Accuracy: 77.34%\n",
      "Epoch [2/10], Step [400/3277], Loss: 0.6680, Accuracy: 77.03%\n",
      "Epoch [2/10], Step [500/3277], Loss: 0.6677, Accuracy: 76.88%\n",
      "Epoch [2/10], Step [600/3277], Loss: 0.6364, Accuracy: 77.81%\n",
      "Epoch [2/10], Step [700/3277], Loss: 0.6486, Accuracy: 77.22%\n",
      "Epoch [2/10], Step [800/3277], Loss: 0.6692, Accuracy: 77.00%\n",
      "Epoch [2/10], Step [900/3277], Loss: 0.6592, Accuracy: 76.38%\n",
      "Epoch [2/10], Step [1000/3277], Loss: 0.6637, Accuracy: 77.19%\n",
      "Epoch [2/10], Step [1100/3277], Loss: 0.6498, Accuracy: 77.53%\n",
      "Epoch [2/10], Step [1200/3277], Loss: 0.6398, Accuracy: 78.00%\n",
      "Epoch [2/10], Step [1300/3277], Loss: 0.6410, Accuracy: 77.47%\n",
      "Epoch [2/10], Step [1400/3277], Loss: 0.6690, Accuracy: 76.47%\n",
      "Epoch [2/10], Step [1500/3277], Loss: 0.6407, Accuracy: 77.69%\n",
      "Epoch [2/10], Step [1600/3277], Loss: 0.6721, Accuracy: 75.81%\n",
      "Epoch [2/10], Step [1700/3277], Loss: 0.6836, Accuracy: 75.53%\n",
      "Epoch [2/10], Step [1800/3277], Loss: 0.6751, Accuracy: 76.47%\n",
      "Epoch [2/10], Step [1900/3277], Loss: 0.6345, Accuracy: 78.19%\n",
      "Epoch [2/10], Step [2000/3277], Loss: 0.6188, Accuracy: 78.00%\n",
      "Epoch [2/10], Step [2100/3277], Loss: 0.6753, Accuracy: 76.09%\n",
      "Epoch [2/10], Step [2200/3277], Loss: 0.6521, Accuracy: 76.97%\n",
      "Epoch [2/10], Step [2300/3277], Loss: 0.6389, Accuracy: 77.31%\n",
      "Epoch [2/10], Step [2400/3277], Loss: 0.6300, Accuracy: 78.91%\n",
      "Epoch [2/10], Step [2500/3277], Loss: 0.6635, Accuracy: 77.16%\n",
      "Epoch [2/10], Step [2600/3277], Loss: 0.6225, Accuracy: 78.56%\n",
      "Epoch [2/10], Step [2700/3277], Loss: 0.6597, Accuracy: 77.75%\n",
      "Epoch [2/10], Step [2800/3277], Loss: 0.6694, Accuracy: 76.59%\n",
      "Epoch [2/10], Step [2900/3277], Loss: 0.6373, Accuracy: 78.09%\n",
      "Epoch [2/10], Step [3000/3277], Loss: 0.6427, Accuracy: 76.72%\n",
      "Epoch [2/10], Step [3100/3277], Loss: 0.6493, Accuracy: 77.41%\n",
      "Epoch [2/10], Step [3200/3277], Loss: 0.6365, Accuracy: 77.91%\n",
      "Epoch [3/10], Step [100/3277], Loss: 0.6650, Accuracy: 76.53%\n",
      "Epoch [3/10], Step [200/3277], Loss: 0.6286, Accuracy: 78.31%\n",
      "Epoch [3/10], Step [300/3277], Loss: 0.6544, Accuracy: 77.97%\n",
      "Epoch [3/10], Step [400/3277], Loss: 0.6019, Accuracy: 79.38%\n",
      "Epoch [3/10], Step [500/3277], Loss: 0.6622, Accuracy: 76.69%\n",
      "Epoch [3/10], Step [600/3277], Loss: 0.6150, Accuracy: 79.16%\n",
      "Epoch [3/10], Step [700/3277], Loss: 0.6291, Accuracy: 77.41%\n",
      "Epoch [3/10], Step [800/3277], Loss: 0.6560, Accuracy: 76.81%\n",
      "Epoch [3/10], Step [900/3277], Loss: 0.6152, Accuracy: 78.81%\n",
      "Epoch [3/10], Step [1000/3277], Loss: 0.6094, Accuracy: 78.50%\n",
      "Epoch [3/10], Step [1100/3277], Loss: 0.6397, Accuracy: 77.59%\n",
      "Epoch [3/10], Step [1200/3277], Loss: 0.6379, Accuracy: 77.41%\n",
      "Epoch [3/10], Step [1300/3277], Loss: 0.6406, Accuracy: 77.81%\n",
      "Epoch [3/10], Step [1400/3277], Loss: 0.6355, Accuracy: 78.28%\n",
      "Epoch [3/10], Step [1500/3277], Loss: 0.6421, Accuracy: 77.50%\n",
      "Epoch [3/10], Step [1600/3277], Loss: 0.6798, Accuracy: 76.44%\n",
      "Epoch [3/10], Step [1700/3277], Loss: 0.6403, Accuracy: 77.53%\n",
      "Epoch [3/10], Step [1800/3277], Loss: 0.6181, Accuracy: 78.31%\n",
      "Epoch [3/10], Step [1900/3277], Loss: 0.6096, Accuracy: 78.22%\n",
      "Epoch [3/10], Step [2000/3277], Loss: 0.6263, Accuracy: 77.91%\n",
      "Epoch [3/10], Step [2100/3277], Loss: 0.6425, Accuracy: 77.78%\n",
      "Epoch [3/10], Step [2200/3277], Loss: 0.6432, Accuracy: 77.00%\n",
      "Epoch [3/10], Step [2300/3277], Loss: 0.6520, Accuracy: 77.03%\n",
      "Epoch [3/10], Step [2400/3277], Loss: 0.6230, Accuracy: 78.56%\n",
      "Epoch [3/10], Step [2500/3277], Loss: 0.6503, Accuracy: 77.12%\n",
      "Epoch [3/10], Step [2600/3277], Loss: 0.6383, Accuracy: 77.59%\n",
      "Epoch [3/10], Step [2700/3277], Loss: 0.6314, Accuracy: 77.94%\n",
      "Epoch [3/10], Step [2800/3277], Loss: 0.6147, Accuracy: 78.88%\n",
      "Epoch [3/10], Step [2900/3277], Loss: 0.6261, Accuracy: 77.44%\n",
      "Epoch [3/10], Step [3000/3277], Loss: 0.6098, Accuracy: 78.66%\n",
      "Epoch [3/10], Step [3100/3277], Loss: 0.6391, Accuracy: 77.97%\n",
      "Epoch [3/10], Step [3200/3277], Loss: 0.6163, Accuracy: 77.91%\n",
      "Epoch [4/10], Step [100/3277], Loss: 0.6395, Accuracy: 78.00%\n",
      "Epoch [4/10], Step [200/3277], Loss: 0.6292, Accuracy: 77.06%\n",
      "Epoch [4/10], Step [300/3277], Loss: 0.6547, Accuracy: 77.38%\n",
      "Epoch [4/10], Step [400/3277], Loss: 0.6454, Accuracy: 77.78%\n",
      "Epoch [4/10], Step [500/3277], Loss: 0.6116, Accuracy: 79.12%\n",
      "Epoch [4/10], Step [600/3277], Loss: 0.6200, Accuracy: 78.38%\n",
      "Epoch [4/10], Step [700/3277], Loss: 0.5870, Accuracy: 79.47%\n",
      "Epoch [4/10], Step [800/3277], Loss: 0.6652, Accuracy: 76.91%\n",
      "Epoch [4/10], Step [900/3277], Loss: 0.6273, Accuracy: 78.28%\n",
      "Epoch [4/10], Step [1000/3277], Loss: 0.6193, Accuracy: 77.84%\n",
      "Epoch [4/10], Step [1100/3277], Loss: 0.6441, Accuracy: 76.91%\n",
      "Epoch [4/10], Step [1200/3277], Loss: 0.6570, Accuracy: 76.94%\n",
      "Epoch [4/10], Step [1300/3277], Loss: 0.6047, Accuracy: 78.91%\n",
      "Epoch [4/10], Step [1400/3277], Loss: 0.6293, Accuracy: 77.69%\n",
      "Epoch [4/10], Step [1500/3277], Loss: 0.6223, Accuracy: 78.19%\n",
      "Epoch [4/10], Step [1600/3277], Loss: 0.6066, Accuracy: 78.62%\n",
      "Epoch [4/10], Step [1700/3277], Loss: 0.6368, Accuracy: 78.09%\n",
      "Epoch [4/10], Step [1800/3277], Loss: 0.6156, Accuracy: 78.34%\n",
      "Epoch [4/10], Step [1900/3277], Loss: 0.6021, Accuracy: 78.72%\n",
      "Epoch [4/10], Step [2000/3277], Loss: 0.6218, Accuracy: 78.03%\n",
      "Epoch [4/10], Step [2100/3277], Loss: 0.6117, Accuracy: 78.31%\n",
      "Epoch [4/10], Step [2200/3277], Loss: 0.6200, Accuracy: 78.22%\n",
      "Epoch [4/10], Step [2300/3277], Loss: 0.6193, Accuracy: 77.81%\n",
      "Epoch [4/10], Step [2400/3277], Loss: 0.6149, Accuracy: 78.06%\n",
      "Epoch [4/10], Step [2500/3277], Loss: 0.6131, Accuracy: 79.00%\n",
      "Epoch [4/10], Step [2600/3277], Loss: 0.6744, Accuracy: 76.00%\n",
      "Epoch [4/10], Step [2700/3277], Loss: 0.6449, Accuracy: 77.47%\n",
      "Epoch [4/10], Step [2800/3277], Loss: 0.6335, Accuracy: 77.19%\n",
      "Epoch [4/10], Step [2900/3277], Loss: 0.6284, Accuracy: 78.06%\n",
      "Epoch [4/10], Step [3000/3277], Loss: 0.6463, Accuracy: 77.47%\n",
      "Epoch [4/10], Step [3100/3277], Loss: 0.5875, Accuracy: 79.38%\n",
      "Epoch [4/10], Step [3200/3277], Loss: 0.6337, Accuracy: 78.31%\n",
      "Epoch [5/10], Step [100/3277], Loss: 0.6211, Accuracy: 78.31%\n",
      "Epoch [5/10], Step [200/3277], Loss: 0.6175, Accuracy: 78.12%\n",
      "Epoch [5/10], Step [300/3277], Loss: 0.6374, Accuracy: 78.03%\n",
      "Epoch [5/10], Step [400/3277], Loss: 0.6117, Accuracy: 78.03%\n",
      "Epoch [5/10], Step [500/3277], Loss: 0.6256, Accuracy: 77.16%\n",
      "Epoch [5/10], Step [600/3277], Loss: 0.6219, Accuracy: 78.56%\n",
      "Epoch [5/10], Step [700/3277], Loss: 0.5893, Accuracy: 79.78%\n",
      "Epoch [5/10], Step [800/3277], Loss: 0.6412, Accuracy: 77.62%\n",
      "Epoch [5/10], Step [900/3277], Loss: 0.5984, Accuracy: 78.66%\n",
      "Epoch [5/10], Step [1000/3277], Loss: 0.6167, Accuracy: 77.69%\n",
      "Epoch [5/10], Step [1100/3277], Loss: 0.6181, Accuracy: 78.31%\n",
      "Epoch [5/10], Step [1200/3277], Loss: 0.6372, Accuracy: 76.75%\n",
      "Epoch [5/10], Step [1300/3277], Loss: 0.6166, Accuracy: 78.84%\n",
      "Epoch [5/10], Step [1400/3277], Loss: 0.6216, Accuracy: 78.25%\n",
      "Epoch [5/10], Step [1500/3277], Loss: 0.6236, Accuracy: 77.84%\n",
      "Epoch [5/10], Step [1600/3277], Loss: 0.6387, Accuracy: 77.44%\n",
      "Epoch [5/10], Step [1700/3277], Loss: 0.6231, Accuracy: 77.84%\n",
      "Epoch [5/10], Step [1800/3277], Loss: 0.6106, Accuracy: 78.16%\n",
      "Epoch [5/10], Step [1900/3277], Loss: 0.5893, Accuracy: 79.31%\n",
      "Epoch [5/10], Step [2000/3277], Loss: 0.6064, Accuracy: 78.72%\n",
      "Epoch [5/10], Step [2100/3277], Loss: 0.6179, Accuracy: 78.50%\n",
      "Epoch [5/10], Step [2200/3277], Loss: 0.6265, Accuracy: 77.66%\n",
      "Epoch [5/10], Step [2300/3277], Loss: 0.6078, Accuracy: 78.97%\n",
      "Epoch [5/10], Step [2400/3277], Loss: 0.6074, Accuracy: 78.91%\n",
      "Epoch [5/10], Step [2500/3277], Loss: 0.6192, Accuracy: 78.16%\n",
      "Epoch [5/10], Step [2600/3277], Loss: 0.6097, Accuracy: 78.66%\n",
      "Epoch [5/10], Step [2700/3277], Loss: 0.6079, Accuracy: 78.81%\n",
      "Epoch [5/10], Step [2800/3277], Loss: 0.6490, Accuracy: 77.25%\n",
      "Epoch [5/10], Step [2900/3277], Loss: 0.6131, Accuracy: 78.75%\n",
      "Epoch [5/10], Step [3000/3277], Loss: 0.6198, Accuracy: 77.47%\n",
      "Epoch [5/10], Step [3100/3277], Loss: 0.6277, Accuracy: 77.38%\n",
      "Epoch [5/10], Step [3200/3277], Loss: 0.6079, Accuracy: 78.28%\n",
      "Epoch [6/10], Step [100/3277], Loss: 0.6068, Accuracy: 78.44%\n",
      "Epoch [6/10], Step [200/3277], Loss: 0.6294, Accuracy: 77.06%\n",
      "Epoch [6/10], Step [300/3277], Loss: 0.6109, Accuracy: 78.06%\n",
      "Epoch [6/10], Step [400/3277], Loss: 0.5822, Accuracy: 79.50%\n",
      "Epoch [6/10], Step [500/3277], Loss: 0.5888, Accuracy: 78.72%\n",
      "Epoch [6/10], Step [600/3277], Loss: 0.5988, Accuracy: 79.50%\n",
      "Epoch [6/10], Step [700/3277], Loss: 0.5986, Accuracy: 78.88%\n",
      "Epoch [6/10], Step [800/3277], Loss: 0.5702, Accuracy: 79.56%\n",
      "Epoch [6/10], Step [900/3277], Loss: 0.6141, Accuracy: 78.19%\n",
      "Epoch [6/10], Step [1000/3277], Loss: 0.5800, Accuracy: 79.25%\n",
      "Epoch [6/10], Step [1100/3277], Loss: 0.6098, Accuracy: 78.84%\n",
      "Epoch [6/10], Step [1200/3277], Loss: 0.6070, Accuracy: 79.03%\n",
      "Epoch [6/10], Step [1300/3277], Loss: 0.5871, Accuracy: 79.84%\n",
      "Epoch [6/10], Step [1400/3277], Loss: 0.6041, Accuracy: 78.03%\n",
      "Epoch [6/10], Step [1500/3277], Loss: 0.6130, Accuracy: 78.00%\n",
      "Epoch [6/10], Step [1600/3277], Loss: 0.6396, Accuracy: 77.22%\n",
      "Epoch [6/10], Step [1700/3277], Loss: 0.6075, Accuracy: 79.25%\n",
      "Epoch [6/10], Step [1800/3277], Loss: 0.5745, Accuracy: 79.47%\n",
      "Epoch [6/10], Step [1900/3277], Loss: 0.5773, Accuracy: 79.62%\n",
      "Epoch [6/10], Step [2000/3277], Loss: 0.5815, Accuracy: 78.59%\n",
      "Epoch [6/10], Step [2100/3277], Loss: 0.5847, Accuracy: 79.69%\n",
      "Epoch [6/10], Step [2200/3277], Loss: 0.6137, Accuracy: 78.47%\n",
      "Epoch [6/10], Step [2300/3277], Loss: 0.5726, Accuracy: 79.34%\n",
      "Epoch [6/10], Step [2400/3277], Loss: 0.6244, Accuracy: 77.78%\n",
      "Epoch [6/10], Step [2500/3277], Loss: 0.6009, Accuracy: 78.78%\n",
      "Epoch [6/10], Step [2600/3277], Loss: 0.6276, Accuracy: 78.00%\n",
      "Epoch [6/10], Step [2700/3277], Loss: 0.5826, Accuracy: 80.31%\n",
      "Epoch [6/10], Step [2800/3277], Loss: 0.6258, Accuracy: 77.47%\n",
      "Epoch [6/10], Step [2900/3277], Loss: 0.5846, Accuracy: 79.56%\n",
      "Epoch [6/10], Step [3000/3277], Loss: 0.5893, Accuracy: 78.69%\n",
      "Epoch [6/10], Step [3100/3277], Loss: 0.6104, Accuracy: 78.91%\n",
      "Epoch [6/10], Step [3200/3277], Loss: 0.6232, Accuracy: 78.59%\n",
      "Epoch [7/10], Step [100/3277], Loss: 0.5760, Accuracy: 79.75%\n",
      "Epoch [7/10], Step [200/3277], Loss: 0.5985, Accuracy: 78.34%\n",
      "Epoch [7/10], Step [300/3277], Loss: 0.5915, Accuracy: 79.16%\n",
      "Epoch [7/10], Step [400/3277], Loss: 0.5693, Accuracy: 80.09%\n",
      "Epoch [7/10], Step [500/3277], Loss: 0.6089, Accuracy: 78.16%\n",
      "Epoch [7/10], Step [600/3277], Loss: 0.6225, Accuracy: 78.22%\n",
      "Epoch [7/10], Step [700/3277], Loss: 0.5893, Accuracy: 78.84%\n",
      "Epoch [7/10], Step [800/3277], Loss: 0.5918, Accuracy: 79.72%\n",
      "Epoch [7/10], Step [900/3277], Loss: 0.5919, Accuracy: 79.19%\n",
      "Epoch [7/10], Step [1000/3277], Loss: 0.6002, Accuracy: 78.62%\n",
      "Epoch [7/10], Step [1100/3277], Loss: 0.5961, Accuracy: 78.94%\n",
      "Epoch [7/10], Step [1200/3277], Loss: 0.6030, Accuracy: 78.91%\n",
      "Epoch [7/10], Step [1300/3277], Loss: 0.5922, Accuracy: 79.34%\n",
      "Epoch [7/10], Step [1400/3277], Loss: 0.5696, Accuracy: 79.41%\n",
      "Epoch [7/10], Step [1500/3277], Loss: 0.6064, Accuracy: 78.62%\n",
      "Epoch [7/10], Step [1600/3277], Loss: 0.5974, Accuracy: 78.88%\n",
      "Epoch [7/10], Step [1700/3277], Loss: 0.5684, Accuracy: 80.06%\n",
      "Epoch [7/10], Step [1800/3277], Loss: 0.5906, Accuracy: 79.47%\n",
      "Epoch [7/10], Step [1900/3277], Loss: 0.6065, Accuracy: 78.44%\n",
      "Epoch [7/10], Step [2000/3277], Loss: 0.6217, Accuracy: 78.09%\n",
      "Epoch [7/10], Step [2100/3277], Loss: 0.5869, Accuracy: 79.12%\n",
      "Epoch [7/10], Step [2200/3277], Loss: 0.5611, Accuracy: 81.12%\n",
      "Epoch [7/10], Step [2300/3277], Loss: 0.5819, Accuracy: 79.47%\n",
      "Epoch [7/10], Step [2400/3277], Loss: 0.6177, Accuracy: 78.25%\n",
      "Epoch [7/10], Step [2500/3277], Loss: 0.5701, Accuracy: 80.56%\n",
      "Epoch [7/10], Step [2600/3277], Loss: 0.5926, Accuracy: 78.78%\n",
      "Epoch [7/10], Step [2700/3277], Loss: 0.5764, Accuracy: 79.84%\n",
      "Epoch [7/10], Step [2800/3277], Loss: 0.6227, Accuracy: 78.28%\n",
      "Epoch [7/10], Step [2900/3277], Loss: 0.6126, Accuracy: 78.78%\n",
      "Epoch [7/10], Step [3000/3277], Loss: 0.6095, Accuracy: 78.75%\n",
      "Epoch [7/10], Step [3100/3277], Loss: 0.6093, Accuracy: 79.06%\n",
      "Epoch [7/10], Step [3200/3277], Loss: 0.6090, Accuracy: 78.34%\n",
      "Epoch [8/10], Step [100/3277], Loss: 0.5912, Accuracy: 79.59%\n",
      "Epoch [8/10], Step [200/3277], Loss: 0.6131, Accuracy: 79.03%\n",
      "Epoch [8/10], Step [300/3277], Loss: 0.5854, Accuracy: 79.44%\n",
      "Epoch [8/10], Step [400/3277], Loss: 0.5971, Accuracy: 78.66%\n",
      "Epoch [8/10], Step [500/3277], Loss: 0.5943, Accuracy: 78.12%\n",
      "Epoch [8/10], Step [600/3277], Loss: 0.5993, Accuracy: 78.66%\n",
      "Epoch [8/10], Step [700/3277], Loss: 0.5901, Accuracy: 79.22%\n",
      "Epoch [8/10], Step [800/3277], Loss: 0.5991, Accuracy: 79.00%\n",
      "Epoch [8/10], Step [900/3277], Loss: 0.5760, Accuracy: 79.75%\n",
      "Epoch [8/10], Step [1000/3277], Loss: 0.6454, Accuracy: 77.91%\n",
      "Epoch [8/10], Step [1100/3277], Loss: 0.5703, Accuracy: 79.59%\n",
      "Epoch [8/10], Step [1200/3277], Loss: 0.5652, Accuracy: 80.12%\n",
      "Epoch [8/10], Step [1300/3277], Loss: 0.5724, Accuracy: 79.56%\n",
      "Epoch [8/10], Step [1400/3277], Loss: 0.5957, Accuracy: 79.59%\n",
      "Epoch [8/10], Step [1500/3277], Loss: 0.5765, Accuracy: 79.66%\n",
      "Epoch [8/10], Step [1600/3277], Loss: 0.6009, Accuracy: 79.31%\n",
      "Epoch [8/10], Step [1700/3277], Loss: 0.5938, Accuracy: 78.91%\n",
      "Epoch [8/10], Step [1800/3277], Loss: 0.5983, Accuracy: 78.97%\n",
      "Epoch [8/10], Step [1900/3277], Loss: 0.5769, Accuracy: 79.28%\n",
      "Epoch [8/10], Step [2000/3277], Loss: 0.5794, Accuracy: 79.81%\n",
      "Epoch [8/10], Step [2100/3277], Loss: 0.5978, Accuracy: 78.78%\n",
      "Epoch [8/10], Step [2200/3277], Loss: 0.5713, Accuracy: 80.09%\n",
      "Epoch [8/10], Step [2300/3277], Loss: 0.6055, Accuracy: 79.00%\n",
      "Epoch [8/10], Step [2400/3277], Loss: 0.6197, Accuracy: 77.75%\n",
      "Epoch [8/10], Step [2500/3277], Loss: 0.5962, Accuracy: 79.59%\n",
      "Epoch [8/10], Step [2600/3277], Loss: 0.5725, Accuracy: 80.25%\n",
      "Epoch [8/10], Step [2700/3277], Loss: 0.5730, Accuracy: 79.97%\n",
      "Epoch [8/10], Step [2800/3277], Loss: 0.6003, Accuracy: 79.03%\n",
      "Epoch [8/10], Step [2900/3277], Loss: 0.5882, Accuracy: 79.38%\n",
      "Epoch [8/10], Step [3000/3277], Loss: 0.5893, Accuracy: 79.34%\n",
      "Epoch [8/10], Step [3100/3277], Loss: 0.5937, Accuracy: 79.66%\n",
      "Epoch [8/10], Step [3200/3277], Loss: 0.6175, Accuracy: 77.84%\n",
      "Epoch [9/10], Step [100/3277], Loss: 0.6031, Accuracy: 78.00%\n",
      "Epoch [9/10], Step [200/3277], Loss: 0.5961, Accuracy: 78.78%\n",
      "Epoch [9/10], Step [300/3277], Loss: 0.5816, Accuracy: 79.44%\n",
      "Epoch [9/10], Step [400/3277], Loss: 0.5787, Accuracy: 79.81%\n",
      "Epoch [9/10], Step [500/3277], Loss: 0.5632, Accuracy: 80.44%\n",
      "Epoch [9/10], Step [600/3277], Loss: 0.5674, Accuracy: 79.44%\n",
      "Epoch [9/10], Step [700/3277], Loss: 0.5892, Accuracy: 79.38%\n",
      "Epoch [9/10], Step [800/3277], Loss: 0.6128, Accuracy: 77.88%\n",
      "Epoch [9/10], Step [900/3277], Loss: 0.5910, Accuracy: 79.06%\n",
      "Epoch [9/10], Step [1000/3277], Loss: 0.5886, Accuracy: 79.16%\n",
      "Epoch [9/10], Step [1100/3277], Loss: 0.6013, Accuracy: 78.72%\n",
      "Epoch [9/10], Step [1200/3277], Loss: 0.5849, Accuracy: 79.75%\n",
      "Epoch [9/10], Step [1300/3277], Loss: 0.6052, Accuracy: 79.09%\n",
      "Epoch [9/10], Step [1400/3277], Loss: 0.5727, Accuracy: 80.25%\n",
      "Epoch [9/10], Step [1500/3277], Loss: 0.5972, Accuracy: 78.72%\n",
      "Epoch [9/10], Step [1600/3277], Loss: 0.5761, Accuracy: 79.72%\n",
      "Epoch [9/10], Step [1700/3277], Loss: 0.6231, Accuracy: 77.88%\n",
      "Epoch [9/10], Step [1800/3277], Loss: 0.5948, Accuracy: 79.53%\n",
      "Epoch [9/10], Step [1900/3277], Loss: 0.5735, Accuracy: 79.91%\n",
      "Epoch [9/10], Step [2000/3277], Loss: 0.5735, Accuracy: 80.06%\n",
      "Epoch [9/10], Step [2100/3277], Loss: 0.6090, Accuracy: 78.38%\n",
      "Epoch [9/10], Step [2200/3277], Loss: 0.6226, Accuracy: 78.09%\n",
      "Epoch [9/10], Step [2300/3277], Loss: 0.5974, Accuracy: 79.12%\n",
      "Epoch [9/10], Step [2400/3277], Loss: 0.5610, Accuracy: 80.38%\n",
      "Epoch [9/10], Step [2500/3277], Loss: 0.5874, Accuracy: 80.28%\n",
      "Epoch [9/10], Step [2600/3277], Loss: 0.5768, Accuracy: 79.84%\n",
      "Epoch [9/10], Step [2700/3277], Loss: 0.5719, Accuracy: 80.84%\n",
      "Epoch [9/10], Step [2800/3277], Loss: 0.5633, Accuracy: 80.41%\n",
      "Epoch [9/10], Step [2900/3277], Loss: 0.5758, Accuracy: 80.03%\n",
      "Epoch [9/10], Step [3000/3277], Loss: 0.5521, Accuracy: 80.69%\n",
      "Epoch [9/10], Step [3100/3277], Loss: 0.6081, Accuracy: 78.31%\n",
      "Epoch [9/10], Step [3200/3277], Loss: 0.6044, Accuracy: 78.81%\n",
      "Epoch [10/10], Step [100/3277], Loss: 0.5925, Accuracy: 79.38%\n",
      "Epoch [10/10], Step [200/3277], Loss: 0.5462, Accuracy: 81.25%\n",
      "Epoch [10/10], Step [300/3277], Loss: 0.5942, Accuracy: 79.03%\n",
      "Epoch [10/10], Step [400/3277], Loss: 0.5673, Accuracy: 80.34%\n",
      "Epoch [10/10], Step [500/3277], Loss: 0.5698, Accuracy: 80.16%\n",
      "Epoch [10/10], Step [600/3277], Loss: 0.5628, Accuracy: 80.72%\n",
      "Epoch [10/10], Step [700/3277], Loss: 0.5625, Accuracy: 80.19%\n",
      "Epoch [10/10], Step [800/3277], Loss: 0.5857, Accuracy: 79.59%\n",
      "Epoch [10/10], Step [900/3277], Loss: 0.5679, Accuracy: 80.59%\n",
      "Epoch [10/10], Step [1000/3277], Loss: 0.5728, Accuracy: 80.78%\n",
      "Epoch [10/10], Step [1100/3277], Loss: 0.5904, Accuracy: 79.22%\n",
      "Epoch [10/10], Step [1200/3277], Loss: 0.5711, Accuracy: 80.09%\n",
      "Epoch [10/10], Step [1300/3277], Loss: 0.6014, Accuracy: 78.78%\n",
      "Epoch [10/10], Step [1400/3277], Loss: 0.5884, Accuracy: 79.78%\n",
      "Epoch [10/10], Step [1500/3277], Loss: 0.5676, Accuracy: 80.47%\n",
      "Epoch [10/10], Step [1600/3277], Loss: 0.5792, Accuracy: 79.84%\n",
      "Epoch [10/10], Step [1700/3277], Loss: 0.5717, Accuracy: 80.31%\n",
      "Epoch [10/10], Step [1800/3277], Loss: 0.5733, Accuracy: 79.72%\n",
      "Epoch [10/10], Step [1900/3277], Loss: 0.5859, Accuracy: 79.62%\n",
      "Epoch [10/10], Step [2000/3277], Loss: 0.5586, Accuracy: 80.59%\n",
      "Epoch [10/10], Step [2100/3277], Loss: 0.5734, Accuracy: 79.91%\n",
      "Epoch [10/10], Step [2200/3277], Loss: 0.5832, Accuracy: 78.69%\n",
      "Epoch [10/10], Step [2300/3277], Loss: 0.5812, Accuracy: 79.53%\n",
      "Epoch [10/10], Step [2400/3277], Loss: 0.5455, Accuracy: 81.12%\n",
      "Epoch [10/10], Step [2500/3277], Loss: 0.5587, Accuracy: 80.16%\n",
      "Epoch [10/10], Step [2600/3277], Loss: 0.5982, Accuracy: 79.09%\n",
      "Epoch [10/10], Step [2700/3277], Loss: 0.5785, Accuracy: 79.91%\n",
      "Epoch [10/10], Step [2800/3277], Loss: 0.5931, Accuracy: 79.12%\n",
      "Epoch [10/10], Step [2900/3277], Loss: 0.6043, Accuracy: 78.91%\n",
      "Epoch [10/10], Step [3000/3277], Loss: 0.5765, Accuracy: 79.84%\n",
      "Epoch [10/10], Step [3100/3277], Loss: 0.5888, Accuracy: 79.69%\n",
      "Epoch [10/10], Step [3200/3277], Loss: 0.5890, Accuracy: 78.88%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], '\n",
    "                  f'Loss: {running_loss / 100:.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "# After training, you may want to save your model\n",
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "365f1ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:17:08.348876Z",
     "start_time": "2024-04-11T22:17:04.353842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8082\n",
      "Precision: 0.7816\n",
      "Recall: 0.8082\n",
      "F1 Score: 0.7809\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Collect all predictions and labels to compute overall metrics\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert collected predictions and labels to arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(all_targets, all_predictions, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfd3612c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:17:15.500544Z",
     "start_time": "2024-04-11T22:17:15.470193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model size is 60.75 KB\n"
     ]
    }
   ],
   "source": [
    "# Assume 'model' is the instance of TimeSeriesTransformer you have already defined and trained\n",
    "model_path = f'{MODELS_PATH}/transformer_base.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Get the size of the saved model file\n",
    "model_size = os.path.getsize(model_path)\n",
    "print(f\"The model size is {model_size/1024:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b340fe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:17:19.920490Z",
     "start_time": "2024-04-11T22:17:18.074230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model: 60.75 KB\n",
      "Accuracy on the test set: 80.82%\n",
      "CPU usage during inference: 37.60%\n",
      "Inference time: 1.8497 seconds\n"
     ]
    }
   ],
   "source": [
    "cpu_usage, inference_time, _ = measure_cpu_utilization_and_run(compute_metrics_base, model, X_test_tensor, y_test_tensor, model_path)\n",
    "\n",
    "print(f'CPU usage during inference: {cpu_usage:.2f}%')\n",
    "print(f'Inference time: {inference_time:.4f} seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834f3e1",
   "metadata": {},
   "source": [
    "### Coreml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(f'{MODELS_PATH}/transformer_base.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-11T21:53:47.437968Z",
     "start_time": "2024-04-11T21:53:47.419155Z"
    }
   },
   "id": "bca19da65161445d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **As April/2024: CoreML does not support nn.AdaptiveAvgPool1d conversion.**\n",
    "\n",
    "> As a workaround copy the changes from coremltools/converters/mil/frontend/torch/ops.py and add them to your installed copy of that file.\n",
    "\n",
    "> [Github](https://github.com/TobyRoseman/coremltools/blob/2982c6c6e3aa28ce282efdda65a25a70ffe93f76/coremltools/converters/mil/frontend/torch/ops.py)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43a78afe8c3f738d"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8334c01d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:17:30.544205Z",
     "start_time": "2024-04-11T22:17:29.606048Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 396/397 [00:00<00:00, 9849.05 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 707.02 passes/s]\n",
      "Running MIL default pipeline:   0%|          | 0/71 [00:00<?, ? passes/s]/opt/homebrew/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:239: UserWarning: Input, 'src.1', of the source model, has been renamed to 'src_1' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL default pipeline: 100%|██████████| 71/71 [00:00<00:00, 221.19 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 1455.81 passes/s]\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "example_input = torch.rand(1,16, 3) \n",
    "\n",
    "model.eval()\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "out = traced_model(example_input)\n",
    "\n",
    "# Convert to Core ML program using the Unified Conversion API.\n",
    "transformer_coreml_model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.TensorType(shape=example_input.shape)]\n",
    " )\n",
    "\n",
    "transformer_coreml_model.save(f'{MODELS_PATH}/transformer.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db3e3715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:17:32.384990Z",
     "start_time": "2024-04-11T22:17:32.371954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "input {\n  name: \"src_1\"\n  type {\n    multiArrayType {\n      shape: 1\n      shape: 16\n      shape: 3\n      dataType: FLOAT32\n    }\n  }\n}\noutput {\n  name: \"linear_10\"\n  type {\n    multiArrayType {\n      shape: 1\n      shape: 6\n      dataType: FLOAT32\n    }\n  }\n}\nmetadata {\n  userDefined {\n    key: \"com.github.apple.coremltools.source\"\n    value: \"torch==2.0.0\"\n  }\n  userDefined {\n    key: \"com.github.apple.coremltools.source_dialect\"\n    value: \"TorchScript\"\n  }\n  userDefined {\n    key: \"com.github.apple.coremltools.version\"\n    value: \"7.1\"\n  }\n}"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_coreml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4982fa3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:17:33.360700Z",
     "start_time": "2024-04-11T22:17:33.346056Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def coreml_metrics(model_name, X_test, y_test, model_path):\n",
    "    predictions = []\n",
    "    for id in range(len(X_test)):\n",
    "        X_test_new = np.expand_dims(X_test[id], axis=0)\n",
    "        output_dict = model_name.predict({'src_1': X_test_new})\n",
    "        pred_class = np.argmax(output_dict['linear_10'])\n",
    "        predictions.append(pred_class)\n",
    "    \n",
    "    accuracy = np.sum(predictions == y_test) / len(predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    model_file = Path(model_path)\n",
    "    \n",
    "    # Size in bytes\n",
    "    model_size_bytes = model_file.stat().st_size\n",
    "    \n",
    "    # Convert size to kilobytes (optional)\n",
    "    model_size_kb = model_size_bytes / 1024\n",
    "    print(f\"Size of the model: {model_size_kb:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d06bf0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T21:53:52.046842Z",
     "start_time": "2024-04-11T21:53:52.033726Z"
    }
   },
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "import coremltools.optimize.coreml as cto\n",
    "\n",
    "# gru_coreml_model = ct.models.MLModel(f'{MODELS_PATH}/transformer.mlpackage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e639e745",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T22:17:39.623735Z",
     "start_time": "2024-04-11T22:17:36.883204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8082322423132677\n",
      "Size of the model: 0.12 KB\n"
     ]
    }
   ],
   "source": [
    "model_name = transformer_coreml_model\n",
    "model_path = f'{MODELS_PATH}/transformer.mlpackage'\n",
    "\n",
    "coreml_metrics(model_name, X_test, y_test, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Post Training Optimization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fad5f791e051af3"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "from coremltools.optimize.coreml import (\n",
    "    OpThresholdPrunerConfig,\n",
    "    OpMagnitudePrunerConfig,\n",
    "    OpPalettizerConfig,\n",
    "    OpLinearQuantizerConfig,\n",
    "    OptimizationConfig,\n",
    "    prune_weights,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:01:57.006104Z",
     "start_time": "2024-04-19T22:01:56.994359Z"
    }
   },
   "id": "991594dd63e20000"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quantization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8e5dd2d421080f6"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass linear_quantize_weights: 100%|██████████| 21/21 [00:00<00:00, 18423.00 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 69/69 [00:00<00:00, 468.50 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 1076.82 passes/s]\n"
     ]
    }
   ],
   "source": [
    "op_config = OpLinearQuantizerConfig(\n",
    "    mode=\"linear_symmetric\", weight_threshold=512\n",
    ")\n",
    "config = OptimizationConfig(global_config=op_config)\n",
    "\n",
    "compressed_8_bit_model = cto.linear_quantize_weights(transformer_coreml_model, config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:02:18.707529Z",
     "start_time": "2024-04-19T22:02:18.260300Z"
    }
   },
   "id": "24755a7d74a79273"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "compressed_8_bit_model.save(f'{MODELS_PATH}/transformer_8bitQuantized_mlmodel.mlpackage')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:02:25.095136Z",
     "start_time": "2024-04-19T22:02:25.065843Z"
    }
   },
   "id": "99eefa198b56e281"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8081559472037843\n",
      "Size of the model: 0.12 KB\n"
     ]
    }
   ],
   "source": [
    "model_name = compressed_8_bit_model\n",
    "model_path = f'{MODELS_PATH}/transformer_8bitQuantized_mlmodel.mlpackage'\n",
    "\n",
    "coreml_metrics(model_name, X_test, y_test, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:02:37.631674Z",
     "start_time": "2024-04-19T22:02:34.222472Z"
    }
   },
   "id": "c7174ba492ab9c92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pruning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2693f08414d1c856"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### a) OpMagnitudePrunerConfig: Prune the weights with a constant sparsity percentile"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ea07281b86796b8"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass prune_weights: 100%|██████████| 21/21 [00:00<00:00, 9186.52 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 69/69 [00:00<00:00, 471.94 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 1136.26 passes/s]\n"
     ]
    }
   ],
   "source": [
    "op_config = OpMagnitudePrunerConfig(\n",
    "    target_sparsity=0.6,\n",
    "    weight_threshold=1024,\n",
    ")\n",
    "config = OptimizationConfig(global_config=op_config)\n",
    "transformer_magnitude_pruner = prune_weights(transformer_coreml_model, config=config)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:03:01.285711Z",
     "start_time": "2024-04-19T22:03:00.836512Z"
    }
   },
   "id": "b2cea191cd23e003"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "transformer_magnitude_pruner.save(f'{MODELS_PATH}/transformer_magnitude_pruner.mlpackage')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:03:12.243456Z",
     "start_time": "2024-04-19T22:03:12.220535Z"
    }
   },
   "id": "8876df3f1b0a4d09"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7955291065842679\n",
      "Size of the model: 0.12 KB\n"
     ]
    }
   ],
   "source": [
    "model_name = transformer_magnitude_pruner\n",
    "model_path = f'{MODELS_PATH}/transformer_magnitude_pruner.mlpackage'\n",
    "\n",
    "coreml_metrics(model_name, X_test, y_test, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:03:20.280783Z",
     "start_time": "2024-04-19T22:03:16.540157Z"
    }
   },
   "id": "1c0af939cc45f320"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### b) OpThresholdPrunerConfig: Sets all weight values below a certain value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62241f70368f235b"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass prune_weights:   0%|          | 0/21 [00:00<?, ? ops/s]weight value has sparsity of 0.005615234375 < minimum_sparsity_percentile 0.01. Skipped.\n",
      "Running compression pass prune_weights: 100%|██████████| 21/21 [00:00<00:00, 22848.35 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 69/69 [00:00<00:00, 487.32 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 1194.25 passes/s]\n"
     ]
    }
   ],
   "source": [
    "op_config = OpThresholdPrunerConfig(\n",
    "    threshold=0.001,\n",
    "    minimum_sparsity_percentile=0.01,\n",
    "    weight_threshold=1024,\n",
    ")\n",
    "\n",
    "config = OptimizationConfig(global_config=op_config)\n",
    "transformer_threshold_pruner = prune_weights(transformer_coreml_model, config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:03:31.246767Z",
     "start_time": "2024-04-19T22:03:30.811975Z"
    }
   },
   "id": "de866acf0f3751bd"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "transformer_threshold_pruner.save(f'{MODELS_PATH}/transformer_threshold_pruner.mlpackage')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:03:53.185908Z",
     "start_time": "2024-04-19T22:03:53.167836Z"
    }
   },
   "id": "c3e4d123fd6b761c"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8082322423132677\n",
      "Size of the model: 0.12 KB\n"
     ]
    }
   ],
   "source": [
    "model_name = transformer_threshold_pruner\n",
    "model_path = f'{MODELS_PATH}/transformer_threshold_pruner.mlpackage'\n",
    "\n",
    "coreml_metrics(model_name, X_test, y_test, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:03:57.933983Z",
     "start_time": "2024-04-19T22:03:54.771311Z"
    }
   },
   "id": "a6435a75c11bf4b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Palletization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9368f6c572a9eda"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass palettize_weights: 100%|██████████| 21/21 [00:00<00:00, 112.62 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 69/69 [00:00<00:00, 275.30 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 1120.77 passes/s]\n"
     ]
    }
   ],
   "source": [
    "op_config = OpPalettizerConfig(\n",
    "    mode=\"kmeans\", \n",
    "    nbits=6\n",
    ")\n",
    "\n",
    "config = OptimizationConfig(global_config=op_config)\n",
    "transformer_palettizer = cto.palettize_weights(transformer_coreml_model, config=config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:04:08.970310Z",
     "start_time": "2024-04-19T22:04:08.228789Z"
    }
   },
   "id": "7998263df97d320c"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "transformer_palettizer.save(f'{MODELS_PATH}/transformer_palettizer.mlpackage')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:04:20.285029Z",
     "start_time": "2024-04-19T22:04:20.262567Z"
    }
   },
   "id": "ecbe91e459dcda12"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8082703898680095\n",
      "Size of the model: 0.12 KB\n"
     ]
    }
   ],
   "source": [
    "model_name = transformer_palettizer\n",
    "model_path = f'{MODELS_PATH}/transformer_palettizer.mlpackage'\n",
    "\n",
    "coreml_metrics(model_name, X_test, y_test, model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T22:04:25.642424Z",
     "start_time": "2024-04-19T22:04:22.470412Z"
    }
   },
   "id": "5e30e087d9ad8449"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "29f829d6cba0396"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
