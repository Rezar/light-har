{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sPHNxudGuMO"
   },
   "source": [
    "### **Data Preprocessing**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UF_fkc-rEH5Q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u9gSA8uiEilq"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x = genfromtxt('../Data/WISDM_x.csv', delimiter=',')\n",
    "y_df = pd.read_csv('../Data/WISDM_y.csv')\n",
    "y = y_df.values.flatten()  # Flatten if y is 2D\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Function to create time series dataset\n",
    "def create_series(x, y, timestep, overlap):\n",
    "    slide_step = int(timestep * (1 - overlap))\n",
    "    data_num = int((len(x) / slide_step) - 1)\n",
    "    dataset = np.ndarray(shape=(data_num, timestep, x.shape[1]))\n",
    "    labels = []\n",
    "\n",
    "    for i in range(data_num):\n",
    "        labels.append(y[slide_step * (i + 1) - 1])\n",
    "        for j in range(timestep):\n",
    "            dataset[i, j, :] = x[slide_step * i + j, :]\n",
    "\n",
    "    return dataset, np.array(labels)\n",
    "\n",
    "# Create time series\n",
    "timestep = 16  # Replace with your value\n",
    "overlap = 0.5  # Replace with your value\n",
    "X_series, y_series = create_series(x, y_encoded, timestep, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gLppIs7ZEiof"
   },
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_series, y_series, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, n_steps):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.hidden_size1 = hidden_size1\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.lstm2 = nn.LSTM(hidden_size1, hidden_size2, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size1).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size1).to(x.device)\n",
    "        \n",
    "        # First LSTM layer\n",
    "        out, _ = self.lstm1(x, (h0, c0))\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        # Second LSTM layer\n",
    "        h1 = torch.zeros(1, x.size(0), self.hidden_size2).to(x.device)\n",
    "        c1 = torch.zeros(1, x.size(0), self.hidden_size2).to(x.device)\n",
    "        out, _ = self.lstm2(out, (h1, c1))\n",
    "        out = self.dropout2(out)\n",
    "\n",
    "        # Dense layer\n",
    "        out = self.fc(out[:, -1, :]) # Taking the last time step\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_size = 3  # Number of features\n",
    "hidden_size1 = 50\n",
    "hidden_size2 = 25\n",
    "output_size = 6\n",
    "n_steps = 16\n",
    "\n",
    "# Create the model\n",
    "model = LSTMNet(input_size, hidden_size1, hidden_size2, output_size, n_steps)\n",
    "\n",
    "# Training setup (for demonstration)\n",
    "# Define your dataset here\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.int64))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.5917, Accuracy: 79.39%\n",
      "Epoch [2/20], Loss: 0.3647, Accuracy: 87.25%\n",
      "Epoch [3/20], Loss: 0.2918, Accuracy: 90.15%\n",
      "Epoch [4/20], Loss: 0.2531, Accuracy: 91.54%\n",
      "Epoch [5/20], Loss: 0.2271, Accuracy: 92.47%\n",
      "Epoch [6/20], Loss: 0.2097, Accuracy: 93.16%\n",
      "Epoch [7/20], Loss: 0.1971, Accuracy: 93.55%\n",
      "Epoch [8/20], Loss: 0.1855, Accuracy: 93.85%\n",
      "Epoch [9/20], Loss: 0.1755, Accuracy: 94.33%\n",
      "Epoch [10/20], Loss: 0.1681, Accuracy: 94.54%\n",
      "Epoch [11/20], Loss: 0.1625, Accuracy: 94.69%\n",
      "Epoch [12/20], Loss: 0.1569, Accuracy: 94.93%\n",
      "Epoch [13/20], Loss: 0.1486, Accuracy: 95.17%\n",
      "Epoch [14/20], Loss: 0.1452, Accuracy: 95.29%\n",
      "Epoch [15/20], Loss: 0.1409, Accuracy: 95.48%\n",
      "Epoch [16/20], Loss: 0.1362, Accuracy: 95.54%\n",
      "Epoch [17/20], Loss: 0.1346, Accuracy: 95.61%\n",
      "Epoch [18/20], Loss: 0.1297, Accuracy: 95.80%\n",
      "Epoch [19/20], Loss: 0.1260, Accuracy: 95.93%\n",
      "Epoch [20/20], Loss: 0.1232, Accuracy: 96.02%\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, loss_fn, optimizer, epochs=0):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "train(model, train_loader, loss_fn, optimizer, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1601, Test Accuracy: 0.9506\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.int64))\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "def evaluate(model, test_loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            y_pred = model(X_batch)\n",
    "            total_loss += loss_fn(y_pred, y_batch).item()\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "avg_loss, accuracy = evaluate(model, test_loader, loss_fn)\n",
    "print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/sandeep/Desktop/BUCourses/Project/saved_models/Pytorch/lstm_base.pth\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Coreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.4.0 is not supported. Minimum required version: 0.17. Maximum required version: 1.1.2. Disabling scikit-learn conversion API.\n",
      "XGBoost version 1.7.6 has not been tested with coremltools. You may run into unexpected errors. XGBoost 1.4.2 is the most recent version that has been tested.\n",
      "TensorFlow version 2.15.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
      "Converting PyTorch Frontend ==> MIL Ops:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉ | 113/114 [00:00<00:00, 12590.49 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 4402.08 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [00:00<00:00, 2451.58 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 12409.18 passes/s]\n"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "example_input = torch.rand(1,16, 3) \n",
    "\n",
    "model.eval()\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "out = traced_model(example_input)\n",
    "\n",
    "# Convert to Core ML program using the Unified Conversion API.\n",
    "mlp_coreml_model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.TensorType(shape=example_input.shape)]\n",
    " )\n",
    "\n",
    "# Save the converted model.\n",
    "mlp_coreml_model.save(\"lstm.mlpackage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Coreml Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def coreml_metrics(model_name, X_test, y_test, model_path):\n",
    "    predictions = []\n",
    "    for id in range(len(X_test)):\n",
    "        X_test_new = np.expand_dims(X_test[id], axis=0)\n",
    "        output_dict = model_name.predict({'x': X_test_new})\n",
    "        pred_class = np.argmax(output_dict['linear_0'])\n",
    "        predictions.append(pred_class)\n",
    "    \n",
    "    accuracy = np.sum(predictions == y_test) / len(predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    model_file = Path(model_path)\n",
    "    \n",
    "    # Size in bytes\n",
    "    model_size_bytes = model_file.stat().st_size\n",
    "    \n",
    "    # Convert size to kilobytes (optional)\n",
    "    model_size_kb = model_size_bytes / 1024\n",
    "    print(f\"Size of the model: {model_size_kb:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools as ct\n",
    "import coremltools.optimize.coreml as cto\n",
    "\n",
    "lstm_coreml_model = ct.models.MLModel(\"lstm.mlpackage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9505372427608815\n",
      "Size of the model: 0.12 KB\n"
     ]
    }
   ],
   "source": [
    "model_name = lstm_coreml_model\n",
    "model_path = \"lstm.mlpackage\"\n",
    "\n",
    "coreml_metrics(model_name, X_test, y_test, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-bit Quantization coreml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running compression pass linear_quantize_weights: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 2779.86 ops/s]\n",
      "Running MIL frontend_milinternal pipeline: 0 passes [00:00, ? passes/s]\n",
      "Running MIL default pipeline: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 2880.16 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 7130.14 passes/s]\n"
     ]
    }
   ],
   "source": [
    "import coremltools.optimize.coreml as cto\n",
    "\n",
    "op_config = cto.OpLinearQuantizerConfig(mode=\"linear_symmetric\", weight_threshold=512)\n",
    "config = cto.OptimizationConfig(global_config=op_config)\n",
    "\n",
    "lstm_compressed_8_bit_model = cto.linear_quantize_weights(lstm_coreml_model, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_compressed_8_bit_model.save(\"lstm_8bitQuantized_mlmodel.mlpackage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9505372427608815\n",
      "Size of the model: 0.12 KB\n"
     ]
    }
   ],
   "source": [
    "model_name = lstm_compressed_8_bit_model\n",
    "model_path = \"lstm_8bitQuantized_mlmodel.mlpackage\"\n",
    "\n",
    "coreml_metrics(model_name, X_test, y_test, model_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7sPHNxudGuMO"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
