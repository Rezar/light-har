{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Quantization of S4\n",
    "This notebook performed S4 Pytorch quantization. The API can only quantized the Linear() layer. The S4D kernel is built from nn.Parameters() and is not supported by the API. However, the current version run into kernel crash issue and unsuccesfully run the quantized the S4 model. Please see NNCF_quantization for an alternative to Pytroch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, openvino\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import the s4 model path\n",
    "import sys\n",
    "sys.path.append('/Users/poomchan/Developer/s4')\n",
    "\n",
    "import s4d\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "importlib.reload(s4d)\n",
    "\n",
    "import nncf\n",
    "from nncf.parameters import ModelType\n",
    "import openvino as ov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# Torch device configuration\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "    if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name(device)}\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = \"/Users/poomchan/Developer/light-har\"\n",
    "DATA_DIR = PROJECT_DIR + \"/data\"\n",
    "MODEL_DIR = PROJECT_DIR + \"/code/s4/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x = genfromtxt(PROJECT_DIR+'/data/WISDM_x.csv', delimiter=',')\n",
    "y_df = pd.read_csv(PROJECT_DIR+'/data/WISDM_y.csv')\n",
    "y = y_df.values.flatten()  # Flatten if y is 2D\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Function to create time series dataset\n",
    "def create_series(x, y, timestep, overlap):\n",
    "    slide_step = int(timestep * (1 - overlap))\n",
    "    data_num = int((len(x) / slide_step) - 1)\n",
    "    dataset = np.ndarray(shape=(data_num, timestep, x.shape[1]))\n",
    "    labels = []\n",
    "\n",
    "    for i in range(data_num):\n",
    "        labels.append(y[slide_step * (i + 1) - 1])\n",
    "        for j in range(timestep):\n",
    "            dataset[i, j, :] = x[slide_step * i + j, :]\n",
    "\n",
    "    return dataset, np.array(labels)\n",
    "\n",
    "# Create time series\n",
    "seq_length = 16\n",
    "overlap = 0.5\n",
    "X_series, y_series = create_series(x, y_encoded, seq_length, overlap)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_series, y_series, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Create a test Dataloader\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create a calibration Dataloader\n",
    "x_cal_tensor = x_train_tensor[:300]\n",
    "y_cal_tensor = y_train_tensor[:300]\n",
    "calibration_loader = DataLoader(TensorDataset(x_cal_tensor, y_cal_tensor), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S4Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_input,\n",
    "        d_output,\n",
    "        d_model=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.2,\n",
    "        lr=0.001,\n",
    "        dropout_fn=nn.Dropout,\n",
    "        prenorm=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.prenorm = prenorm\n",
    "\n",
    "        # Linear encoder\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "\n",
    "        # Stack S4 layers as residual blocks\n",
    "        self.s4_layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.s4_layers.append(\n",
    "                s4d.S4D(d_model, dropout=dropout, transposed=True, lr=lr)\n",
    "            )\n",
    "            self.norms.append(nn.LayerNorm(d_model))\n",
    "            self.dropouts.append(dropout_fn(dropout))\n",
    "\n",
    "        # Linear decoder\n",
    "        self.decoder = nn.Linear(d_model, d_output)\n",
    "        \n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is shape (B, L, d_input)\n",
    "        \"\"\"\n",
    "        # Perform static quantization\n",
    "        x = self.quant(x)\n",
    "        \n",
    "        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)\n",
    "\n",
    "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
    "        for layer, norm, dropout in zip(self.s4_layers, self.norms, self.dropouts):\n",
    "            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)\n",
    "            z = x\n",
    "            if self.prenorm:\n",
    "                # Prenorm\n",
    "                z = norm(z.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "            # Apply S4 block: we ignore the state input and output\n",
    "            z, _ = layer(z)\n",
    "\n",
    "            # Dropout on the output of the S4 block\n",
    "            z = dropout(z)\n",
    "\n",
    "            # Residual connection\n",
    "            x, z = self.dequant(x), self.dequant(z)\n",
    "            x = z + x\n",
    "            x, z = self.quant(x), self.quant(z)\n",
    "\n",
    "            if not self.prenorm:\n",
    "                # Postnorm\n",
    "                x = norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "        x = x.transpose(-1, -2)\n",
    "\n",
    "        # Pooling: average pooling over the sequence length\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # Decode the outputs\n",
    "        x = self.decoder(x)  # (B, d_model) -> (B, d_output)\n",
    "        \n",
    "        # Dequantize\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = S4Model(\n",
    "    d_input=3, # num of feature\n",
    "    d_output=6, # 6 classes\n",
    "    d_model=16,\n",
    "    n_layers=4,\n",
    "    dropout=0.2,\n",
    "    lr=0.001,\n",
    "    dropout_fn=nn.Dropout,\n",
    "    prenorm=False,\n",
    ")\n",
    "\n",
    "state_path = f\"{MODEL_DIR}/s4-d16.pt\"\n",
    "state_dict = torch.load(state_path, map_location='mps')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S4Model(\n",
       "  (encoder): Linear(in_features=3, out_features=16, bias=True)\n",
       "  (s4_layers): ModuleList(\n",
       "    (0-3): 4 x S4D(\n",
       "      (kernel): S4DKernel()\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): DropoutNd()\n",
       "      (output_linear): Sequential(\n",
       "        (0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "        (1): GLU(dim=-2)\n",
       "      )\n",
       "      (quant): QuantStub()\n",
       "      (dequant): DeQuantStub()\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0-3): 4 x LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropouts): ModuleList(\n",
       "    (0-3): 4 x Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (decoder): Linear(in_features=16, out_features=6, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 92.40 %\n",
      "Size of the model: 56.25 KB\n",
      "Total inference time: 2.82 seconds\n",
      "CPU Utilization: 52.65 %\n"
     ]
    }
   ],
   "source": [
    "utils.run_measurements(model, test_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poomchan/miniconda3/envs/ml-env/lib/python3.11/site-packages/torch/ao/quantization/observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "S4Model(\n",
       "  (encoder): QuantizedLinear(in_features=3, out_features=16, scale=0.3021073341369629, zero_point=64, qscheme=torch.per_channel_affine)\n",
       "  (s4_layers): ModuleList(\n",
       "    (0): S4D(\n",
       "      (kernel): S4DKernel()\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): DropoutNd()\n",
       "      (output_linear): Sequential(\n",
       "        (0): QuantizedConv1d(16, 32, kernel_size=(1,), stride=(1,), scale=0.9975776076316833, zero_point=74)\n",
       "        (1): GLU(dim=-2)\n",
       "      )\n",
       "      (quant): Quantize(scale=tensor([0.2703]), zero_point=tensor([51]), dtype=torch.quint8)\n",
       "      (dequant): DeQuantize()\n",
       "    )\n",
       "    (1): S4D(\n",
       "      (kernel): S4DKernel()\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): DropoutNd()\n",
       "      (output_linear): Sequential(\n",
       "        (0): QuantizedConv1d(16, 32, kernel_size=(1,), stride=(1,), scale=0.297935426235199, zero_point=85)\n",
       "        (1): GLU(dim=-2)\n",
       "      )\n",
       "      (quant): Quantize(scale=tensor([0.0739]), zero_point=tensor([48]), dtype=torch.quint8)\n",
       "      (dequant): DeQuantize()\n",
       "    )\n",
       "    (2): S4D(\n",
       "      (kernel): S4DKernel()\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): DropoutNd()\n",
       "      (output_linear): Sequential(\n",
       "        (0): QuantizedConv1d(16, 32, kernel_size=(1,), stride=(1,), scale=0.3339153528213501, zero_point=85)\n",
       "        (1): GLU(dim=-2)\n",
       "      )\n",
       "      (quant): Quantize(scale=tensor([0.0849]), zero_point=tensor([46]), dtype=torch.quint8)\n",
       "      (dequant): DeQuantize()\n",
       "    )\n",
       "    (3): S4D(\n",
       "      (kernel): S4DKernel()\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): DropoutNd()\n",
       "      (output_linear): Sequential(\n",
       "        (0): QuantizedConv1d(16, 32, kernel_size=(1,), stride=(1,), scale=0.4244658946990967, zero_point=68)\n",
       "        (1): GLU(dim=-2)\n",
       "      )\n",
       "      (quant): Quantize(scale=tensor([0.0955]), zero_point=tensor([54]), dtype=torch.quint8)\n",
       "      (dequant): DeQuantize()\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0-3): 4 x QuantizedLayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropouts): ModuleList(\n",
       "    (0-3): 4 x QuantizedDropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (decoder): QuantizedLinear(in_features=16, out_features=6, scale=0.3266921043395996, zero_point=81, qscheme=torch.per_channel_affine)\n",
       "  (quant): Quantize(scale=tensor([0.3193]), zero_point=tensor([64]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "backend = \"fbgemm\"  # \"fbgemm\" for x86 CPU. Use \"qnnpack\" if running on ARM.\n",
    "\n",
    "quantized_model = copy.deepcopy(model)\n",
    "quantized_model.eval()\n",
    "\n",
    "\"\"\"Prepare\"\"\"\n",
    "quantized_model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.quantization.prepare(quantized_model, inplace=True)\n",
    "\n",
    "\"\"\"Calibrate\n",
    "- Use representative (validation) data.\n",
    "\"\"\"\n",
    "with torch.inference_mode():\n",
    "  for inputs, labels in calibration_loader:\n",
    "    quantized_model(inputs)\n",
    "\n",
    "\"\"\"Convert\"\"\"\n",
    "torch.quantization.convert(quantized_model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 91.49 %\n",
      "Size of the model: 64.27 KB\n",
      "Total inference time: 13.46 seconds\n",
      "CPU Utilization: 73.65 %\n"
     ]
    }
   ],
   "source": [
    "utils.run_measurements(quantized_model, test_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
