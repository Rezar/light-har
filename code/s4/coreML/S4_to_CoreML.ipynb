{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import the s4 model path\n",
    "import sys\n",
    "sys.path.append('/Users/poomchan/Developer/light-har/code/s4')\n",
    "from s4d import S4D\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S4Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_input,\n",
    "        d_output,\n",
    "        d_model=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.2,\n",
    "        lr=0.001,\n",
    "        dropout_fn=nn.Dropout,\n",
    "        prenorm=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.prenorm = prenorm\n",
    "\n",
    "        # Linear encoder (d_input = 1 for grayscale and 3 for RGB)\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "\n",
    "        # Stack S4 layers as residual blocks\n",
    "        self.s4_layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.s4_layers.append(\n",
    "                S4D(d_model, dropout=dropout, transposed=True, lr=lr)\n",
    "            )\n",
    "            self.norms.append(nn.LayerNorm(d_model))\n",
    "            self.dropouts.append(dropout_fn(dropout))\n",
    "\n",
    "        # Linear decoder\n",
    "        self.decoder = nn.Linear(d_model, d_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is shape (B, L, d_input)\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)\n",
    "\n",
    "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
    "        for layer, norm, dropout in zip(self.s4_layers, self.norms, self.dropouts):\n",
    "            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)\n",
    "\n",
    "            z = x\n",
    "            if self.prenorm:\n",
    "                # Prenorm\n",
    "                z = norm(z.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "            # Apply S4 block: we ignore the state input and output\n",
    "            z, _ = layer(z)\n",
    "\n",
    "            # Dropout on the output of the S4 block\n",
    "            z = dropout(z)\n",
    "\n",
    "            # Residual connection\n",
    "            x = z + x\n",
    "\n",
    "            if not self.prenorm:\n",
    "                # Postnorm\n",
    "                x = norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "        x = x.transpose(-1, -2)\n",
    "\n",
    "        # Pooling: average pooling over the sequence length\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # Decode the outputs\n",
    "        x = self.decoder(x)  # (B, d_model) -> (B, d_output)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the PyTorch model.\n",
    "model = S4Model(\n",
    "    d_input=3, # num of feature\n",
    "    d_output=6, # 6 classes\n",
    "    d_model=16,\n",
    "    n_layers=4,\n",
    "    dropout=0.2,\n",
    "    lr=0.001,\n",
    "    dropout_fn=nn.Dropout,\n",
    "    prenorm=False,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "model_path = \"/Users/poomchan/Developer/light-har/code/s4/models/s4-d16.pt\"\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/poomchan/miniconda3/envs/coreml/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/poomchan/miniconda3/envs/coreml/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.8.dylib\n",
      "  Referenced from: <90B45554-B79A-39BA-8A44-F2AD877B729C> /Users/poomchan/miniconda3/envs/coreml/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/poomchan/miniconda3/envs/coreml/lib/python3.9/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/poomchan/miniconda3/envs/coreml/lib/python3.9/site-packages/torchvision/../../../libjpeg.8.dylib' (no such file), '/Users/poomchan/miniconda3/envs/coreml/lib/python3.9/lib-dynload/../../libjpeg.8.dylib' (no such file), '/Users/poomchan/miniconda3/envs/coreml/bin/../lib/libjpeg.8.dylib' (no such file), '/usr/local/lib/libjpeg.8.dylib' (no such file), '/usr/lib/libjpeg.8.dylib' (no such file, not in dyld cache)\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch._C.Node' object has no attribute 'cs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m traced_model(example_input)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Convert to Core ML program using the Unified Conversion API.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m coreml_model \u001b[38;5;241m=\u001b[39m \u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraced_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlprogram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorType\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Save the converted model.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m coreml_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms4.mlpackage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/_converters_entry.py:574\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, compute_precision, skip_model_load, compute_units, package_dir, debug, pass_pipeline)\u001b[0m\n\u001b[1;32m    566\u001b[0m     specification_version \u001b[38;5;241m=\u001b[39m _set_default_specification_version(exact_target)\n\u001b[1;32m    568\u001b[0m use_default_fp16_io \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    569\u001b[0m     specification_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m specification_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m AvailableTarget\u001b[38;5;241m.\u001b[39miOS16\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m need_fp16_cast_pass\n\u001b[1;32m    572\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m mlmodel \u001b[38;5;241m=\u001b[39m \u001b[43mmil_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs_as_tensor_or_image_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# None or list[ct.ImageType/ct.TensorType]\u001b[39;49;00m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_model_load\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_model_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackage_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackage_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecification_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecification_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmain_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_default_fp16_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_default_fp16_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exact_target \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlprogram\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mlmodel\u001b[38;5;241m.\u001b[39m_input_has_infinite_upper_bound():\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor mlprogram, inputs with infinite upper_bound is not allowed. Please set upper_bound\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    593\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to a positive value in \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRangeDim()\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for the \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m param in ct.convert().\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    594\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/converter.py:188\u001b[0m, in \u001b[0;36mmil_convert\u001b[0;34m(model, convert_from, convert_to, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;129m@_profile\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmil_convert\u001b[39m(\n\u001b[1;32m    151\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    156\u001b[0m ):\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    Convert model from a specified frontend `convert_from` to a specified\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    converter backend `convert_to`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m        See `coremltools.converters.convert`\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_mil_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_from\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConverterRegistry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/converter.py:212\u001b[0m, in \u001b[0;36m_mil_convert\u001b[0;34m(model, convert_from, convert_to, registry, modelClass, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     weights_dir \u001b[38;5;241m=\u001b[39m _tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory()\n\u001b[1;32m    210\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m weights_dir\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m--> 212\u001b[0m proto, mil_program \u001b[38;5;241m=\u001b[39m \u001b[43mmil_convert_to_proto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mconvert_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m                     \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m _reset_conversion_state()\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmilinternal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/converter.py:286\u001b[0m, in \u001b[0;36mmil_convert_to_proto\u001b[0;34m(model, convert_from, convert_to, converter_registry, main_pipeline, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m frontend_pipeline, backend_pipeline \u001b[38;5;241m=\u001b[39m _construct_other_pipelines(\n\u001b[1;32m    282\u001b[0m     main_pipeline, convert_from, convert_to\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m frontend_converter \u001b[38;5;241m=\u001b[39m frontend_converter_type()\n\u001b[0;32m--> 286\u001b[0m prog \u001b[38;5;241m=\u001b[39m \u001b[43mfrontend_converter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m PassPipelineManager\u001b[38;5;241m.\u001b[39mapply_pipeline(prog, frontend_pipeline)\n\u001b[1;32m    289\u001b[0m PassPipelineManager\u001b[38;5;241m.\u001b[39mapply_pipeline(prog, main_pipeline)\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/converter.py:108\u001b[0m, in \u001b[0;36mTorchFrontend.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrontend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/frontend/torch/load.py:71\u001b[0m, in \u001b[0;36mload\u001b[0;34m(spec, inputs, specification_version, debug, outputs, cut_at_symbols, use_default_fp16_io, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     model \u001b[38;5;241m=\u001b[39m _torchscript_from_spec(spec)\n\u001b[0;32m---> 71\u001b[0m converter \u001b[38;5;241m=\u001b[39m \u001b[43mTorchConverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcut_at_symbols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecification_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_default_fp16_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _perform_torch_convert(converter, debug)\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/frontend/torch/converter.py:349\u001b[0m, in \u001b[0;36mTorchConverter.__init__\u001b[0;34m(self, loaded_model, inputs, outputs, cut_at_symbols, opset_version, use_default_fp16_io)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prog \u001b[38;5;241m=\u001b[39m Program()\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loaded_model, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule):\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_dict \u001b[38;5;241m=\u001b[39m \u001b[43mInternalTorchIRGraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_torchscript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorchscript\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloaded_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcut_at_symbols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcut_at_symbols\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;66;03m# TODO (rdar://106161395): Register Torch IR passes and unify them into the pass pipeline.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;66;03m# Apply Torch IR passes\u001b[39;00m\n\u001b[1;32m    355\u001b[0m     passes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    356\u001b[0m         transform_inplace_ops,\n\u001b[1;32m    357\u001b[0m         flatten_graph_input_values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m         generate_tensor_assignment_ops,\n\u001b[1;32m    361\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/frontend/torch/internal_graph.py:411\u001b[0m, in \u001b[0;36mInternalTorchIRGraph.from_torchscript\u001b[0;34m(cls, torchscript, input_values, cut_at_symbols)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# Add nodes\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m raw_node \u001b[38;5;129;01min\u001b[39;00m raw_graph\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[0;32m--> 411\u001b[0m     new_node \u001b[38;5;241m=\u001b[39m \u001b[43mInternalTorchIRNode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_torchscript_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minternal_graph\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_node\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m new_node\u001b[38;5;241m.\u001b[39mkind:\n\u001b[1;32m    415\u001b[0m         new_node\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m _find_new_name(new_node\u001b[38;5;241m.\u001b[39mname, node_names)\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/frontend/torch/internal_graph.py:195\u001b[0m, in \u001b[0;36mInternalTorchIRNode.from_torchscript_node\u001b[0;34m(cls, node, parent)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     kind \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mkind()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m--> 195\u001b[0m attr \u001b[38;5;241m=\u001b[39m {name: \u001b[38;5;28mgetattr\u001b[39m(node, node\u001b[38;5;241m.\u001b[39mkindOf(name))(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattributeNames()}\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m attr:\n\u001b[1;32m    197\u001b[0m     attr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/frontend/torch/internal_graph.py:195\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     kind \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mkind()\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m--> 195\u001b[0m attr \u001b[38;5;241m=\u001b[39m {name: \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkindOf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mattributeNames()}\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m attr:\n\u001b[1;32m    197\u001b[0m     attr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch._C.Node' object has no attribute 'cs'"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "\n",
    "example_input = torch.randn(1, 16, 3)\n",
    "\n",
    "model.to('cpu')\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "traced_model(example_input)\n",
    "\n",
    "# Convert to Core ML program using the Unified Conversion API.\n",
    "coreml_model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to=\"mlprogram\",\n",
    "    inputs=[ct.TensorType(shape=example_input.shape)]\n",
    " )\n",
    "\n",
    "# Save the converted model.\n",
    "coreml_model.save(\"s4.mlpackage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools.optimize.coreml as cto\n",
    "import coremltools as ct\n",
    "\n",
    "coreml_model = ct.models.MLModel(\"cnn.mlpackage\")\n",
    "coreml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_config = cto.OpLinearQuantizerConfig(mode=\"linear_symmetric\", weight_threshold=512)\n",
    "config = cto.OptimizationConfig(global_config=op_config)\n",
    "\n",
    "quantized_model = cto.linear_quantize_weights(coreml_model, config=config)\n",
    "\n",
    "# Save the model\n",
    "model_path = \"quantized-s4.mlpackage\"\n",
    "quantized_model.save(\"quantized-s4.mlpackage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Data\n",
    "x = genfromtxt('../Data/WISDM_x.csv', delimiter=',')\n",
    "y_df = pd.read_csv('../Data/WISDM_y.csv')\n",
    "y = y_df.values.flatten()  # Flatten if y is 2D\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Function to create time series dataset\n",
    "def create_series(x, y, timestep, overlap):\n",
    "    slide_step = int(timestep * (1 - overlap))\n",
    "    data_num = int((len(x) / slide_step) - 1)\n",
    "    dataset = np.ndarray(shape=(data_num, timestep, x.shape[1]))\n",
    "    labels = []\n",
    "\n",
    "    for i in range(data_num):\n",
    "        labels.append(y[slide_step * (i + 1) - 1])\n",
    "        for j in range(timestep):\n",
    "            dataset[i, j, :] = x[slide_step * i + j, :]\n",
    "\n",
    "    return dataset, np.array(labels)\n",
    "\n",
    "# Create time series\n",
    "timestep = 16  # Replace with your value\n",
    "overlap = 0.5  # Replace with your value\n",
    "X_series, y_series = create_series(x, y_encoded, timestep, overlap)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_series, y_series, test_size=0.2, random_state=42)\n",
    "print(f'X_train shape:{X_train.shape}, X_test shape:{X_test.shape}, y_train shape:{y_train.shape}, y_test shape:{y_test.shape}')\n",
    "\n",
    "# Convert arrays to PyTorch Tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)  # Assuming y_train is class labels for classification\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Creating TensorDatasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Creating DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def coreml_metrics(model_name, X_test, y_test, model_path):\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        X_test_sample = X_test[i].view(1, 3, 16)\n",
    "        #X_test_new = np.expand_dims(X_test[id], axis=0)\n",
    "        output_dict = model_name.predict({'x': X_test_sample.numpy()})\n",
    "        pred_class = np.argmax(output_dict['var_75'])\n",
    "        predictions.append(pred_class)\n",
    "    \n",
    "    accuracy = np.sum(np.array(predictions) == y_test.numpy()) / len(predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    model_file = Path(model_path)\n",
    "    \n",
    "    # Size in bytes\n",
    "    model_size_bytes = model_file.stat().st_size\n",
    "    \n",
    "    # Convert size to kilobytes (optional)\n",
    "    model_size_kb = model_size_bytes / 1024\n",
    "    print(f\"Size of the model: {model_size_kb:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_metrics(quantized_model, X_test, y_test, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
