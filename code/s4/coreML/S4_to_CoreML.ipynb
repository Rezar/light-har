{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n",
      "Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Import the s4 model path\n",
    "import sys\n",
    "# PATH_TO_S4_REPO = \"/Users/poomchan/Developer/s4\"\n",
    "PATH_TO_S4_REPO = \"/Users/poomchan/Developer/light-har/code/s4\"\n",
    "sys.path.append(PATH_TO_S4_REPO)\n",
    "# from models.s4.s4d import S4D\n",
    "from s4 import S4Block\n",
    "# from s4d import S4D\n",
    "import s4d2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__ = 2.1.0.post100\n",
      "coremltools.__version__ = 7.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch.__version__ = {torch.__version__}\")\n",
    "print(f\"coremltools.__version__ = {ct.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S4Model(\n",
       "  (encoder): Linear(in_features=3, out_features=16, bias=True)\n",
       "  (s4_layers): ModuleList(\n",
       "    (0-3): 4 x S4D(\n",
       "      (activation): GELU(approximate='none')\n",
       "      (dropout): Identity()\n",
       "      (output_linear): Sequential(\n",
       "        (0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "        (1): GLU(dim=-2)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norms): ModuleList(\n",
       "    (0-3): 4 x LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropouts): ModuleList(\n",
       "    (0-3): 4 x Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (decoder): Linear(in_features=16, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(s4d2)\n",
    "\n",
    "class S4Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_input,\n",
    "        d_output,\n",
    "        d_model=256,\n",
    "        n_layers=4,\n",
    "        dropout=0.2,\n",
    "        lr=0.001,\n",
    "        dropout_fn=nn.Dropout,\n",
    "        prenorm=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.prenorm = prenorm\n",
    "\n",
    "        # Linear encoder (d_input = 1 for grayscale and 3 for RGB)\n",
    "        self.encoder = nn.Linear(d_input, d_model)\n",
    "\n",
    "        # Stack S4 layers as residual blocks\n",
    "        self.s4_layers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        for _ in range(n_layers):\n",
    "            self.s4_layers.append(\n",
    "                s4d2.S4D(d_model, dropout=dropout, transposed=True, lr=lr)\n",
    "            )\n",
    "            self.norms.append(nn.LayerNorm(d_model))\n",
    "            self.dropouts.append(dropout_fn(dropout))\n",
    "\n",
    "        # Linear decoder\n",
    "        self.decoder = nn.Linear(d_model, d_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is shape (B, L, d_input)\n",
    "        \"\"\"\n",
    "        x = self.encoder(x)  # (B, L, d_input) -> (B, L, d_model)\n",
    "\n",
    "        x = x.transpose(-1, -2)  # (B, L, d_model) -> (B, d_model, L)\n",
    "        for layer, norm, dropout in zip(self.s4_layers, self.norms, self.dropouts):\n",
    "            # Each iteration of this loop will map (B, d_model, L) -> (B, d_model, L)\n",
    "\n",
    "            z = x\n",
    "            if self.prenorm:\n",
    "                # Prenorm\n",
    "                z = norm(z.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "            # Apply S4 block: we ignore the state input and output\n",
    "            z, _ = layer(z)\n",
    "\n",
    "            # Dropout on the output of the S4 block\n",
    "            z = dropout(z)\n",
    "\n",
    "            # Residual connection\n",
    "            x = z + x\n",
    "\n",
    "            if not self.prenorm:\n",
    "                # Postnorm\n",
    "                x = norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "        x = x.transpose(-1, -2)\n",
    "\n",
    "        # Pooling: average pooling over the sequence length\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # Decode the outputs\n",
    "        x = self.decoder(x)  # (B, d_model) -> (B, d_output)\n",
    "\n",
    "        return x\n",
    "\n",
    "# import the PyTorch model.\n",
    "model = S4Model(\n",
    "    d_input=3, # num of feature\n",
    "    d_output=6, # 6 classes\n",
    "    d_model=16,\n",
    "    n_layers=4,\n",
    "    dropout=0.0,\n",
    "    lr=0.001,\n",
    "    dropout_fn=nn.Dropout,\n",
    "    prenorm=False,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "# model_path = \"/Users/poomchan/Developer/light-har/code/s4/models/s4-d16.pt\"\n",
    "# model.load_state_dict(torch.load(model_path, map_location='cpu'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When both 'convert_to' and 'minimum_deployment_target' not specified, 'convert_to' is set to \"mlprogram\" and 'minimum_deployment_targer' is set to ct.target.iOS15 (which is same as ct.target.macOS12). Note: the model will not run on systems older than iOS15/macOS12/watchOS8/tvOS15. In order to make your model run on older system, please set the 'minimum_deployment_target' to iOS14/iOS13. Details please see the link: https://coremltools.readme.io/docs/unified-conversion-api#target-conversion-formats\n",
      "Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops:  71%|███████▏  | 5/7 [00:00<00:00, 1776.80 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 7174.66 passes/s]\n",
      "Running MIL default pipeline:   0%|          | 0/71 [00:00<?, ? passes/s]/Users/poomchan/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:267: UserWarning: Output, '7', of the source model, has been renamed to 'var_7' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL default pipeline: 100%|██████████| 71/71 [00:00<00:00, 7030.28 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 25191.02 passes/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "input {\n",
       "  name: \"x\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 3\n",
       "      dataType: FLOAT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "output {\n",
       "  name: \"x\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 3\n",
       "      dataType: FLOAT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "output {\n",
       "  name: \"var_7\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 3\n",
       "      dataType: FLOAT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "metadata {\n",
       "  userDefined {\n",
       "    key: \"com.github.apple.coremltools.source\"\n",
       "    value: \"torch==2.1.0.post100\"\n",
       "  }\n",
       "  userDefined {\n",
       "    key: \"com.github.apple.coremltools.source_dialect\"\n",
       "    value: \"TorchScript\"\n",
       "  }\n",
       "  userDefined {\n",
       "    key: \"com.github.apple.coremltools.version\"\n",
       "    value: \"7.1\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import coremltools as ct\n",
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        real_part = x\n",
    "        imag_part = torch.zeros_like(x)  # Assuming imaginary part is initially zero\n",
    "        return real_part, imag_part\n",
    "\n",
    "m = MyModel().eval()\n",
    "x = torch.Tensor([1, 2, 3])\n",
    "m = torch.jit.trace(m, x)\n",
    "\n",
    "# Now convert the modified model\n",
    "ct.convert(m, inputs=[ct.TensorType(shape=x.shape)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import coremltools as ct\n",
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.complex(x, x)\n",
    "\n",
    "m = MyModel().eval()\n",
    "x = torch.Tensor([1, 2, 3])\n",
    "m = torch.jit.trace(m, x)\n",
    "ct.convert(m, inputs=[ct.TensorType(shape=x.shape)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops:   0%|          | 0/245 [00:00<?, ? ops/s]Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  16%|█▋        | 40/245 [00:00<00:00, 1993.89 ops/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Op \"65\" (op_type: mul) Input x=\"complex_rfft_1\" expects tensor or scalar of dtype from type domain ['fp16', 'fp32', 'int32'] but got tensor[1,16,17,complex64]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m traced_model(example_input)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Convert to Core ML program using the Unified Conversion API.\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m coreml_model \u001b[38;5;241m=\u001b[39m \u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraced_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlprogram\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpytorch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorType\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/_converters_entry.py:574\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(model, source, inputs, outputs, classifier_config, minimum_deployment_target, convert_to, compute_precision, skip_model_load, compute_units, package_dir, debug, pass_pipeline)\u001b[0m\n\u001b[1;32m    566\u001b[0m     specification_version \u001b[38;5;241m=\u001b[39m _set_default_specification_version(exact_target)\n\u001b[1;32m    568\u001b[0m use_default_fp16_io \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    569\u001b[0m     specification_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m specification_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m AvailableTarget\u001b[38;5;241m.\u001b[39miOS16\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m need_fp16_cast_pass\n\u001b[1;32m    572\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m mlmodel \u001b[38;5;241m=\u001b[39m \u001b[43mmil_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs_as_tensor_or_image_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# None or list[ct.ImageType/ct.TensorType]\u001b[39;49;00m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_model_load\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_model_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackage_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackage_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspecification_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecification_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmain_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpass_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_default_fp16_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_default_fp16_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exact_target \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlprogram\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mlmodel\u001b[38;5;241m.\u001b[39m_input_has_infinite_upper_bound():\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    592\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor mlprogram, inputs with infinite upper_bound is not allowed. Please set upper_bound\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    593\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to a positive value in \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRangeDim()\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for the \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m param in ct.convert().\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    594\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/converter.py:188\u001b[0m, in \u001b[0;36mmil_convert\u001b[0;34m(model, convert_from, convert_to, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;129m@_profile\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmil_convert\u001b[39m(\n\u001b[1;32m    151\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    156\u001b[0m ):\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    Convert model from a specified frontend `convert_from` to a specified\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    converter backend `convert_to`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m        See `coremltools.converters.convert`\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_mil_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_from\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConverterRegistry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/converter.py:212\u001b[0m, in \u001b[0;36m_mil_convert\u001b[0;34m(model, convert_from, convert_to, registry, modelClass, compute_units, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     weights_dir \u001b[38;5;241m=\u001b[39m _tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory()\n\u001b[1;32m    210\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m weights_dir\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m--> 212\u001b[0m proto, mil_program \u001b[38;5;241m=\u001b[39m \u001b[43mmil_convert_to_proto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mconvert_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mconvert_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m                     \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m _reset_conversion_state()\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmilinternal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/converter.py:286\u001b[0m, in \u001b[0;36mmil_convert_to_proto\u001b[0;34m(model, convert_from, convert_to, converter_registry, main_pipeline, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m frontend_pipeline, backend_pipeline \u001b[38;5;241m=\u001b[39m _construct_other_pipelines(\n\u001b[1;32m    282\u001b[0m     main_pipeline, convert_from, convert_to\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m frontend_converter \u001b[38;5;241m=\u001b[39m frontend_converter_type()\n\u001b[0;32m--> 286\u001b[0m prog \u001b[38;5;241m=\u001b[39m \u001b[43mfrontend_converter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m PassPipelineManager\u001b[38;5;241m.\u001b[39mapply_pipeline(prog, frontend_pipeline)\n\u001b[1;32m    289\u001b[0m PassPipelineManager\u001b[38;5;241m.\u001b[39mapply_pipeline(prog, main_pipeline)\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/converter.py:108\u001b[0m, in \u001b[0;36mTorchFrontend.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrontend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/frontend/torch/load.py:80\u001b[0m, in \u001b[0;36mload\u001b[0;34m(spec, inputs, specification_version, debug, outputs, cut_at_symbols, use_default_fp16_io, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m     model \u001b[38;5;241m=\u001b[39m _torchscript_from_spec(spec)\n\u001b[1;32m     71\u001b[0m converter \u001b[38;5;241m=\u001b[39m TorchConverter(\n\u001b[1;32m     72\u001b[0m     model,\n\u001b[1;32m     73\u001b[0m     inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     use_default_fp16_io,\n\u001b[1;32m     78\u001b[0m )\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_perform_torch_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/frontend/torch/load.py:99\u001b[0m, in \u001b[0;36m_perform_torch_convert\u001b[0;34m(converter, debug)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_perform_torch_convert\u001b[39m(converter: TorchConverter, debug: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Program:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m         prog \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m debug \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert function\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/frontend/torch/converter.py:519\u001b[0m, in \u001b[0;36mTorchConverter.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_const()\n\u001b[1;32m    518\u001b[0m \u001b[38;5;66;03m# Add the rest of the operations\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m \u001b[43mconvert_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m graph_outputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39moutputs]\n\u001b[1;32m    523\u001b[0m \u001b[38;5;66;03m# An output can be None when it's a None constant, which happens\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;66;03m# in Fairseq MT.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/frontend/torch/ops.py:88\u001b[0m, in \u001b[0;36mconvert_nodes\u001b[0;34m(context, graph)\u001b[0m\n\u001b[1;32m     85\u001b[0m context\u001b[38;5;241m.\u001b[39mquant_context\u001b[38;5;241m.\u001b[39mmaybe_handle_quantized_inputs(node)\n\u001b[1;32m     86\u001b[0m context\u001b[38;5;241m.\u001b[39mprepare_for_conversion(node)\n\u001b[0;32m---> 88\u001b[0m \u001b[43madd_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TORCH_OPS_REGISTRY\u001b[38;5;241m.\u001b[39mis_inplace_op(op_lookup):\n\u001b[1;32m     91\u001b[0m     context\u001b[38;5;241m.\u001b[39mprocess_inplace_op(node)\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/frontend/torch/ops.py:1499\u001b[0m, in \u001b[0;36mmul\u001b[0;34m(context, node)\u001b[0m\n\u001b[1;32m   1497\u001b[0m     res \u001b[38;5;241m=\u001b[39m mb\u001b[38;5;241m.\u001b[39mlogical_and(x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39my, name\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1499\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mmb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1500\u001b[0m context\u001b[38;5;241m.\u001b[39madd(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/mil/ops/registry.py:182\u001b[0m, in \u001b[0;36mSSAOpRegistry.register_op.<locals>.class_wrapper.<locals>.add_op\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     op_cls_to_add \u001b[38;5;241m=\u001b[39m op_reg[op_type]\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_cls_to_add\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/mil/builder.py:168\u001b[0m, in \u001b[0;36mBuilder._add_op\u001b[0;34m(cls, op_cls, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_create_vars(\n\u001b[1;32m    164\u001b[0m     input_spec\u001b[38;5;241m=\u001b[39mop_cls\u001b[38;5;241m.\u001b[39minput_spec,\n\u001b[1;32m    165\u001b[0m     op_name\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m], before_op\u001b[38;5;241m=\u001b[39mbefore_op,\n\u001b[1;32m    166\u001b[0m     candidate_kv\u001b[38;5;241m=\u001b[39mkwargs))\n\u001b[1;32m    167\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menclosing_block\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m curr_block()\n\u001b[0;32m--> 168\u001b[0m new_op \u001b[38;5;241m=\u001b[39m \u001b[43mop_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Initialize optional input Vars if it wasn't in kwargs\u001b[39;00m\n\u001b[1;32m    171\u001b[0m default_inputs \u001b[38;5;241m=\u001b[39m new_op\u001b[38;5;241m.\u001b[39mdefault_inputs()\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/mil/operation.py:190\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# Set inputs from kwargs\u001b[39;00m\n\u001b[1;32m    188\u001b[0m input_kv \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    189\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_types \u001b[38;5;129;01mand\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_set_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_kv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_required_inputs()\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/mil/operation.py:503\u001b[0m, in \u001b[0;36mOperation._validate_and_set_inputs\u001b[0;34m(self, input_kvs, no_check_var_types)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    498\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew var type `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv_new\u001b[38;5;241m.\u001b[39msym_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` not a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubtype of existing var type `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv_old\u001b[38;5;241m.\u001b[39msym_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    501\u001b[0m     v_old\u001b[38;5;241m.\u001b[39mremove_child_op(op, no_check_var_types)\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_kvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, var \u001b[38;5;129;01min\u001b[39;00m input_kvs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# Remove this operation itself from existing input\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;66;03m# Var's child_ops\u001b[39;00m\n\u001b[1;32m    508\u001b[0m     existing_input_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_vars[name]\n",
      "File \u001b[0;32m~/miniconda3/envs/coreml/lib/python3.9/site-packages/coremltools/converters/mil/mil/input_type.py:163\u001b[0m, in \u001b[0;36mInputSpec.validate_inputs\u001b[0;34m(self, op_name, op_type, candidate_kvs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(var, InternalVar) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m input_type\u001b[38;5;241m.\u001b[39mis_compatible(var):\n\u001b[1;32m    161\u001b[0m     msg \u001b[38;5;241m=\u001b[39m msg_prefix \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name, var\u001b[38;5;241m.\u001b[39mname, input_type\u001b[38;5;241m.\u001b[39mtype_str,\n\u001b[1;32m    164\u001b[0m                 var\u001b[38;5;241m.\u001b[39msym_type\u001b[38;5;241m.\u001b[39m__type_info__()))\n",
      "\u001b[0;31mValueError\u001b[0m: Op \"65\" (op_type: mul) Input x=\"complex_rfft_1\" expects tensor or scalar of dtype from type domain ['fp16', 'fp32', 'int32'] but got tensor[1,16,17,complex64]"
     ]
    }
   ],
   "source": [
    "import coremltools as ct\n",
    "\n",
    "example_input = torch.randn(1, 16, 3)\n",
    "\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "traced_model(example_input)\n",
    "\n",
    "# Convert to Core ML program using the Unified Conversion API.\n",
    "coreml_model = ct.convert(\n",
    "    traced_model,\n",
    "    convert_to=\"mlprogram\",\n",
    "    source=\"pytorch\",\n",
    "    inputs=[ct.TensorType(shape=example_input.shape)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coremltools.converters.mil.frontend.torch.edgeir_utils import extract_inputs_from_edge_program\n",
    "from coremltools.converters.mil.frontend.torch.torchscript_utils import _expand_and_optimize_ir\n",
    "\n",
    "example_input = torch.randn(1, 16, 3)\n",
    "\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "traced_model(example_input)\n",
    "\n",
    "raw_graph, params_dict, buffer_dict = _expand_and_optimize_ir(traced_model)\n",
    "\n",
    "for node in raw_graph.nodes():\n",
    "    attr = {}\n",
    "    for name in node.attributeNames():\n",
    "        if node.kindOf(name) == \"cs\":\n",
    "            # attr[name] = node.c(name)\n",
    "            print(node)\n",
    "            attr[name] = getattr(node, \"c\")(name)\n",
    "        else:\n",
    "            attr[name] = getattr(node, node.kindOf(name))(name)\n",
    "    # print(attr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools.optimize.coreml as cto\n",
    "import coremltools as ct\n",
    "\n",
    "coreml_model = ct.models.MLModel(\"s4.mlpackage\")\n",
    "coreml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_config = cto.OpLinearQuantizerConfig(mode=\"linear_symmetric\", weight_threshold=512)\n",
    "config = cto.OptimizationConfig(global_config=op_config)\n",
    "\n",
    "quantized_model = cto.linear_quantize_weights(coreml_model, config=config)\n",
    "\n",
    "# # Save the model\n",
    "# model_path = \"quantized-s4.mlpackage\"\n",
    "# quantized_model.save(\"quantized-s4.mlpackage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch._C import Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Data\n",
    "x = genfromtxt('../Data/WISDM_x.csv', delimiter=',')\n",
    "y_df = pd.read_csv('../Data/WISDM_y.csv')\n",
    "y = y_df.values.flatten()  # Flatten if y is 2D\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Function to create time series dataset\n",
    "def create_series(x, y, timestep, overlap):\n",
    "    slide_step = int(timestep * (1 - overlap))\n",
    "    data_num = int((len(x) / slide_step) - 1)\n",
    "    dataset = np.ndarray(shape=(data_num, timestep, x.shape[1]))\n",
    "    labels = []\n",
    "\n",
    "    for i in range(data_num):\n",
    "        labels.append(y[slide_step * (i + 1) - 1])\n",
    "        for j in range(timestep):\n",
    "            dataset[i, j, :] = x[slide_step * i + j, :]\n",
    "\n",
    "    return dataset, np.array(labels)\n",
    "\n",
    "# Create time series\n",
    "timestep = 16  # Replace with your value\n",
    "overlap = 0.5  # Replace with your value\n",
    "X_series, y_series = create_series(x, y_encoded, timestep, overlap)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_series, y_series, test_size=0.2, random_state=42)\n",
    "print(f'X_train shape:{X_train.shape}, X_test shape:{X_test.shape}, y_train shape:{y_train.shape}, y_test shape:{y_test.shape}')\n",
    "\n",
    "# Convert arrays to PyTorch Tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)  # Assuming y_train is class labels for classification\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Creating TensorDatasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Creating DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def coreml_metrics(model_name, X_test, y_test, model_path):\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        X_test_sample = X_test[i].view(1, 3, 16)\n",
    "        #X_test_new = np.expand_dims(X_test[id], axis=0)\n",
    "        output_dict = model_name.predict({'x': X_test_sample.numpy()})\n",
    "        pred_class = np.argmax(output_dict['var_75'])\n",
    "        predictions.append(pred_class)\n",
    "    \n",
    "    accuracy = np.sum(np.array(predictions) == y_test.numpy()) / len(predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    model_file = Path(model_path)\n",
    "    \n",
    "    # Size in bytes\n",
    "    model_size_bytes = model_file.stat().st_size\n",
    "    \n",
    "    # Convert size to kilobytes (optional)\n",
    "    model_size_kb = model_size_bytes / 1024\n",
    "    print(f\"Size of the model: {model_size_kb:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_metrics(quantized_model, X_test, y_test, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
